# FactHarbor Environment Variables
# These values must match the API configuration in appsettings.Development.json

# =============================================================================
# IMPORTANT: Agents and Administrators: .env.example shall allways be in sync with .env.local, 
# but .env.example without the API Keys!!
# So that Agents that don't have access to .env.local know the current configuration
# =============================================================================

# =============================================================================
# API Configuration
# =============================================================================
FH_API_BASE_URL=http://localhost:5000

# Keys for internal calls (must match API's appsettings.Development.json)
FH_ADMIN_KEY=DEV_SHARED_SECRET_ADMIN_KEY
FH_INTERNAL_RUNNER_KEY=DEV_SHARED_SECRET_RUNNER_KEY

# Max concurrent analysis jobs
FH_RUNNER_MAX_CONCURRENCY=4

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Set which LLM provider to use (anthropic recommended for best results)
# Options: anthropic, openai, google, mistral
LLM_PROVIDER=anthropic
# LLM_PROVIDER=openai
# LLM_PROVIDER=google
# LLM_PROVIDER=mistral

# API Keys - set the key for your chosen provider
OPENAI_API_KEY=PASTE_YOUR_KEY_HERE
ANTHROPIC_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_GENERATIVE_AI_API_KEY=PASTE_YOUR_KEY_HERE
MISTRAL_API_KEY=PASTE_YOUR_KEY_HERE

# LLM fallback order (comma-separated, optional)
# If primary provider fails, try these in order
# FH_LLM_FALLBACKS=openai,anthropic,google,mistral

# =============================================================================
# LLM Tiering (RECOMMENDED for cost optimization)
# =============================================================================
# Enable tiered model selection - uses cheaper models for simple tasks
# Options: on, off (default: off)
# Savings: 50-70% cost reduction with minimal quality impact
FH_LLM_TIERING=on

# Per-task model overrides (when tiering is on)
# Understanding claims: cheaper model is fine
FH_MODEL_UNDERSTAND=claude-3-5-haiku-20241022
# Extracting facts: cheaper model is fine
FH_MODEL_EXTRACT_FACTS=claude-3-5-haiku-20241022
# Final verdict: use best model for accuracy
FH_MODEL_VERDICT=claude-sonnet-4-20250514

# =============================================================================
# LLM Text Analysis (v2.9 - Delegated Heuristics)
# =============================================================================
# Replace hardcoded text analysis heuristics with LLM calls.
# Each analysis point can be enabled independently.
# When enabled, uses LLM with automatic fallback to heuristics on failure.
# See: Docs/REVIEWS/LLM_Text_Analysis_Pipeline_Deep_Analysis.md

# Call 1: Input Classification + Claim Decomposition (UNDERSTAND phase)
# Replaces: isComparativeLikeText(), isCompoundLikeText(), deriveCandidateClaimTexts()
# FH_LLM_INPUT_CLASSIFICATION=false  # (default: false)

# Call 2: Evidence Quality Assessment (EXTRACT_FACTS phase)
# Replaces: countVaguePhrases(), hasTemporalAnchor(), hasCitation()
# FH_LLM_EVIDENCE_QUALITY=false  # (default: false)

# Call 3: Scope Similarity Analysis (SCOPE_REFINE phase)
# Replaces: calculateScopeSimilarity(), inferPhaseBucket()
# FH_LLM_SCOPE_SIMILARITY=false  # (default: false)

# Call 4: Verdict Validation (VERDICT phase)
# Replaces: detectHarmPotential(), detectClaimContestation(), detectVerdictInversion()
# FH_LLM_VERDICT_VALIDATION=false  # (default: false)

FH_LLM_INPUT_CLASSIFICATION=true
FH_LLM_EVIDENCE_QUALITY=true
FH_LLM_SCOPE_SIMILARITY=true  
FH_LLM_VERDICT_VALIDATION=true

# =============================================================================
# Web Search Configuration
# =============================================================================
# Search provider (auto recommended - tries Google CSE first, falls back to SerpAPI)
# Options: auto, google-cse, serpapi
FH_SEARCH_PROVIDER=auto
# FH_SEARCH_ENABLED=true  # (default: true - uncomment only to disable)
FH_SEARCH_MAX_RESULTS=6

# Google Custom Search Engine (recommended - faster, cheaper)
GOOGLE_CSE_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_CSE_ID=PASTE_YOUR_CSE_ID_HERE

# SerpAPI (fallback)
SERPAPI_API_KEY=PASTE_YOUR_KEY_HERE

# Date restriction for searches (optional)
# Options: d (day), w (week), m (month), y (year), empty for no restriction
# Note: Only applied to recency-sensitive topics unless set globally
# FH_SEARCH_DATE_RESTRICT=y

# Domain whitelist (optional - restricts searches to authoritative domains)
# WARNING: Too restrictive may reduce claim investigation depth
# Basic whitelist:
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,reuters.com,apnews.com,bbc.com
# Extended whitelist (more comprehensive):
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,oecd.org,worldbank.org,imf.org,un.org,reuters.com,apnews.com,bbc.com,nature.com,science.org,nejm.org,thelancet.com,arxiv.org

# =============================================================================
# Analysis Configuration (AFFECTS NUMBER OF CLAIMS INVESTIGATED)
# =============================================================================
# Analysis mode: quick (faster, cheaper) | deep (more thorough)
# quick: 4 iterations, 12 sources max, 6 facts minimum
# deep:  5 iterations, 20 sources max, 12 facts minimum
# Impact: Deep mode allows more claims to be fully researched
# WARNING (v2.6.39): Deep mode costs ~2-3x more than quick mode but yields higher quality
FH_ANALYSIS_MODE=deep

# Allow LLM to use its training knowledge (not just web sources)
# Setting to false requires evidence for all claims (stricter, may reduce claim count)
# Default: false - Setting to true for more comprehensive analysis
FH_ALLOW_MODEL_KNOWLEDGE=true

# Deterministic mode - Use true for reproducible outputs; false for more variation
# true = temperature 0 (recommended for testing and consistency)
# false = allows sampling (may find more creative connections)
# FH_DETERMINISTIC=true  # (default: true - uncomment only to disable)

# Report style: standard (clean), rich (detailed markdown - NOT IMPLEMENTED)
# FH_REPORT_STYLE=standard  # (default: standard)

# Scope deduplication threshold (0-1, higher = stricter deduplication)
# Lower values = more scopes detected = more claims investigated
# 0.85 = default (merges similar contexts)
# 0.70 = balanced (more scopes)
# 0.50 = aggressive (finds more distinct contexts)
FH_SCOPE_DEDUP_THRESHOLD=0.70

# =============================================================================
# Budget Controls (DIRECTLY AFFECTS CLAIM INVESTIGATION DEPTH)
# =============================================================================
# WARNING: These settings were root cause of Jan 2026 quality regression
# Too strict limits = fewer claims investigated, lower confidence scores
# See: Docs/STATUS/HISTORY.md - "Quality Regression (January 13-19, 2026)"

# Max research iterations per scope
# Default: 5 (v2.8.2 increased from 3 after quality issues)
# Impact: Each claim needs multiple iterations to gather sufficient evidence
# FH_MAX_ITERATIONS_PER_SCOPE=5  # (default: 5)

# Max total iterations across all scopes
# Default: 20 (v2.8.2 increased from 12 after quality regression)
# Impact: With 2 scopes and per-scope limit of 5, you get max 10 iterations total
# FH_MAX_TOTAL_ITERATIONS=20  # (default: 20)

# Max tokens per analysis
# Default: 750000 (750K) - ~$2.25 max cost at Claude rates
# Impact: Running out of tokens stops research early
# FH_MAX_TOTAL_TOKENS=750000  # (default: 750000)

# Enforce hard budget limits
# Default: true = strict enforcement (stops at limits)
# false = soft limits (allows exceeding for important claims - recommended for quality)
FH_ENFORCE_BUDGETS=false

# =============================================================================
# Quality Gates (AFFECTS WHICH CLAIMS ARE INVESTIGATED)
# =============================================================================
# Gate 1: Claim Validation - filters claims before research
# These thresholds are hardcoded in quality-gates.ts but documented here:
#
# Opinion threshold: Claims with >30% opinion content are filtered
# Specificity threshold: Claims with <30% specificity are filtered
# Central claims: Always kept regardless of thresholds
#
# Impact: Stricter gates = fewer claims researched = lower analysis cost
#         Looser gates = more claims = more thorough but expensive
#
# Note: Currently not configurable via env vars, but can be modified in:
#       apps/web/src/lib/analyzer/quality-gates.ts

# Gate 4: Verdict Confidence - requires minimum evidence
# HIGH tier: >= 3 sources, >= 5 facts, >= 100 chars reasoning
# MEDIUM tier: >= 2 sources, >= 3 facts, >= 50 chars reasoning  
# LOW tier: >= 1 source, >= 1 fact
# INSUFFICIENT: Below LOW tier thresholds
#
# These are hardcoded but affect which claims get sufficient investigation

# =============================================================================
# Pipeline Selection
# =============================================================================
# Default pipeline variant: orchestrated | monolithic_canonical | monolithic_dynamic
# orchestrated: Traditional staged pipeline (highest quality, slowest)
# monolithic_canonical: LLM tool-loop with canonical output (faster, experimental)
# monolithic_dynamic: Flexible LLM-defined output (fastest, most experimental)
# 
# Note: User can override per-job in UI
# FH_DEFAULT_PIPELINE_VARIANT=orchestrated

# =============================================================================
# Debug Options (development only)
# =============================================================================
# Enable debug logging to file (shows detailed analysis decisions)
# FH_DEBUG_LOG_FILE=true  # (default: true - uncomment only to disable)
FH_DEBUG_LOG_PATH=./debug-analyzer.log
# FH_DEBUG_LOG_CLEAR_ON_START=false  # (default: false)

# =============================================================================
# Metrics and Testing (v2.8.1 infrastructure - not yet integrated)
# =============================================================================
# Enable metrics collection (requires integration in analyzer.ts)
# FH_METRICS_ENABLED=false  # (default: false)

# Use optimized prompts for testing (v2.8 provider-specific)
# WARNING: Never validated with real API calls
# FH_USE_OPTIMIZED_PROMPTS=false

# =============================================================================
# Source Reliability (LLM-powered evaluation)
# =============================================================================
# Evaluates source reliability using LLM with optional multi-model consensus.
# Primary: Claude 3.5 Haiku, Secondary: Configurable via FH_SR_OPENAI_MODEL
# See: Docs/ARCHITECTURE/Source_Reliability.md 
 
# Enable/disable source reliability scoring 
# FH_SR_ENABLED=true  # (default: true - uncomment only to disable)
 
# Multi-model consensus (Claude + OpenAI) - reduces hallucination risk
# Requires both ANTHROPIC_API_KEY and OPENAI_API_KEY to be set
# FH_SR_MULTI_MODEL=true  # (default: true - uncomment only to disable)

# OpenAI model for refinement (default: gpt-4o)
# Options: gpt-4o (quality), gpt-4o-mini (cost savings ~15x cheaper)
FH_SR_OPENAI_MODEL=gpt-4o-mini 
 
# Confidence threshold - minimum confidence to accept a score (0.5-0.95)
# Lower values accept more scores but with less certainty
# FH_SR_CONFIDENCE_THRESHOLD=0.8  # (default: 0.8)
 
# Consensus threshold - max score diff between models (0.05-0.30) 
# FH_SR_CONSENSUS_THRESHOLD=0.20  # (default: 0.20)
 
# Default score for unknown sources (0.0-1.0)
# 0.5 = neutral (center of symmetric scale)
# FH_SR_DEFAULT_SCORE=0.5  # (default: 0.5)
 
# Cache settings 
# FH_SR_CACHE_TTL_DAYS=90  # (default: 90)
FH_SR_CACHE_PATH=./source-reliability.db 
 
# Importance filter - skip blogs/spam TLDs (60%% cost savings) 
# FH_SR_FILTER_ENABLED=true  # (default: true - uncomment only to disable)
# FH_SR_SKIP_PLATFORMS=blogspot.,wordpress.com,medium.com,substack.com 
# FH_SR_SKIP_TLDS=xyz,top,club,icu,buzz,tk,ml,ga,cf,gq 
 
# Rate limiting 
# FH_SR_RATE_LIMIT_PER_IP=10  # (default: 10)
# FH_SR_RATE_LIMIT_DOMAIN_COOLDOWN=60  # (default: 60)

# =============================================================================
# CONFIGURATION PRESETS (uncomment to use)
# =============================================================================

# --- PRESET: Maximum Quality (thorough, expensive) ---
# Recommended for: Important analyses, baseline testing, quality validation
# FH_ANALYSIS_MODE=deep
# FH_MAX_ITERATIONS_PER_SCOPE=5
# FH_MAX_TOTAL_ITERATIONS=20
# FH_MAX_TOTAL_TOKENS=750000
# FH_ENFORCE_BUDGETS=false
# FH_ALLOW_MODEL_KNOWLEDGE=false
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=off
# Expected: More claims investigated, higher confidence, 2-3x cost

# --- PRESET: Balanced (good quality, reasonable cost) ---
# Recommended for: Regular use, most analyses
# FH_ANALYSIS_MODE=quick
# FH_MAX_ITERATIONS_PER_SCOPE=4
# FH_MAX_TOTAL_ITERATIONS=15
# FH_MAX_TOTAL_TOKENS=750000
# FH_ENFORCE_BUDGETS=false
# FH_ALLOW_MODEL_KNOWLEDGE=false
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=on
# Expected: Good claim coverage, reasonable confidence, moderate cost

# --- PRESET: Cost Optimized (faster, cheaper, lower quality) ---
# Recommended for: Testing, rapid iteration, high-volume processing
# FH_ANALYSIS_MODE=quick
# FH_MAX_ITERATIONS_PER_SCOPE=3
# FH_MAX_TOTAL_ITERATIONS=12
# FH_MAX_TOTAL_TOKENS=500000
# FH_ENFORCE_BUDGETS=true
# FH_ALLOW_MODEL_KNOWLEDGE=true
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=on
# Expected: Fewer claims investigated, lower confidence, 50-70% cost savings

# =============================================================================
# TROUBLESHOOTING
# =============================================================================
# 
# Problem: Too few claims investigated
# Solution: Increase FH_MAX_ITERATIONS_PER_SCOPE to 5
#          Increase FH_MAX_TOTAL_ITERATIONS to 20
#          Set FH_ENFORCE_BUDGETS=false
#          Set FH_ANALYSIS_MODE=deep
#
# Problem: Analysis too expensive
# Solution: Enable FH_LLM_TIERING=on (50-70% savings)
#          Decrease FH_MAX_TOTAL_ITERATIONS to 12
#          Set FH_ENFORCE_BUDGETS=true
#          Set FH_ANALYSIS_MODE=quick
#
# Problem: Low confidence scores
# Solution: Same as "too few claims" above
#          Also check FH_SEARCH_ENABLED=true
#          Remove FH_SEARCH_DOMAIN_WHITELIST if too restrictive
#
# Problem: Input neutrality issues (question vs statement different results)
# Solution: Ensure FH_DETERMINISTIC=true
#          This is also affected by LLM behavior - see Known Issues
#
# See: Docs/STATUS/KNOWN_ISSUES.md for complete troubleshooting guide
# See: Docs/STATUS/HISTORY.md for quality regression details
