# FactHarbor Environment Variables
# These values must match the API configuration in appsettings.Development.json
# Copy this file to .env.local and update with your actual keys

# =============================================================================
# API Configuration
# =============================================================================
FH_API_BASE_URL=http://localhost:5000

# Keys for internal calls (must match API's appsettings.Development.json)
FH_ADMIN_KEY=DEV_SHARED_SECRET_ADMIN_KEY
FH_INTERNAL_RUNNER_KEY=DEV_SHARED_SECRET_RUNNER_KEY

# Max concurrent analysis jobs
FH_RUNNER_MAX_CONCURRENCY=4

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Set which LLM provider to use (anthropic recommended for best results)
# Options: anthropic, openai, google, mistral
LLM_PROVIDER=anthropic
# LLM_PROVIDER=openai
# LLM_PROVIDER=google
# LLM_PROVIDER=mistral

# API Keys - set the key for your chosen provider
OPENAI_API_KEY=PASTE_YOUR_KEY_HERE
ANTHROPIC_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_GENERATIVE_AI_API_KEY=PASTE_YOUR_KEY_HERE
MISTRAL_API_KEY=PASTE_YOUR_KEY_HERE

# LLM fallback order (comma-separated, optional)
# If primary provider fails, try these in order
# FH_LLM_FALLBACKS=openai,anthropic,google,mistral

# =============================================================================
# LLM Tiering (RECOMMENDED for cost optimization)
# =============================================================================
# Enable tiered model selection - uses cheaper models for simple tasks
# Options: on, off (default: off)
# Savings: 50-70% cost reduction with minimal quality impact
FH_LLM_TIERING=on

# Per-task model overrides (when tiering is on)
# Understanding claims: cheaper model is fine
FH_MODEL_UNDERSTAND=claude-3-5-haiku-20241022
# Extracting facts: cheaper model is fine
FH_MODEL_EXTRACT_FACTS=claude-3-5-haiku-20241022
# Final verdict: use best model for accuracy
FH_MODEL_VERDICT=claude-sonnet-4-20250514

# =============================================================================
# Web Search Configuration
# =============================================================================
# Search provider (auto recommended - tries Google CSE first, falls back to SerpAPI)
# Options: auto, google-cse, serpapi
FH_SEARCH_PROVIDER=auto
FH_SEARCH_ENABLED=true
FH_SEARCH_MAX_RESULTS=6

# Google Custom Search Engine (recommended - faster, cheaper)
GOOGLE_CSE_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_CSE_ID=PASTE_YOUR_CSE_ID_HERE

# SerpAPI (fallback)
SERPAPI_API_KEY=PASTE_YOUR_KEY_HERE

# Date restriction for searches (optional)
# Options: d (day), w (week), m (month), y (year), empty for no restriction
# Note: Only applied to recency-sensitive topics unless set globally
# FH_SEARCH_DATE_RESTRICT=y

# Domain whitelist (optional - restricts searches to authoritative domains)
# WARNING: Too restrictive may reduce claim investigation depth
# Basic whitelist:
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,reuters.com,apnews.com,bbc.com
# Extended whitelist (more comprehensive):
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,oecd.org,worldbank.org,imf.org,un.org,reuters.com,apnews.com,bbc.com,nature.com,science.org,nejm.org,thelancet.com,arxiv.org

# =============================================================================
# Analysis Configuration (AFFECTS NUMBER OF CLAIMS INVESTIGATED)
# =============================================================================
# Analysis mode: quick (faster, cheaper) | deep (more thorough)
# quick: 4 iterations, 12 sources max, 6 facts minimum
# deep:  5 iterations, 20 sources max, 12 facts minimum
# Impact: Deep mode allows more claims to be fully researched
FH_ANALYSIS_MODE=quick

# Allow LLM to use its training knowledge (not just web sources)
# Setting to false requires evidence for all claims (stricter, may reduce claim count)
FH_ALLOW_MODEL_KNOWLEDGE=false

# Deterministic mode - Use true for reproducible outputs; false for more variation
# true = temperature 0 (recommended for testing and consistency)
# false = allows sampling (may find more creative connections)
FH_DETERMINISTIC=true

# Report style: standard (clean), rich (detailed markdown - NOT IMPLEMENTED)
FH_REPORT_STYLE=standard

# Scope deduplication threshold (0-1, higher = stricter deduplication)
# Lower values = more scopes detected = more claims investigated
# 0.70 = balanced (default)
# 0.50 = more scopes (finds more distinct contexts)
# 0.85 = fewer scopes (merges similar contexts)
FH_SCOPE_DEDUP_THRESHOLD=0.70

# =============================================================================
# Budget Controls (DIRECTLY AFFECTS CLAIM INVESTIGATION DEPTH)
# =============================================================================
# WARNING: These settings were root cause of Jan 2026 quality regression
# Too strict limits = fewer claims investigated, lower confidence scores
# See: Docs/STATUS/HISTORY.md - "Quality Regression (January 13-19, 2026)"

# Max research iterations per scope
# Default: 3 (v2.8.2), was causing quality issues when too low
# Recommended: 5 for thorough analysis, 3 for cost control
# Impact: Each claim needs multiple iterations to gather sufficient evidence
FH_MAX_ITERATIONS_PER_SCOPE=5

# Max total iterations across all scopes
# Default: 12, increased to 20 in v2.8.2 after quality regression
# Recommended: 20 for multi-scope analyses, 12 for single-scope
# Impact: With 2 scopes and per-scope limit of 3, you get max 6 iterations total
#         This was limiting research from 16 searches down to 9
FH_MAX_TOTAL_ITERATIONS=20

# Max tokens per analysis
# Default: 500000 (500K), increased to 750K recommended
# Impact: Running out of tokens stops research early
FH_MAX_TOTAL_TOKENS=750000

# Enforce hard budget limits
# true = strict enforcement (stops at limits, may reduce quality)
# false = soft limits (allows exceeding for important claims)
# Recommended: false during testing, true for production cost control
FH_ENFORCE_BUDGETS=false

# =============================================================================
# Quality Gates (AFFECTS WHICH CLAIMS ARE INVESTIGATED)
# =============================================================================
# Gate 1: Claim Validation - filters claims before research
# These thresholds are hardcoded in quality-gates.ts but documented here:
#
# Opinion threshold: Claims with >30% opinion content are filtered
# Specificity threshold: Claims with <30% specificity are filtered
# Central claims: Always kept regardless of thresholds
#
# Impact: Stricter gates = fewer claims researched = lower analysis cost
#         Looser gates = more claims = more thorough but expensive
#
# Note: Currently not configurable via env vars, but can be modified in:
#       apps/web/src/lib/analyzer/quality-gates.ts

# Gate 4: Verdict Confidence - requires minimum evidence
# HIGH tier: >= 3 sources, >= 5 facts, >= 100 chars reasoning
# MEDIUM tier: >= 2 sources, >= 3 facts, >= 50 chars reasoning  
# LOW tier: >= 1 source, >= 1 fact
# INSUFFICIENT: Below LOW tier thresholds
#
# These are hardcoded but affect which claims get sufficient investigation

# =============================================================================
# Pipeline Selection
# =============================================================================
# Default pipeline variant: orchestrated | monolithic_canonical | monolithic_dynamic
# orchestrated: Traditional staged pipeline (highest quality, slowest)
# monolithic_canonical: LLM tool-loop with canonical output (faster, experimental)
# monolithic_dynamic: Flexible LLM-defined output (fastest, most experimental)
# 
# Note: User can override per-job in UI
# FH_DEFAULT_PIPELINE_VARIANT=orchestrated

# =============================================================================
# Debug Options (development only)
# =============================================================================
# Enable debug logging to file (shows detailed analysis decisions)
FH_DEBUG_LOG_FILE=true
FH_DEBUG_LOG_PATH=./debug-analyzer.log
FH_DEBUG_LOG_CLEAR_ON_START=false

# =============================================================================
# Metrics and Testing (v2.8.1 infrastructure - not yet integrated)
# =============================================================================
# Enable metrics collection (requires integration in analyzer.ts)
FH_METRICS_ENABLED=false

# Use optimized prompts for testing (v2.8 provider-specific)
# WARNING: Never validated with real API calls
# FH_USE_OPTIMIZED_PROMPTS=false

# ============================================================================= 
# Source Reliability (v2.6.34+ LLM-powered evaluation) 
# ============================================================================= 
# Evaluates source reliability using LLM with optional multi-model consensus. 
# See: Docs/ARCHITECTURE/Source_Reliability.md 
 
# Enable/disable source reliability scoring 
FH_SR_ENABLED=true 
 
# Multi-model consensus (Claude + GPT-4) - reduces hallucination risk 
# Requires both ANTHROPIC_API_KEY and OPENAI_API_KEY to be set 
FH_SR_MULTI_MODEL=true 
 
# Confidence threshold (0.5-0.95) 
FH_SR_CONFIDENCE_THRESHOLD=0.65 
 
# Consensus threshold - max score diff between models (0.05-0.30) 
FH_SR_CONSENSUS_THRESHOLD=0.15 
 
# Spread multiplier - amplifies deviation from neutral (1.0-2.0)
# Higher = more differentiation between high/low reliability sources
FH_SR_SPREAD_MULTIPLIER=1.3


# Consensus spread multiplier - extra spread when models agree (1.0-1.5)
# Higher = more verdict impact from consensus-backed scores
FH_SR_CONSENSUS_SPREAD_MULTIPLIER=1.1
# Default score for unknown sources (0.0-1.0)
# 0.5 = neutral (center of symmetric scale)
FH_SR_DEFAULT_SCORE=0.5
 
# Cache settings 
FH_SR_CACHE_TTL_DAYS=90 
FH_SR_CACHE_PATH=./source-reliability.db 
 
# Importance filter - skip blogs/spam TLDs (60%% cost savings) 
FH_SR_FILTER_ENABLED=true 
# FH_SR_SKIP_PLATFORMS=blogspot.,wordpress.com,medium.com,substack.com 
# FH_SR_SKIP_TLDS=xyz,top,club,icu,buzz,tk,ml,ga,cf,gq 
 
# Rate limiting 
FH_SR_RATE_LIMIT_PER_IP=10 
FH_SR_RATE_LIMIT_DOMAIN_COOLDOWN=60

# =============================================================================
# CONFIGURATION PRESETS (uncomment to use)
# =============================================================================

# --- PRESET: Maximum Quality (thorough, expensive) ---
# Recommended for: Important analyses, baseline testing, quality validation
# FH_ANALYSIS_MODE=deep
# FH_MAX_ITERATIONS_PER_SCOPE=5
# FH_MAX_TOTAL_ITERATIONS=20
# FH_MAX_TOTAL_TOKENS=750000
# FH_ENFORCE_BUDGETS=false
# FH_ALLOW_MODEL_KNOWLEDGE=false
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=off
# Expected: More claims investigated, higher confidence, 2-3x cost

# --- PRESET: Balanced (good quality, reasonable cost) ---
# Recommended for: Regular use, most analyses
# FH_ANALYSIS_MODE=quick
# FH_MAX_ITERATIONS_PER_SCOPE=4
# FH_MAX_TOTAL_ITERATIONS=15
# FH_MAX_TOTAL_TOKENS=750000
# FH_ENFORCE_BUDGETS=false
# FH_ALLOW_MODEL_KNOWLEDGE=false
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=on
# Expected: Good claim coverage, reasonable confidence, moderate cost

# --- PRESET: Cost Optimized (faster, cheaper, lower quality) ---
# Recommended for: Testing, rapid iteration, high-volume processing
# FH_ANALYSIS_MODE=quick
# FH_MAX_ITERATIONS_PER_SCOPE=3
# FH_MAX_TOTAL_ITERATIONS=12
# FH_MAX_TOTAL_TOKENS=500000
# FH_ENFORCE_BUDGETS=true
# FH_ALLOW_MODEL_KNOWLEDGE=true
# FH_DETERMINISTIC=true
# FH_LLM_TIERING=on
# Expected: Fewer claims investigated, lower confidence, 50-70% cost savings

# =============================================================================
# TROUBLESHOOTING
# =============================================================================
# 
# Problem: Too few claims investigated
# Solution: Increase FH_MAX_ITERATIONS_PER_SCOPE to 5
#          Increase FH_MAX_TOTAL_ITERATIONS to 20
#          Set FH_ENFORCE_BUDGETS=false
#          Set FH_ANALYSIS_MODE=deep
#
# Problem: Analysis too expensive
# Solution: Enable FH_LLM_TIERING=on (50-70% savings)
#          Decrease FH_MAX_TOTAL_ITERATIONS to 12
#          Set FH_ENFORCE_BUDGETS=true
#          Set FH_ANALYSIS_MODE=quick
#
# Problem: Low confidence scores
# Solution: Same as "too few claims" above
#          Also check FH_SEARCH_ENABLED=true
#          Remove FH_SEARCH_DOMAIN_WHITELIST if too restrictive
#
# Problem: Input neutrality issues (question vs statement different results)
# Solution: Ensure FH_DETERMINISTIC=true
#          This is also affected by LLM behavior - see Known Issues
#
# See: Docs/STATUS/KNOWN_ISSUES.md for complete troubleshooting guide
# See: Docs/STATUS/HISTORY.md for quality regression details
