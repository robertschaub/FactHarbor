# FactHarbor Environment Variables
# These values must match the API configuration in appsettings.Development.json
# Copy this file to .env.local and update with your actual keys

# =============================================================================
# API Configuration
# =============================================================================
FH_API_BASE_URL=http://localhost:5000

# Keys for internal calls (must match API's appsettings.Development.json)
FH_ADMIN_KEY=DEV_SHARED_SECRET_ADMIN_KEY
FH_INTERNAL_RUNNER_KEY=DEV_SHARED_SECRET_RUNNER_KEY

# Max concurrent analysis jobs
FH_RUNNER_MAX_CONCURRENCY=4

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Set which LLM provider to use (anthropic recommended for best results)
# Options: anthropic, openai, google, mistral
LLM_PROVIDER=anthropic
# LLM_PROVIDER=google
# LLM_PROVIDER=mistral

# API Keys - set the key for your chosen provider
OPENAI_API_KEY=PASTE_YOUR_KEY_HERE
ANTHROPIC_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_GENERATIVE_AI_API_KEY=PASTE_YOUR_KEY_HERE
MISTRAL_API_KEY=PASTE_YOUR_KEY_HERE

# LLM fallback order (comma-separated, optional)
# If primary provider fails, try these in order
# FH_LLM_FALLBACKS=openai,anthropic,google,mistral

# =============================================================================
# LLM Tiering (RECOMMENDED for cost optimization)
# =============================================================================
# Enable tiered model selection - uses cheaper models for simple tasks
# Options: on, off (default: off)
FH_LLM_TIERING=on

# Per-task model overrides (when tiering is on)
# Understanding claims: cheaper model is fine
FH_MODEL_UNDERSTAND=claude-3-5-haiku-20241022
# Extracting facts: cheaper model is fine
FH_MODEL_EXTRACT_FACTS=claude-3-5-haiku-20241022
# Final verdict: use best model for accuracy
FH_MODEL_VERDICT=claude-sonnet-4-20250514

# =============================================================================
# Web Search Configuration
# =============================================================================
# Search provider (auto recommended - tries Google CSE first, falls back to SerpAPI)
# Options: auto, google-cse, serpapi
FH_SEARCH_PROVIDER=auto
FH_SEARCH_ENABLED=true
FH_SEARCH_MAX_RESULTS=6

# Google Custom Search Engine (recommended - faster, cheaper)
GOOGLE_CSE_API_KEY=PASTE_YOUR_KEY_HERE
GOOGLE_CSE_ID=PASTE_YOUR_CSE_ID_HERE

# SerpAPI (fallback)
SERPAPI_API_KEY=PASTE_YOUR_KEY_HERE

# Date restriction for searches
# Options: d (day), w (week), m (month), y (year), empty for no restriction
# FH_SEARCH_DATE_RESTRICT=y

# Domain whitelist (optional - restricts searches to authoritative domains)
# Basic whitelist:
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,reuters.com,apnews.com,bbc.com
# Extended whitelist (more comprehensive):
# FH_SEARCH_DOMAIN_WHITELIST=who.int,cdc.gov,nih.gov,ec.europa.eu,oecd.org,worldbank.org,imf.org,un.org,reuters.com,apnews.com,bbc.com,nature.com,science.org,nejm.org,thelancet.com,arxiv.org

# =============================================================================
# Analysis Configuration
# =============================================================================
# Report style: structured (clean JSON), rich (detailed markdown)
FH_REPORT_STYLE=rich

# Allow LLM to use its training knowledge (not just web sources)
FH_ALLOW_MODEL_KNOWLEDGE=true

# Deterministic mode - Use true for reproducible outputs; false for more variation.
FH_DETERMINISTIC=false

# Analysis mode: quick (default), deep (more iterations)
# FH_ANALYSIS_MODE=quick

# Scope deduplication threshold (0-1, higher = stricter)
FH_SCOPE_DEDUP_THRESHOLD=0.70

# =============================================================================
# Budget Controls (protects against runaway costs)
# =============================================================================
# These apply to BOTH orchestrated and monolithic pipelines

# Max research iterations per scope (default: 3)
# FH_MAX_ITERATIONS_PER_SCOPE=3

# Max total iterations across all scopes (default: 12)
# FH_MAX_TOTAL_ITERATIONS=12

# Max tokens per analysis (default: 500000)
# FH_MAX_TOTAL_TOKENS=500000

# Enforce hard budget limits (default: true)
# FH_ENFORCE_BUDGETS=true

# =============================================================================
# Debug Options (development only)
# =============================================================================
# Enable debug logging to file
# FH_DEBUG_LOG_FILE=true
# FH_DEBUG_LOG_PATH=./debug.log
# FH_DEBUG_LOG_CLEAR_ON_START=false

# =============================================================================
# Source Bundle (experimental - currently disabled)
# =============================================================================
# Path to pre-loaded source bundle (see Docs/ARCHITECTURE/Source_Reliability.md)
# FH_SOURCE_BUNDLE_PATH=./source-bundle.json
# FH_SOURCE_BUNDLE_MAX_SOURCES=6
# FH_SOURCE_BUNDLE_EXCERPT_CHARS=1200

# Public dataset URL(s) for dynamic source scores (CSV or JSON)
# FH_SOURCE_BUNDLE_URLS=https://raw.githubusercontent.com/dk3500/mbfc-data/main/mbfc.json
# FH_SOURCE_BUNDLE_FETCH=false
# Optional SHA-256 checksum for bundle content integrity
# FH_SOURCE_BUNDLE_SHA256=
