= POC1: Specification vs. Implementation Analysis =

**Date:** January 2, 2026\\
**Specification Source:** FactHarbor Spec and Impl 1.Jan.26.xar (xWiki export)\\
**Implementation Version:** Current codebase (analyzer v2.6.17)\\
**Analyst:** Claude Code

{{info}}
**Historical Document (January 2026, v2.6.17).** Many gaps identified here have since been resolved ‚Äî see [[POC to Alpha Transition>>FactHarbor.Roadmap.POC to Alpha Transition.WebHome]] for current status (v2.10.2). Key changes: AnalysisContexts fully implemented, 7-point verdict scale adopted, LLM tiering enabled, evidence quality filtering added.
{{/info}}

----

== Executive Summary ==

This document analyzes the current FactHarbor implementation against the POC1 specification defined in the xWiki documentation. The analysis categorizes differences as **Improvements** (implementation exceeds spec), **Weak Points** (missing/incomplete vs. spec), and **Uncertain** (requiring discussion).

**Key Findings:**

* (% class="success" %)‚úÖ **Significant improvements**(%%) in analysis sophistication (7-point truth scale, pseudoscience detection)
* (% class="error" %)‚ùå **Critical gaps**(%%) in quality validation (Gates 1 &amp; 4 not implemented)
* (% class="warning" %)‚ö†Ô∏è **Spec-compliant deferrals**(%%) (scenarios correctly postponed to POC2)
* üìä **Missing validation infrastructure** (quality metrics tracking required for POC1 success)

----

== Table of Contents ==

{{toc numbered="true" start="2"/}}

----

== (% class="success" %)Improvements (Implementation > Spec)(%%) ==

=== 1. Enhanced Truth Scale (7-Point Symmetric) ‚≠ê ===

**Specification Requirement:**

* POC1 uses basic 4-level scale: WELL-SUPPORTED, PARTIALLY-SUPPORTED, UNCERTAIN, REFUTED
* Source: {{code}}POC/Requirements.xml:170-197{{/code}}

**Current Implementation:**

* Professional 7-point symmetric scale centered on neutral (50%):

{{code language="none"}}
TRUE          (86-100%, +3)
MOSTLY-TRUE   (72-85%,  +2)
LEANING-TRUE  (58-71%,  +1)
UNVERIFIED    (43-57%,   0)
LEANING-FALSE (29-42%,  -1)
MOSTLY-FALSE  (15-28%,  -2)
FALSE         (0-14%,   -3)
{{/code}}

* Source: {{code}}apps/web/src/lib/analyzer.ts:484-599{{/code}}

**Impact:**

* More nuanced verdicts aligned with professional fact-checking standards
* Symmetric scale avoids bias (equal levels above/below neutral)
* Better user comprehension of confidence levels

**Assessment:** ‚≠ê (% class="success" %)**Significant Improvement**(%%) - Adds professional polish without blocking POC1 goals

----

=== 2. Pseudoscience Detection System ‚≠ê‚≠ê ===

**Specification Requirement:**

* Not mentioned in POC1 requirements

**Current Implementation:**

* Comprehensive pattern-matching system with 100+ patterns across categories:
** Water pseudoscience (memory, structuring, Grander, Emoto)
** Energy fields (chakra, aura, vital energy)
** Quantum misuse (quantum healing, consciousness)
** Homeopathy (potentization, succussion)
** Known pseudoscience brands
* Automatic verdict escalation (UNCERTAIN ‚Üí REFUTED when patterns + debunk sources found)
* Confidence-based recommendations (never FALSE without 99%+ certainty)
* Source: {{code}}apps/web/src/lib/analyzer.ts:176-479{{/code}}

**Example Detection:**

{{code language="typescript"}}
// Detects: "Structured water has memory and healing properties"
{
  isPseudoscience: true,
  confidence: 0.75,
  categories: ["waterMemory", "energyFields"],
  matchedPatterns: [/water\s*memory/i, /healing\s*properties/i],
  debunkIndicatorsFound: [/no\s*scientific\s*evidence/i],
  recommendation: "REFUTED"
}
{{/code}}

**Impact:**

* Proactively identifies debunked claims before full analysis
* Prevents spreading of anti-vaccine, homeopathy, energy healing claims
* Addresses major quality risk not in original spec

**Assessment:** ‚≠ê‚≠ê (% class="success" %)**Major Improvement**(%%) - Critical for credibility and harm prevention

----

=== 3. Claim Dependency Tracking ‚≠ê ===

**Specification Requirement:**

* Not mentioned in POC1

**Current Implementation:**

* Claims tagged with {{code}}claimRole{{/code}}: attribution/source/timing/core
* Dependency propagation: if prerequisite claim false ‚Üí dependent claims flagged
* Source: {{code}}apps/web/src/lib/analyzer.ts:11-12{{/code}}

**Example:**

{{code language="json"}}
{
  "claim": "Study shows 30% reduction",
  "claimRole": "core"
},
{
  "claim": "Published in Nature journal",
  "claimRole": "source",
  "dependsOn": "Study shows 30% reduction"
}
{{/code}}

If source claim is FALSE ‚Üí core claim verdict downgraded with explanation

**Impact:**

* Sophisticated logical analysis (if source unreliable, claim verdict affected)
* Prevents false claims based on misattributed sources

**Assessment:** ‚≠ê (% class="success" %)**Improvement**(%%) - Demonstrates advanced reasoning capability

----

=== 4. Advanced Configuration System ===

**Specification Requirement:**

* Basic environment configuration mentioned

**Current Implementation:**

* Comprehensive {{code}}FH_*{{/code}} prefixed environment variables:
** {{code}}FH_ANALYSIS_MODE{{/code}}: quick/deep (affects iterations, sources, article length)
** {{code}}FH_SEARCH_ENABLED{{/code}}: true/false
** {{code}}FH_SEARCH_PROVIDER{{/code}}: auto-detection from API keys (SerpAPI, Google CSE, Bing, Tavily, Brave)
** {{code}}FH_SEARCH_DOMAIN_WHITELIST{{/code}}: comma-separated trusted domains
** {{code}}FH_SOURCE_BUNDLE_PATH{{/code}}: custom source reliability data
** {{code}}FH_REPORT_STYLE{{/code}}: structured/rich
** {{code}}FH_ALLOW_MODEL_KNOWLEDGE{{/code}}: true/false (strict source-only mode)
* Source: {{code}}apps/web/src/lib/analyzer.ts:33-121{{/code}}

**Impact:**

* Production-ready configuration without code changes
* Easy A/B testing (quick vs deep mode)
* Security (domain whitelisting prevents malicious source injection)
* Flexibility for different deployment environments

**Assessment:** ‚≠ê (% class="success" %)**Improvement**(%%) - Production-quality configuration management

----

=== 5. Multi-LLM Provider Support (Exceeds Spec) ‚úÖ ===

**Specification Requirement:**

* NFR-POC-11: LLM abstraction layer required (POC/Requirements.xml:1411-1457)
* Primary provider: Anthropic Claude
* Future: Secondary providers with failover

**Current Implementation:**

* **Full implementation** supporting 4 providers:
** Anthropic Claude (Sonnet, Haiku)
** OpenAI GPT
** Google Gemini
** Mistral
* Provider selection via {{code}}LLM_PROVIDER{{/code}} environment variable
* Source: {{code}}apps/web/src/lib/analyzer.ts:19-23{{/code}}

**Impact:**

* ‚úÖ Vendor independence (no lock-in)
* ‚úÖ Resilience (switch providers if outage)
* ‚úÖ Cost optimization (use cheaper models for extraction, quality for analysis)

**Assessment:** (% class="success" %)‚úÖ **Exceeds Specification**(%%) - NFR-POC-11 fully satisfied

----

=== 6. Article-Level Verdict Analysis (Experimental Feature Success) ‚úÖ ===

**Specification Requirement:**

* Listed as "Experimental" in POC1 (Roadmap/POC1.xml:64-86)
* Goal: Test if AI can detect when article credibility ‚â† claim average
* Success criteria: ‚â•70% accuracy on 30-article test set
* If &lt;50% ‚Üí defer to POC2

**Current Implementation:**

* ‚úÖ Fully implemented in {{code}}ArticleVerdictBanner{{/code}} component
* Detects:
** Article's main thesis vs. supporting claims
** Central vs. peripheral claims
** Logical fallacies (correlation‚Üícausation, cherry-picking)
** Misleading framing (accurate facts, false conclusion)
* Source: {{code}}apps/web/src/components/ArticleVerdictBanner.tsx{{/code}}

**Example Detection:**

{{code}}
Article claims: "Coffee cures cancer"
Claims analyzed:
  ‚úÖ Coffee contains antioxidants (TRUE)
  ‚úÖ Antioxidants fight free radicals (MOSTLY-TRUE)
  ‚ùå Coffee cures cancer (FALSE - causal leap)

Article Verdict: MISLEADING
Reason: Makes unsupported medical claim despite citing accurate facts
{{/code}}

**Impact:**

* Successfully implemented experimental POC1 feature
* Addresses "Article Verdict Problem" (POC/Article-Verdict-Problem.xml)

**Assessment:** (% class="success" %)‚úÖ **Experimental Feature Success**(%%) - Ship in POC2 per spec decision tree

----

== (% class="error" %)Weak Points (Missing/Incomplete vs. Spec)(%%) ==

=== 1. Quality Gates Not Implemented üî¥ CRITICAL BLOCKER ===

**Specification Requirement:**

POC1 **MUST** implement 2 quality gates before displaying verdicts to users:

==== Gate 1: Claim Validation (Roadmap/POC1.xml:99-123, POC/Specification.xml:106-156) ====

**Required Checks:**

# **Factuality Test**: Can claim be verified with evidence?
# **Opinion Detection**: Contains hedging language? ("I think", "probably", "best")
# **Specificity Score**: Contains concrete details? (names, numbers, dates, locations)
# **Future Prediction Test**: About future events?

**Pass Criteria:**

{{code language="typescript"}}
{
  isFactual: true,
  opinionScore: ‚â§ 0.3,
  specificityScore: ‚â• 0.3,
  claimType: "FACTUAL"
}
{{/code}}

**Actions if Failed:**

* Flag as "Non-verifiable: Opinion/Prediction/Ambiguous"
* DO NOT generate scenarios or verdicts
* Display explanation to user

**Target:** 0% opinion statements processed as facts

==== Gate 4: Verdict Confidence Assessment (Roadmap/POC1.xml:124-158, POC/Specification.xml:159-206) ====

**Required Checks:**

# **Evidence Count**: Minimum 2 independent sources
# **Source Quality**: Average reliability ‚â• 0.6 (on 0-1 scale)
# **Evidence Agreement**: % supporting vs. contradicting ‚â• 0.6
# **Uncertainty Factors**: Count of hedging statements in reasoning

**Confidence Tiers:**

{{code}}
HIGH (80-100%):
  ‚â•3 sources, ‚â•0.7 avg quality, ‚â•80% agreement

MEDIUM (50-79%):
  ‚â•2 sources, ‚â•0.6 avg quality, ‚â•60% agreement

LOW (0-49%):
  ‚â•2 sources BUT low quality/agreement

INSUFFICIENT:
  <2 sources ‚Üí DO NOT PUBLISH
{{/code}}

**Publication Rule:** Minimum MEDIUM confidence required

**Target:** 0% verdicts published with &lt;2 sources

----

**Current Implementation:**

(% class="error" %)‚ùå **Not Implemented**(%%)

Evidence:

* No {{code}}ClaimValidationResult{{/code}} entity (spec: Data Model/WebHome.xml:344-360)
* No {{code}}VerdictValidationResult{{/code}} entity (spec: Data Model/WebHome.xml:363-379)
* No opinion score calculation in analyzer
* No specificity score (no concrete detail counting)
* No confidence tier assignment (HIGH/MEDIUM/LOW/INSUFFICIENT)
* No publication blocking for LOW/INSUFFICIENT verdicts
* Evidence gathering exists but not validated against thresholds

----

**Impact:**

(% class="error" %)üî¥ **POC1 Success Criteria Violated:**(%%)

From POC/Requirements.xml:218-233:

{{code}}
POC1 is considered SUCCESSFUL if:

‚úÖ Functional:
  ‚ùå Blocks all non-factual claims (0% pass through) - MISSING GATE 1
  ‚ùå Blocks all insufficient-evidence verdicts (0% with <2 sources) - MISSING GATE 4

‚úÖ Quality:
  ‚ùå 0 verdicts with <2 sources published - NOT ENFORCED
  ‚ùå 0 opinion statements published as facts - NOT ENFORCED
{{/code}}

From Roadmap/POC1.xml:24-26:

{{info}}
**Phase Goal:** Prove AKEL can produce credible, quality outputs **without manual intervention**

**Success Metric:** &lt;10% hallucination rate, **quality gates prevent low-confidence publications**
{{/info}}

**Specification Quote (POC/Requirements.xml:96):**

{{info}}
"AKEL must validate outputs before displaying to users. POC1 implements a **2-gate subset** of the full NFR11 framework."
{{/info}}

**Specification Quote (Roadmap/POC1.xml:99-100):**

{{warning}}
**Importance:** CRITICAL - Core POC1 Requirement\\
**Fulfills:** AI safety, credibility, prevents embarrassing failures
{{/warning}}

----

**Required Data Structures:**

{{code language="typescript"}}
// Missing from implementation
interface ClaimValidationResult {
  claimId: string;
  isFactual: boolean;
  opinionScore: number;        // 0-1
  specificityScore: number;    // 0-1
  futureOriented: boolean;
  claimType: "FACTUAL" | "OPINION" | "PREDICTION" | "AMBIGUOUS";
  passed: boolean;
  failureReason?: string;
  validatedAt: Date;
}

interface VerdictValidationResult {
  verdictId: string;
  evidenceCount: number;
  averageSourceQuality: number;     // 0-1
  evidenceAgreement: number;        // 0-1
  uncertaintyFactors: number;
  confidenceTier: "HIGH" | "MEDIUM" | "LOW" | "INSUFFICIENT";
  publishable: boolean;
  failureReasons?: string[];
  validatedAt: Date;
}
{{/code}}

----

**Assessment:** (% class="error" %)üî¥ **CRITICAL BLOCKER**(%%) - POC1 specification defines gates as **mandatory** for success

**Priority:** **P0 - Required for POC1 completion**

**Recommendation:** Implement both gates before declaring POC1 complete

----

=== 2. Missing Quality Metrics Tracking üî¥ CRITICAL ===

**Specification Requirement:**

POC1 requires quality metrics tracking for validation (POC/Specification.xml:382-405):

{{code language="typescript"}}
interface QualityMetric {
  metric_type: string;      // "ErrorRate", "ConfidenceScore", "ProcessingTime"
  category: string;         // "Politics", "Science", "Health"
  value: number;
  target: number;
  timestamp: Date;
}
{{/code}}

**Required Metrics:**

|= Metric |= Target |= Measurement Method
| Claims extracted per article | 5-15 | Automated count
| Claims passing Gate 1 | 60-80% | Automated count
| Verdicts passing Gate 4 | 60-80% | Automated count
| **Hallucination rate** | **&lt;10%** | **Manual review**
| Evidence accuracy | >90% | Manual verification
| User-reported issues | &lt;5% | Manual tracking

**Manual Quality Review Process (Required):**

From POC/Specification.xml:396-404:

{{code}}
1. Select random sample of 20 verdicts
2. Verify evidence sources are real and accurately quoted
3. Check verdict assessment matches evidence
4. Document any hallucinations or errors
5. Calculate quality metrics
6. Adjust thresholds if needed
{{/code}}

**POC1 Success Criteria (POC/Requirements.xml:1111-1122):**

{{code}}
Quality Definition:
  "Reasonable verdict" = Defensible given general knowledge
  "Coherent summary" = Logically structured, grammatically correct
  "Comprehensible" = Reviewers understand what analysis means

Thresholds:
  Claim Extraction:     ‚â•70% accuracy
  Verdict Logic:        ‚â•70% defensible
  Reasoning Clarity:    ‚â•70% clear
  Overall Analysis:     ‚â•70% useful

Analogy: "B student" quality (70-80%), not "A+" perfection yet
{{/code}}

----

**Current Implementation:**

(% class="error" %)‚ùå **Not Implemented**(%%)

Evidence:

* No {{code}}QualityMetric{{/code}} entity in database
* No quality dashboard
* No hallucination rate tracking
* No manual review process defined
* No quality score display in UI
* LLM usage tracked but not quality metrics

----

**Impact:**

(% class="error" %)üî¥ **Cannot Validate POC1 Success**(%%)

From POC/Requirements.xml:1083-1097:

{{code}}
Minimum Success (POC Passes):

Required for GO decision:
  ‚ùå Verdicts are reasonable (‚â•70% make logical sense) - CANNOT MEASURE
  ‚ùå Minimal or no manual editing needed (<30% require intervention) - CANNOT TRACK
  ‚úÖ Cost efficiency acceptable (<$0.05 USD target) - CAN ESTIMATE
  ‚ùå Hallucination rate <10% - NOT TRACKED
{{/code}}

**Specification Quote (POC/Requirements.xml:956):**

{{warning}}
**CRITICAL:** Unit economics must be viable for scaling decision!
{{/warning}}

**Without Quality Metrics:**

* Cannot determine if POC1 passes/fails
* Cannot make GO/NO-GO decision
* Cannot identify improvement opportunities
* Cannot validate hallucination rate &lt;10% (CRITICAL success metric)

----

**Assessment:** (% class="error" %)üî¥ **CRITICAL GAP**(%%) - Required for POC1 validation

**Priority:** **P0 - Blocking POC1 sign-off**

**Recommendation:**

# Implement {{code}}QualityMetric{{/code}} entity in database
# Create manual review process (20-verdict samples)
# Track hallucination rate
# Display quality scores in UI

----

=== 3. Missing Error Pattern Tracking ===

**Specification Requirement:**

{{code}}ErrorPattern{{/code}} entity for continuous improvement (Data Model/WebHome.xml:319-327):

{{code language="typescript"}}
interface ErrorPattern {
  error_category: string;    // "WrongSource", "Hallucination", "MissingEvidence"
  claim_id: string;
  description: string;
  root_cause: string;
  frequency: number;
  status: "OPEN" | "ANALYZING" | "FIXED" | "WONTFIX";
  created_at: Date;
  fixed_at?: Date;
}
{{/code}}

**Usage (Data Model/WebHome.xml:316-327):**

{{code}}
Error capture ‚Üí Pattern analysis ‚Üí Improvement workflow:
  Analyze ‚Üí Fix ‚Üí Test ‚Üí Deploy ‚Üí Re-process ‚Üí Monitor

Example:
  category: "WrongSource"
  description: "Unreliable tabloid cited"
  root_cause: "No quality check"
  frequency: 23
  status: "Fixed"

  ‚Üí Led to: Gate 4 implementation (source quality threshold)
{{/code}}

----

**Current Implementation:**

(% class="error" %)‚ùå **Not Implemented**(%%)

Evidence:

* No {{code}}ErrorPattern{{/code}} table
* No error categorization
* No systematic error tracking
* Errors logged to events but not analyzed for patterns

----

**Impact:**

* No structured learning from failures
* Cannot identify systematic weaknesses
* Cannot prioritize improvements based on frequency
* Missing feedback loop for system improvement

----

**Assessment:** (% class="warning" %)üü° **Gap**(%%) - Important for continuous improvement, lower priority than quality gates

**Priority:** **P2 - Defer to POC2**

**Recommendation:** Implement after Gates 1 &amp; 4 are working and producing error data to track

----

=== 4. Simplified Data Model (Acceptable for POC1) ===

**Specification Requirement:**

Full data model with 10 entities (Data Model/WebHome.xml:24-408):

# Claim
# Evidence
# Source (with track record)
# Scenario
# Verdict
# User
# Edit (version history)
# Flag (user reports)
# QualityMetric
# ErrorPattern

----

**Current Implementation:**

Minimal database schema ({{code}}apps/api/Data/Entities.cs{{/code}}):

{{code language="csharp"}}
// ‚úÖ JobEntity (job management)
public class JobEntity {
    public string JobId { get; set; }
    public string Status { get; set; }        // QUEUED/RUNNING/SUCCEEDED/FAILED
    public int Progress { get; set; }
    public DateTime CreatedUtc { get; set; }
    public DateTime UpdatedUtc { get; set; }
    public string InputType { get; set; }     // text/url
    public string InputValue { get; set; }
    public string InputPreview { get; set; }
    public string? ResultJson { get; set; }   // ‚ö†Ô∏è Stores full analysis as JSON blob
    public string? ReportMarkdown { get; set; }
}

// ‚úÖ JobEventEntity (progress tracking)
public class JobEventEntity {
    public int Id { get; set; }
    public string JobId { get; set; }
    public DateTime TsUtc { get; set; }
    public string Level { get; set; }         // info/warn/error
    public string Message { get; set; }
}

// ‚ùå No Claim table
// ‚ùå No Evidence table
// ‚ùå No Source table (no track record tracking)
// ‚ùå No Scenario table
// ‚ùå No Verdict table
// ‚ùå No User table (no authentication)
// ‚ùå No Edit table (no version history)
// ‚ùå No Flag table (no user feedback)
// ‚ùå No QualityMetric table
// ‚ùå No ErrorPattern table
{{/code}}

----

**Impact:**

**For POC1:**

* (% class="success" %)‚úÖ **Acceptable**(%%) - Spec allows POC1 simplifications (POC/Requirements.xml:315-341)
* ‚úÖ Stateless design works for proof-of-concept
* ‚úÖ Fast to implement and iterate

**Specification Quote (POC/Requirements.xml:336-341):**

{{code}}
POC Acceptable Simplifications:
  ‚úÖ Single AKEL call (not multi-component pipeline)
  ‚úÖ No scenarios (implicit in verdicts)
  ‚úÖ Basic evidence linking
  ‚úÖ 2 gates instead of 4
  ‚úÖ No review queue
{{/code}}

**For POC2/Beta:**

* (% class="error" %)‚ùå **Blocking**(%%) - Cannot implement:
** Source track record system (no Source table)
** Scenario generation (no Scenario table)
** Version history (no Edit table)
** User feedback (no Flag table)
** Quality metrics (no QualityMetric table)
** Claim reuse/search (no Claim table)

----

**Assessment:** (% class="warning" %)‚ö†Ô∏è **Acceptable for POC1, Blocking for POC2**(%%)

**Priority:** **P3 - Plan for POC2**

**Recommendation:**

* Keep simplified model for POC1 completion
* Design full schema before POC2 starts
* Migration path: Extract claims from {{code}}ResultJson{{/code}} ‚Üí populate Claim/Evidence/Source tables

----

=== 5. No Source Track Record System ===

**Specification Requirement:**

Sources must have reliability scores updated weekly (Data Model/WebHome.xml:56-171):

{{code language="typescript"}}
interface Source {
  id: string;
  name: string;                    // "New York Times"
  domain: string;                  // "nytimes.com"
  type: "NewsOutlet" | "AcademicJournal" | "GovernmentAgency";
  track_record_score: number;      // 0-100
  accuracy_history: object;        // Historical data
  correction_frequency: number;    // How often source publishes corrections
  last_updated: Date;
}
{{/code}}

**Scoring Process (Separation of Concerns):**

From Data Model/WebHome.xml:76-170:

{{code}}
CRITICAL: Prevent circular dependencies

Weekly Background Job (Sunday 2 AM):
  - Analyze all claims from past week
  - Calculate source accuracy (correct verdicts / total citations)
  - Update track_record_score
  - NEVER triggered by individual claim analysis

Real-Time Claim Analysis:
  - READ source scores (snapshot from last update)
  - NEVER WRITE source scores
  - Use scores to weight evidence

Benefits:
  ‚úÖ No circular dependencies
  ‚úÖ Predictable behavior
  ‚úÖ Clear audit trail
{{/code}}

----

**Current Implementation:**

(% class="warning" %)‚ö†Ô∏è **Partial Implementation**(%%)

Evidence:

* Can load source reliability from external bundle (MBFC)
* No database tracking
* No weekly update job
* No accuracy history
* No separation of concerns (no write protection)

----

**Assessment:** (% class="warning" %)üü° **Weak Point**(%%) - Important for quality, but acceptable for POC1

**Priority:** **P2 - Required for POC2**

**Recommendation:**

# POC1: Continue using static source bundle if available
# POC2: Implement full Source table with weekly update job
# Design: Follow spec's temporal separation pattern

----

=== 6. No Redis Caching Layer ===

**Specification Requirement:**

Redis cache for claim deduplication and cost savings (POC/Specification.xml:407-433):

**Cache Design:**

{{code}}
Key:   claim:v1norm1:{language}:{sha256(canonical_claim)}
Value: Complete ClaimAnalysis JSON (~15KB, ~5KB compressed)
TTL:   90 days
{{/code}}

**Projected Performance:**

{{code}}
Articles 0-100:      10% hit rate
Articles 100-1,000:  40% hit rate
Articles 1,000-10K:  70% hit rate (TARGET)
Articles 10K+:       80-90% hit rate
{{/code}}

**Cost Impact:**

{{code}}
70% hit rate: $0.16/article (break-even with monolithic)
80% hit rate: $0.11/article (27% savings)
90% hit rate: $0.07/article (53% savings)
{{/code}}

----

**Current Implementation:**

(% class="error" %)‚ùå **Not Implemented**(%%)

Evidence:

* No Redis configuration in codebase
* No claim canonicalization algorithm
* No cache layer in architecture
* Every claim analyzed from scratch (100% LLM calls)

----

**Cost Implications:**

|= Scenario |= Hit Rate |= Cost per Article |= Monthly Cost (10K articles)
| **No Cache (current)** | 0% | $0.20 | $2,000
| **With Cache (spec)** | 70% | $0.16 | $1,600
| **Optimized Cache** | 90% | $0.07 | $700
| **Savings Potential** | - | - | **$1,300/month (65%)**

----

**Assessment:** (% class="warning" %)üü° **Medium Priority**(%%) - Significant cost optimization missing

**Priority:** **P2 - Implement before scale**

**Recommendation:**

# POC1: Not required (small volume, optimization premature)
# POC2: Implement Redis caching before scaling beyond 1K articles/month
# Design: Follow spec's canonicalization algorithm

----

== (% class="warning" %)Uncertain (Need Discussion/Clarification)(%%) ==

=== 1. Scenario Implementation Strategy ‚ö†Ô∏è DECISION REQUIRED ===

**Your Statement:**

{{info}}
"Scenario is not implemented so far, and I consider to drop it."
{{/info}}

**Specification Position:**

From POC/Requirements.xml:57-88:

{{code}}
=== 1.2 Scenarios Deferred to POC2 ===

Intentional Simplification:

Scenarios are a core component of the full FactHarbor system
(Claims ‚Üí Scenarios ‚Üí Evidence ‚Üí Verdicts), but are deliberately
excluded from POC1.

Rationale:
  ‚Ä¢ POC1 tests: Can AI extract claims and generate verdicts?
  ‚Ä¢ POC2 will add: Scenario generation and management
  ‚Ä¢ Open questions remain: Should scenarios be separate entities?

Design Decision:
Prove basic AI capability first, then add scenario complexity
based on POC1 learnings.
{{/code}}

From Architecture/WebHome.xml:171-189:

{{code}}
Scenarios Purpose:
  Different interpretations or contexts for evaluating claims

Example for claim "Vaccines reduce hospitalization":
  ‚Ä¢ Scenario 1: Clinical trials (healthy adults 18-65, original strain)
  ‚Ä¢ Scenario 2: Real-world data (diverse population, Omicron variant)
  ‚Ä¢ Scenario 3: Immunocompromised patients
{{/code}}

----

**Uncertainty:**

ü§î **Does "drop scenario" mean:**

* **Option A:** Drop from POC1 only ((% class="success" %)‚úÖ spec-compliant(%%)
* **Option B:** Drop permanently from FactHarbor ((% class="error" %)‚ùå conflicts with core architecture(%%)

**Critical Questions:**

# **Scope Clarification:** Is scenario deferral temporary (POC1 ‚Üí POC2) or permanent?
# **Architecture Impact:** Without scenarios, how to handle context-dependent claims?
# **POC1 Decision Tree:** If scenarios dropped, what's the POC2 scope?

----

**Recommendation:**

(% class="success" %)‚úÖ **Keep Scenarios Deferred to POC2 (Spec-Compliant Path)**(%%)

**Rationale:**

# Specification **intentionally** defers scenarios to POC2 (Requirements:57-88)
# POC1 goal: Prove AI can extract claims + generate verdicts (baseline)
# POC2 goal: Add scenario complexity after validating baseline
# Deferral is **good engineering**: test hardest part first (Requirements:68-71)

**Action Items:**

# ‚úÖ **Complete POC1 without scenarios** (as spec intends)
# ‚úÖ **Validate POC1 success** (quality gates, metrics, 20-article test)
# ‚ö†Ô∏è **Plan POC2 with scenarios** (don't drop permanently)
# ü§î **Decide after POC1**: If scenarios add value or can be simplified

----

**Assessment:** (% class="warning" %)‚ö†Ô∏è **Needs Clarification**(%%) - Confirm if deferral or permanent removal

**Priority:** **P1 - Discuss before POC2 planning**

----

=== 2. Separated Architecture Implementation ===

**Your Statement:**

{{info}}
"I also consider to implement Separated_Architecture_Implementation_Guide.md"
{{/info}}

**Current Architecture:**

{{code}}
Monorepo Structure:
  apps/
    api/              ASP.NET Core (C#) - System of Record
      - JobService, JobController
      - SQLite database
      - SSE event streaming

    web/              Next.js (TypeScript) - AI Orchestrator + UI
      - analyzer.ts (AKEL logic)
      - API routes (/api/internal/run-job)
      - React components
      - LLM integration
{{/code}}

**Specification Architecture (Architecture/WebHome.xml:23-88):**

{{code}}
Three-Layer Architecture:

1. Interface Layer:
   - Web UI (React/Vue/Svelte)
   - REST API
   - Authentication & Authorization

2. Processing Layer:
   - AKEL Pipeline (AI-driven claim analysis)
   - LLM Abstraction Layer
   - Background Jobs

3. Data & Storage Layer:
   - PostgreSQL (primary database)
   - Redis (caching)
   - S3 (archival)
{{/code}}

----

**Uncertainty:**

ü§î **Questions to Clarify:**

# **What problems are you trying to solve?**
#* Is current architecture causing issues?
#* Performance bottlenecks?
#* Deployment constraints?
# **Separation Goals:**
#* Separate AI from web UI?
#* Separate API from AI orchestrator?
#* Microservices for scale?
# **Timing:**
#* Separate now (during POC1)?
#* Wait until POC2 (after validation)?

----

**Specification Guidance:**

From Architecture/WebHome.xml:152-158:

{{code}}
Design Philosophy: Start Simple, Evolve Based on Metrics

  ‚Ä¢ Single primary database (PostgreSQL handles most workloads initially)
  ‚Ä¢ Three clear layers (easy to understand and maintain)
  ‚Ä¢ Measure before optimizing (add complexity only when proven necessary)
{{/code}}

----

**Recommendation:**

(% class="warning" %)‚ö†Ô∏è **Discuss Before Implementing**(%%)

**Questions to Answer:**

# What specific problem does separation solve?
# Is current architecture blocking POC1 goals?
# What's the target architecture?
# When to implement (now, POC2, Beta)?

**Suggested Path:**

# ‚úÖ **POC1**: Keep current architecture (working, focus on quality gates)
# ü§î **POC2 Planning**: Evaluate if separation needed
# üìä **Metrics-Driven**: Separate only if current arch shows problems

**POC1 Focus:** Implement quality gates and metrics tracking, not architectural refactoring

----

**Assessment:** (% class="warning" %)‚ùì **Needs Discussion**(%%) - Clarify goals and timing

**Priority:** **P2 - Discuss during POC2 planning**

----

== Summary Matrix ==

|= Category |= Item |= Spec Status |= Current |= Gap |= Priority
| **Quality Gates** | Gate 1 (Claim Validation) | CRITICAL (POC1) | (% class="error" %)‚ùå Missing(%%) | (% class="error" %)üî¥ High(%%) | **P0**
| **Quality Gates** | Gate 4 (Verdict Confidence) | CRITICAL (POC1) | (% class="error" %)‚ùå Missing(%%) | (% class="error" %)üî¥ High(%%) | **P0**
| **Metrics** | Quality metrics tracking | CRITICAL (POC1) | (% class="error" %)‚ùå Missing(%%) | (% class="error" %)üî¥ High(%%) | **P0**
| **Metrics** | Hallucination rate | Required (&lt;10%) | (% class="error" %)‚ùå Missing(%%) | (% class="error" %)üî¥ High(%%) | **P0**
| **Truth Scale** | 7-point symmetric | Not specified | (% class="success" %)‚úÖ Implemented(%%) | (% class="success" %)‚úÖ Improvement(%%) | -
| **Pseudoscience** | Detection system | Not specified | (% class="success" %)‚úÖ Implemented(%%) | (% class="success" %)‚úÖ Improvement(%%) | -
| **LLM Abstraction** | Multi-provider | Required | (% class="success" %)‚úÖ Implemented(%%) | (% class="success" %)‚úÖ Exceeds(%%) | -
| **Article Analysis** | Context-aware | Experimental | (% class="success" %)‚úÖ Implemented(%%) | (% class="success" %)‚úÖ Success(%%) | -
| **Caching** | Redis cache | Recommended | (% class="error" %)‚ùå Missing(%%) | (% class="warning" %)üü° Medium(%%) | **P2**
| **Cost Tracking** | Usage stats display | CRITICAL | (% class="warning" %)‚ö†Ô∏è Partial(%%) | (% class="warning" %)üü° Medium(%%) | **P1**
| **Scenarios** | Generation | Deferred (POC2) | (% class="error" %)‚ùå Not impl(%%) | (% class="success" %)‚úÖ As planned(%%) | -
| **Data Model** | Full entities | POC2 required | (% class="error" %)‚ùå Simplified(%%) | (% class="warning" %)‚ö†Ô∏è Accept POC1(%%) | **P3**

----

== Recommendations ==

=== Immediate Actions (POC1 Completion) üî¥ ===

==== 1. Implement Quality Gate 1: Claim Validation **[BLOCKING]** ====

**File:** {{code}}apps/web/src/lib/quality-gates.ts{{/code}} (new file)

{{code language="typescript"}}
interface ClaimValidationResult {
  claimId: string;
  isFactual: boolean;
  opinionScore: number;        // 0-1
  specificityScore: number;    // 0-1
  futureOriented: boolean;
  claimType: "FACTUAL" | "OPINION" | "PREDICTION" | "AMBIGUOUS";
  passed: boolean;
  failureReason?: string;
  validatedAt: Date;
}

export function validateClaim(claimText: string): ClaimValidationResult {
  // Implementation details in full MD document
}
{{/code}}

**Success Metric:** 0% opinion statements processed as facts

----

==== 2. Implement Quality Gate 4: Verdict Confidence Assessment **[BLOCKING]** ====

**Success Metric:** 0% verdicts published with &lt;2 sources

----

==== 3. Implement Quality Metrics Tracking **[BLOCKING]** ====

**Database Migration:**

{{code language="csharp"}}
public class QualityMetricEntity {
    public int Id { get; set; }
    public string MetricType { get; set; }
    public string Category { get; set; }
    public double Value { get; set; }
    public double Target { get; set; }
    public DateTime Timestamp { get; set; }
}
{{/code}}

**Success Metric:** Manual hallucination rate verification &lt;10% after 20-verdict sample

----

==== 4. Add Cost Tracking Display (Component 5) **[IMPORTANT]** ====

**Success Metric:** Cost data collected for all analyses, average cost/analysis calculated

----

==== 5. Verify Publication Mode Labeling **[IMPORTANT]** ====

**Success Metric:** Prominent disclaimer visible on all analysis results

----

=== Short-Term Planning (POC2 Preparation) üü° ===

==== 6. Design Full Data Model Migration ====

**Timeline:** Before POC2 starts

----

==== 7. Implement Redis Caching Layer ====

**Goal:** 70%+ cache hit rate, 50%+ cost savings

**Timeline:** Before scaling beyond 1K articles/month

----

==== 8. Implement Source Track Record System ====

**Timeline:** POC2 requirement

----

=== Architecture Discussions ü§î ===

==== 9. Clarify Scenario Strategy ====

**Recommendation:** Keep deferred for POC1, decide after validation

----

==== 10. Evaluate Separated Architecture Need ====

**Recommendation:** Keep current for POC1, evaluate during POC2 planning

----

== POC1 Completion Checklist ==

**Critical (P0) - Blocking POC1 Sign-Off:**

* [ ] Implement Quality Gate 1 (Claim Validation)
* [ ] Implement Quality Gate 4 (Verdict Confidence Assessment)
* [ ] Add ClaimValidationResult and VerdictValidationResult to results
* [ ] Implement Quality Metrics tracking infrastructure
* [ ] Create manual quality review process (20-verdict sampling)
* [ ] Run quality review and verify hallucination rate &lt;10%

**Important (P1) - Required for POC1:**

* [ ] Add cost tracking display (Component 5)
* [ ] Verify Mode 2 labeling is prominent in UI
* [ ] Display quality gate status in results
* [ ] Track and display cost per analysis

**Planning (P2) - POC2 Preparation:**

* [ ] Design full data model schema
* [ ] Plan Redis caching implementation
* [ ] Design source track record system
* [ ] Document error pattern tracking requirements

**Discussion (P1/P2) - Strategic Decisions:**

* [ ] Clarify scenario strategy (deferred vs. dropped)
* [ ] Evaluate separated architecture need
* [ ] Define POC2 scope based on POC1 learnings

----

== References ==

=== Specification Documents ===

**Source:** {{code}}docs/FactHarbor Spec and Impl 1.Jan.26.xar{{/code}} (xWiki export)

# **POC1 Roadmap:** {{code}}FactHarbor/Roadmap/POC1/WebHome.xml{{/code}}
# **POC Requirements:** {{code}}FactHarbor/Specification/POC/Requirements.xml{{/code}}
# **POC Specification:** {{code}}FactHarbor/Specification/POC/Specification.xml{{/code}}
# **Architecture:** {{code}}FactHarbor/Specification/Architecture/WebHome.xml{{/code}}
# **Data Model:** {{code}}FactHarbor/Specification/Data Model/WebHome.xml{{/code}}

=== Implementation Files ===

# **Analyzer:** {{code}}apps/web/src/lib/analyzer.ts{{/code}} (v2.6.17)
# **Database:** {{code}}apps/api/Data/Entities.cs{{/code}}
# **UI Components:** {{code}}apps/web/src/components/ArticleVerdictBanner.tsx{{/code}}

----

== Document Metadata ==

**Created:** January 2, 2026\\
**Author:** Claude Code (Anthropic)\\
**Version:** 1.0\\
**Specification Reference:** FactHarbor Spec and Impl 1.Jan.26.xar\\
**Implementation Reference:** FactHarbor codebase (analyzer v2.6.17)

**Change Log:**

* 2026-01-02: Initial analysis document created (xWiki format)

----

**END OF REPORT**
