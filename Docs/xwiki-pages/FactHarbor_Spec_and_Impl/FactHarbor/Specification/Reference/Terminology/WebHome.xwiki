= FactHarbor Terminology Reference =

**Version**: 3.1.0
**Date**: 2026-02-04
**Audience**: Developers, Prompt Engineers, LLM Systems
**Status**: v3.1 Complete - All terminology migrations finished, legacy aliases removed

----

== Purpose ==

This document provides the **authoritative glossary** for FactHarbor's terminology across all layers: TypeScript code, JSON schema, database storage, and LLM prompts. Use this as the single source of truth when encountering ambiguous terms.

----

== Field Mapping Table (v3.1) ==

**v3.0 Breaking Changes Applied**: Legacy JSON field names are NO longer accepted. All code uses new terminology.

|= Concept |= TypeScript Type |= JSON Field (v3.1) |= JSON Field (Legacy - removed) |= Prompt Term
| Top-level context | ##AnalysisContext## | ##analysisContexts## | ~~##distinctProceedings##~~ | AnalysisContext
| Per-evidence metadata | ##EvidenceScope## | ##evidenceScope## | ##evidenceScope## | EvidenceScope
| Context answer | ##AnalysisContextAnswer## | ##analysisContextAnswers## | ~~##contextAnswers##~~ | (internal)
| Narrative background | (string) | ##backgroundDetails## | ~~##analysisContext##~~ | Background
| Evidence item | ##EvidenceItem## | ##evidenceItems## | ~~##facts##~~ | EvidenceItem
| Evidence statement | ##statement## | ##statement## | ~~##fact##~~ | statement
| Evidence ID prefix | ##E1, E2, E3...## | ##E1, E2, E3...## | ~~##F1, F2, F3...##~~ | E-prefix

**Schema Version**: 3.0.0 (all config schemas)

----

== Field Hierarchy: Understanding the Layers ==

FactHarbor uses multiple "framing" concepts that work together hierarchically:

=== Level 1: Background Details (Optional Context) ===

* **What:** Broader topic or narrative setting of the article
* **When:** Only for articles with clear thematic frame (can be empty)
* **Display:** Optional banner in UI labeled "Background"
* **Example:** "Climate policy and decarbonization", "Brazilian democratic crisis 2023-2024"
* **JSON field:** ##backgroundDetails##
* **UI Component:** ##BackgroundBanner.tsx##

=== Level 2: ArticleThesis (Main Claim) ===

* **What:** What the article/input specifically asserts
* **When:** Always present (the claim being fact-checked)
* **Display:** Prominent display in summary section
* **Example:** "Hydrogen is more efficient than electric", "Bolsonaro trials were politically motivated"
* **JSON field:** ##articleThesis##

=== Level 3: AnalysisContexts (Verdict Spaces) ===

* **What:** Distinct analytical frames requiring separate, independent verdicts
* **When:** 1+ contexts detected (typically 1-3 per input)
* **Display:** Primary grouping in UI - each context gets its own verdict section
* **Example:** [TSE electoral case, STF criminal case], [WTW methodology, TTW methodology]
* **JSON field:** ##analysisContexts## (plural array)

=== Level 4: Evidence Items (Supporting Evidence) ===

* **What:** Individual evidence items extracted from sources
* **When:** Found during research phase
* **Display:** Listed under each AnalysisContext with supporting/opposing indicators
* **Assigned to:** One AnalysisContext via ##contextId##
* **JSON field:** ##evidenceItems## (array of ##EvidenceItem##)
* **ID format:** ##E1, E2, E3...## (E-prefix for Evidence)

=== Level 5: EvidenceScope (Source Methodology - NOT Currently Displayed) ===

* **What:** The analytical frame/methodology used BY THE SOURCE when producing evidence
* **When:** Optional per-evidence metadata (not all evidence items have this)
* **Display:** //Should be shown via tooltips or sub-grouping (currently hidden)//
* **Example:** "ISO 14040 LCA", "GREET Model", "Brazilian Electoral Law", "Journalistic reporting"
* **JSON field:** ##evidenceItem.evidenceScope## (optional object)

**Key Distinction:**
* **AnalysisContext** = "WHAT we're analyzing" (user's question: "Was TSE fair?")
* **EvidenceScope** = "HOW sources analyzed it" (source metadata: "Using electoral law framework")

**UI Grouping Rule:** Always group by AnalysisContext (uncomparable verdict spaces), then show EvidenceScope as metadata within each context.

----

== Core Concepts ==

=== 1. AnalysisContext (Top-Level Analytical Frame) ===

**What it is**: A bounded analytical frame that requires separate, independent analysis and verdict.

**Why it matters**: When a user's input involves multiple distinct analytical frames (e.g., different legal jurisdictions, different scientific methodologies), each must be analyzed separately to avoid conflating evidence.

**Examples**:
* Different legal proceedings: "TSE Electoral Case" vs "STF Criminal Case"
* Different methodologies: "Well-to-Wheel Analysis" vs "Tank-to-Wheel Analysis"
* Different regulatory frameworks: "EU REACH Standards" vs "US EPA Standards"

**Code representation**:

{{code language="typescript"}}
// TypeScript interface name
export interface AnalysisContext {
  id: string;
  name: string;
  shortName: string;
  subject: string;
  // ...
}
{{/code}}

**JSON field name** (v3.1):

{{code language="json"}}
{
  "analysisContexts": [
    { "id": "CTX_TSE", "name": "TSE Electoral Ruling" },
    { "id": "CTX_SCOTUS", "name": "SCOTUS Colorado Case" }
  ]
}
{{/code}}

**Prompt terminology**:
* Preferred: "AnalysisContext" or "Context"
* Avoid: "Scope" (reserved for EvidenceScope)
* Removed: ~~"Proceeding"~~ (legacy term removed in v3.0)

**Common confusion**:
* AnalysisContext is NOT the same as EvidenceScope (per-evidence metadata)
* AnalysisContext is NOT the same as backgroundDetails (narrative background)

----

=== 2. EvidenceScope (Per-Evidence Source Metadata) ===

**What it is**: Metadata attached to individual evidence items describing the methodology, boundaries, geography, and time period that **the source document** used when producing that evidence.

**Why it matters**: A fact saying "40% efficiency" from a Well-to-Wheel study (includes full energy chain) cannot be directly compared to a Tank-to-Wheel study (only vehicle operation). EvidenceScope captures these methodological differences.

**Examples**:
* Methodology: "ISO 14040 LCA", "EU RED II", "GREET Model"
* Boundaries: "Primary energy to wheel", "Tank to wheel only"
* Geographic: "European Union", "California", "China"
* Temporal: "2020-2025 data", "FY2024 projections"

**Code representation**:

{{code language="typescript"}}
export interface EvidenceScope {
  name: string;
  methodology?: string;
  boundaries?: string;
  geographic?: string;
  temporal?: string;
}

// Attached to evidence items
export interface EvidenceItem {
  id: string;           // E1, E2, E3... (E-prefix)
  statement: string;    // The evidence statement
  evidenceScope?: EvidenceScope;
  // ...
}
{{/code}}

**JSON field name**:

{{code language="json"}}
{
  "evidenceItems": [
    {
      "id": "E1",
      "statement": "Hydrogen achieves 40% WTW efficiency",
      "evidenceScope": {
        "name": "WTW",
        "methodology": "Well-to-Wheel",
        "boundaries": "Primary energy to vehicle motion",
        "geographic": "EU",
        "temporal": "2024"
      }
    }
  ]
}
{{/code}}

**Prompt terminology**:
* Always: "evidenceScope" (lowercase, as field name)
* In explanations: "Per-evidence EvidenceScope" (to distinguish from AnalysisContext)

**Common confusion**:
* EvidenceScope is NOT a top-level scope requiring separate verdicts
* Multiple evidence items can have the same EvidenceScope (many sources use WTW methodology)
* EvidenceScope IS metadata about **how the source computed** the data

----

=== 3. Background Details (Narrative Background) ===

**What it is**: The narrative/rhetorical framing or background context of the input article. This describes **how the article presents** the information, but is NOT a reason to split into separate AnalysisContexts.

**Why it matters**: Helps understand the user's intent and article structure, but does NOT affect verdict logic.

**Examples**:
* "Brazilian political crisis following January 8th events"
* "Climate policy debate in European Union"
* "Legal proceedings against former president"

**Code representation**:

{{code language="typescript"}}
// Stored as string in ClaimUnderstanding
export interface ClaimUnderstanding {
  backgroundDetails: string; // Narrative background
  // ...
}
{{/code}}

**JSON field name** (v3.1):

{{code language="json"}}
{
  "backgroundDetails": "Brazilian political crisis following January 8th events"
}
{{/code}}

**UI Display**: Shown in ##BackgroundBanner.tsx## component with label "Background"

**Prompt terminology**:
* Preferred: "backgroundDetails" or "Background"
* Removed: ~~"ArticleFrame"~~, ~~"analysisContext" (singular)~~ (legacy terms)

**Common confusion**:
* backgroundDetails is NOT an AnalysisContext (not a reason to split analysis)
* backgroundDetails does NOT get its own verdict
* backgroundDetails IS purely descriptive/informational

----

=== 4. Doubted vs Contested (Contestation Classification) - v2.8 ===

**What it is**: A distinction between two types of opposition to a claim, which affects how the opposition impacts the verdict weight.

**Why it matters**: Not all criticism is equal. Political statements without evidence shouldn't reduce a claim's weight as much as documented counter-evidence. This ensures:
* **Evidence-based contestation** appropriately reduces certainty
* **Opinion-based doubt** doesn't unfairly penalize well-evidenced claims

**Two Categories**:

|= Category |= factualBasis |= Weight Multiplier |= Example
| **DOUBTED** | ##"opinion"## | 1.0x (full) | "Government says trial was unfair" (no specifics)
| **DOUBTED** | ##"alleged"## | 1.0x (full) | "Critics claim bias" (no evidence cited)
| **CONTESTED** | ##"disputed"## | 0.5x (reduced) | "Defense presented conflicting expert testimony"
| **CONTESTED** | ##"established"## | 0.3x (heavily reduced) | "Audit found violation of Regulation 47(b)"

**Weight calculation** (in ##getClaimWeight()##):

{{code language="typescript"}}
if (claim.isContested) {
  if (basis === "established") weight *= 0.3;  // Strong counter-evidence
  else if (basis === "disputed") weight *= 0.5; // Some counter-evidence
  // "opinion"/"alleged"/"unknown" -> full weight (just doubted)
}
{{/code}}

**Common confusion**:
* "contested" does NOT mean "disputed politically" (that's "doubted")
* "contested" means there IS documented counter-evidence
* Political statements alone do NOT reduce claim weight
* Only factual counter-evidence reduces claim weight

----

== Terminology Mapping Tables ==

=== Table 1: Primary Entities (v3.1) ===

|= Concept |= TypeScript Name |= JSON Field |= Prompt Term |= UI Label |= Database Column
| Top-level analytical frame | ##AnalysisContext## | ##analysisContexts## | "AnalysisContext" | "Contexts" | ##ResultJson.analysisContexts##
| Per-evidence source metadata | ##EvidenceScope## | ##evidenceScope## | "evidenceScope" | (not displayed separately) | ##ResultJson.evidenceItems[].evidenceScope##
| Narrative background | (string) | ##backgroundDetails## | "Background" | "Background" | ##ResultJson.understanding.backgroundDetails##
| Evidence item | ##EvidenceItem## | ##evidenceItems## | "EvidenceItem" | "Evidence" | ##ResultJson.evidenceItems##

=== Table 2: Reference Fields (v3.1) ===

|= Field Purpose |= TypeScript Field |= JSON Field |= Prompt Term |= Valid Values
| Evidence -> AnalysisContext | ##contextId?: string## | ##contextId## | "contextId" | Must match ##AnalysisContext.id##
| Claim -> AnalysisContext | ##contextId?: string## | ##contextId## | "contextId" | Must match ##AnalysisContext.id##
| Verdict -> AnalysisContext | ##contextId: string## | ##contextId## | "contextId" | Must match ##AnalysisContext.id##
| Supporting evidence | ##supportingEvidenceIds## | ##supportingEvidenceIds## | "supportingEvidenceIds" | Array of E-prefix IDs

=== Table 3: Special Constants ===

|= Constant |= Value |= Meaning |= When to Use
| ##UNSCOPED_ID## | ##"CTX_UNSCOPED"## | Evidence doesn't map to any detected context | When evidence is general/background
| ##CTX_MAIN## | ##"CTX_MAIN"## | Fallback context for single-context analysis | When no distinct contexts detected
| ##CTX_GENERAL## | ##"CTX_GENERAL"## | General context (cross-cutting) | When evidence applies to all contexts

----

== Quick Reference: "Which term should I use?" ==

=== In TypeScript Code ===

{{code language="typescript"}}
// CORRECT (v3.1)
import { AnalysisContext, EvidenceScope, EvidenceItem } from './types';

function processContexts(contexts: AnalysisContext[]) {
  // ...
}

function processEvidence(items: EvidenceItem[]) {
  // ...
}

// REMOVED in v3.0 - do not use:
// ExtractedFact (use EvidenceItem)
// DistinctProceeding (use AnalysisContext)
{{/code}}

=== In JSON Schema (Zod) ===

{{code language="typescript"}}
// CORRECT (v3.1 field names)
const schema = z.object({
  analysisContexts: z.array(AnalysisContextSchema),
  backgroundDetails: z.string(),
  evidenceItems: z.array(EvidenceItemSchema),
});
{{/code}}

=== In LLM Prompts ===

{{code language="typescript"}}
// CORRECT (v3.1 terminology)
const prompt = `
## TERMINOLOGY

**AnalysisContext**: Top-level bounded analytical frame (stored as analysisContexts)
**EvidenceScope**: Per-evidence source metadata (stored as evidenceItem.evidenceScope)
**Background**: Narrative background (stored as backgroundDetails)
**EvidenceItem**: Individual evidence with id (E1, E2...) and statement

Your task: Identify AnalysisContexts from evidence...
`;

// AVOID (legacy terms)
const prompt = `Identify scopes from evidence...`;  // Which "scope"?
const prompt = `Extract facts...`;  // Use "evidence" not "facts"
{{/code}}

=== In UI/Documentation ===

{{code language="typescript"}}
// CORRECT
<h2>Analysis Contexts</h2>
<p>This analysis involves 2 distinct analytical frames:</p>

<BackgroundBanner backgroundDetails={background} />

// REMOVED in v3.0:
// <ArticleFrameBanner articleFrame={...} />
{{/code}}

----

== Internal Task Names (v3.1) ==

|= Task Name |= Description |= Used In
| ##extract_evidence## | Extract evidence items from sources | llm.ts, model-tiering.ts
| ##context_refinement## | Refine AnalysisContext assignments | llm.ts, model-tiering.ts
| ##understand## | Initial claim understanding | llm.ts, model-tiering.ts
| ##verdict## | Generate verdicts | llm.ts, model-tiering.ts

**Note:** Legacy task names ##extract_facts## and ##scope_refinement## were renamed in v3.1.

----

== Config Field Names (v3.1) ==

|= Config Field |= Description |= Default
| ##contextDetectionMethod## | Method for detecting contexts | ##"heuristic"##
| ##contextDetectionEnabled## | Enable context detection | ##true##
| ##contextDetectionMinConfidence## | Minimum confidence threshold | ##0.7##
| ##contextDetectionMaxContexts## | Maximum contexts to detect | ##5##
| ##contextDedupThreshold## | Threshold for deduplication | ##0.85##

**Note:** Legacy field names ##scopeDetection*## and ##scopeDedup*## were renamed in v3.0.

----

== Decision Trees ==

=== "Should I create a new AnalysisContext?" ===

{{code}}
START: Do the facts involve distinct analytical frames?
  |
  +-- YES -> Are the methodologies/boundaries INCOMPATIBLE?
  |   |
  |   +-- YES -> CREATE separate AnalysisContexts
  |   |   Example: WTW vs TTW (different system boundaries)
  |   |
  |   +-- NO -> SINGLE AnalysisContext
  |       Example: Multiple studies using same WTW methodology
  |
  +-- NO -> Are they different LEGAL proceedings analyzing different matters?
      |
      +-- YES -> CREATE separate AnalysisContexts
      |   Example: TSE electoral case vs STF criminal case
      |
      +-- NO -> SINGLE AnalysisContext
          Example: Different viewpoints on same legal case
{{/code}}

=== "Is this an EvidenceScope or AnalysisContext?" ===

{{code}}
START: Where does this information come from?
  |
  +-- FROM SOURCE DOCUMENT -> EvidenceScope
  |   Example: "Study used ISO 14040 methodology"
  |   Attach to evidenceItem.evidenceScope
  |
  +-- FROM INPUT/USER -> AnalysisContext?
      |
      +-- Does it define a DISTINCT analytical frame?
          |
          +-- YES -> AnalysisContext
          |   Example: "Compare US EPA vs EU REACH"
          |
          +-- NO -> backgroundDetails
              Example: "Article is written as opinion piece"
{{/code}}

----

== Common Pitfalls & Solutions ==

=== Pitfall 1: Using "Scope" Without Qualifier ===

**Problem**:

{{code language="typescript"}}
// Ambiguous - which scope?
function getScope(id: string) { ... }
{{/code}}

**Solution**:

{{code language="typescript"}}
// Explicit
function getAnalysisContext(id: string): AnalysisContext { ... }
function getEvidenceScope(evidence: EvidenceItem): EvidenceScope | null { ... }
{{/code}}

=== Pitfall 2: Conflating backgroundDetails with AnalysisContext ===

**Problem**:

{{code language="json"}}
{
  "analysisContexts": [
    { "name": "Article frames as conspiracy theory" }
  ]
}
{{/code}}

**Solution**:

{{code language="json"}}
{
  "backgroundDetails": "Article frames as conspiracy theory",
  "analysisContexts": [
    { "name": "Central Bank Policy Analysis" }
  ]
}
{{/code}}

=== Pitfall 3: Using Legacy Field Names ===

**Problem** (v3.0+ will fail):

{{code language="typescript"}}
const facts = result.facts;  // REMOVED
const context = understanding.analysisContext;  // RENAMED
{{/code}}

**Solution**:

{{code language="typescript"}}
const evidenceItems = result.evidenceItems;  // v3.1
const background = understanding.backgroundDetails;  // v3.1
{{/code}}

----

== Validation Checklist ==

Use this checklist when reviewing code that involves contexts/evidence:

* Is "scope" qualified as AnalysisContext or EvidenceScope?
* Do JSON field names use v3.1 names (##analysisContexts##, ##evidenceItems##, ##backgroundDetails##)?
* Does prompt include terminology glossary header?
* Are ##contextId## values validated against ##analysisContexts[]##?
* Are fallbacks logged (not silent)?
* Does EvidenceScope capture source methodology (not create new AnalysisContexts)?
* Is backgroundDetails separate from AnalysisContexts?
* Are evidence IDs using E-prefix (##E1, E2, E3...##)?

----

== FAQ ==

**Q: When should I use EvidenceScope vs AnalysisContext?**

A: If the information describes **how a source document computed its data** (methodology, boundaries), it's EvidenceScope. If it describes **a distinct analytical frame requiring separate verdicts**, it's AnalysisContext.

**Q: What's the difference between CTX_UNSCOPED and CTX_GENERAL?**

A: ##CTX_UNSCOPED## means the evidence doesn't map to any detected context (background info). ##CTX_GENERAL## means the evidence applies across all contexts (cross-cutting evidence). In practice, both are grouped together in display.

**Q: Can an evidence item have BOTH contextId AND evidenceScope?**

A: Yes! ##contextId## says **which AnalysisContext the evidence supports**, while ##evidenceScope## says **how the source computed the data**. They're orthogonal concepts.

**Q: Should prompts say "AnalysisContext", "Context", or "Framework"?**

A: Use "AnalysisContext" for precision or "context" for brevity. **NEVER use "framework"** when referring to the architectural concept of ##AnalysisContext##. The term "framework" is reserved for descriptive English phrases like "regulatory frameworks".

----

== Related Documentation ==

* v2-to-v3-migration-guide.md - Migration guide for v3.0/v3.1
* AGENTS.md - High-level rules for context detection
* types.ts - TypeScript interface definitions
* Pipeline_TriplePath_Architecture.md - Pipeline design

----

**Document Maintainer**: Lead Developer
**Last Reviewed**: 2026-02-04 (Updated for v3.1)
**Next Review**: 2026-05 (or after next major version)