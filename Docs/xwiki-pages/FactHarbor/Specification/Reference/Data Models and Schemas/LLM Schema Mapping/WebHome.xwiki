= LLM Schema Mapping Reference =

**Version**: 3.1.0
**Date**: 2026-02-07
**Purpose**: Complete mapping of TypeScript -> LLM Prompts -> JSON Schemas
**Audience**: Prompt Engineers, LLM System Developers

----

== Overview ==

This document maps how FactHarbor's TypeScript objects are presented to LLMs (via prompts) and how LLM outputs are validated (via Zod schemas). Use this as the authoritative reference when writing or updating prompts.

----

== Master Mapping Table ==

|= TypeScript Type |= Prompt Term |= LLM Output Field |= Zod Schema
| ##AnalysisContext## | "AnalysisContext" or "Context" | ##analysisContexts## | ##AnalysisContextSchema##
| ##EvidenceScope## | "EvidenceScope" or "Scope" | ##evidenceScope## | ##EvidenceScopeSchema##
| ##EvidenceItem## | "Evidence" | ##evidenceItems## | ##EvidenceItemSchema##
| ##ContextAnswer## | "Verdict" | (embedded in result) | ##ContextAnswerSchema##

> **CRITICAL TERMINOLOGY**: "Scope" refers to ##EvidenceScope## (per-evidence metadata), NOT ##AnalysisContext##. Use "Context" for top-level analytical frames.

{{warning}}
**v3.0 Breaking Change (February 2026):** All legacy JSON field names have been removed from the codebase. Legacy names (##distinctProceedings##, ##relatedProceedingId##, ##proceedingId##, ##supportingFactIds##, ##facts##, etc.) are **no longer accepted** by Zod schemas. Only the migration script (##apps/api/scripts/migrate-terminology-v2.7.ts##) handles old→new field renaming when reading historical job data from the database.
{{/warning}}

----

== Phase-by-Phase Mappings ==

=== UNDERSTAND Phase ===

**Purpose**: Extract claims and detect preliminary AnalysisContexts

**Input to LLM**:

{{code language="typescript"}}
// Variables passed to prompt
{
  currentDate: string;  // e.g., "2026-01-18"
  isRecent: boolean;    // Temporal relevance flag
}
{{/code}}

**Prompt Terms Used**:
* "AnalysisContext" or "Context" for top-level analytical frames
* "Multi-Context Detection" for identifying distinct frames
* "Claim Extraction" for factual assertions

**LLM Output Schema (v2.7)**:

{{code language="json"}}
{
  "impliedClaim": "string",
  "articleThesis": "string",
  "subClaims": [
    {
      "id": "string",
      "text": "string",
      "claimRole": "attribution" | "source" | "timing" | "core",
      "centrality": "HIGH" | "MEDIUM" | "LOW",
      "isCentral": boolean
    }
  ],
  "researchQueries": ["string"],
  "analysisContexts": [
    {
      "id": "string",
      "name": "string",
      "type": "legal" | "scientific" | "methodological" | "general"
    }
  ],
  "requiresSeparateAnalysis": boolean
}
{{/code}}

**Zod Validation**: ##UnderstandingSchema## (in ##orchestrated.ts##)

**Key Mappings**:
* Prompt: "AnalysisContext" -> Output: ##analysisContexts## array
* Prompt: "requiresSeparateAnalysis" -> Output: ##requiresSeparateAnalysis## boolean

----

=== EXTRACT_EVIDENCE Phase ===

**Purpose**: Extract verifiable evidence items from fetched sources

**Input to LLM**:

{{code language="typescript"}}
{
  currentDate: string;
  originalClaim: string;      // User's input
  contextsList: string;       // Stringified list of detected AnalysisContexts
}
{{/code}}

**Prompt Terms Used**:
* "EvidenceScope" for per-evidence methodology metadata (NOT an AnalysisContext)
* "contextId" for AnalysisContext assignment
* "claimDirection" for support/contradict/neutral assessment

**LLM Output Schema (v2.7)**:

{{code language="json"}}
{
  "evidenceItems": [
    {
      "id": "string",
      "statement": "string",
      "category": "evidence" | "expert_quote" | "statistic" | "event" | "legal_provision" | "criticism",
      "specificity": "high" | "medium",
      "sourceExcerpt": "string (50-200 chars)",
      "claimDirection": "supports" | "contradicts" | "neutral",
      "contextId": "string (e.g., CTX_TSE)",
      "evidenceScope": {
        "name": "string",
        "methodology": "string?",
        "boundaries": "string?",
        "geographic": "string?",
        "temporal": "string?"
      } | null
    }
  ]
}
{{/code}}

**Zod Validation**: ##EvidenceItemSchema## (in ##types.ts##)

**Key Mappings**:
* Prompt: "EvidenceScope" -> Output: ##evidenceScope## object (nullable)
* Prompt: "contextId" -> Output: ##contextId##

----

=== CONTEXT_REFINEMENT Phase ===

**Purpose**: Identify final AnalysisContexts from evidence

**Input to LLM**:

{{code language="typescript"}}
{
  evidenceItems: EvidenceItem[];              // All extracted evidence items
  preliminaryContexts: AnalysisContext[];     // From UNDERSTAND phase
}
{{/code}}

**Prompt Terms Used**:
* "AnalysisContext" or "Context" (primary term for top-level frames)
* "ArticleFrame" (what NOT to split on)
* "EvidenceScope" (per-evidence metadata - NOT an AnalysisContext)
* "analysisContexts" (output field name)

**LLM Output Schema (v2.7)**:

{{code language="json"}}
{
  "requiresSeparateAnalysis": boolean,
  "analysisContexts": [
    {
      "id": "string",
      "name": "string",
      "shortName": "string",
      "subject": "string",
      "temporal": "string",
      "status": "concluded" | "ongoing" | "pending" | "unknown",
      "outcome": "string",
      "metadata": {
        "institution": "string?",
        "jurisdiction": "string?",
        "methodology": "string?",
        "boundaries": "string?",
        "geographic": "string?",
        "dataSource": "string?"
      }
    }
  ],
  "evidenceContextAssignments": [
    {
      "evidenceId": "string",
      "contextId": "string"    // References AnalysisContext.id
    }
  ],
  "claimContextAssignments": [
    {
      "claimId": "string",
      "contextId": "string"
    }
  ]
}
{{/code}}

**Zod Validation**: ##ContextRefinementSchema## (in ##orchestrated.ts##)

**Key Mappings**:
* Prompt: "AnalysisContext" -> Output: ##analysisContexts##
* Prompt: "ArticleFrame" -> (explicitly NOT included in output)
* Prompt: "EvidenceScope" -> (per-evidence metadata, not top-level context)

----

=== VERDICT Phase ===

**Purpose**: Generate truth verdicts per context per claim

**Input to LLM**:

{{code language="typescript"}}
{
  currentDate: string;
  originalClaim: string;
  claimsList: string;          // Stringified claims
  contextsList: string;        // Stringified AnalysisContexts
  allEvidenceItems: string;    // Stringified evidence items
}
{{/code}}

**Prompt Terms Used**:
* "contextId" for verdict assignment
* "answer" for truth percentage (0-100)
* "keyFactors" for evidence summary

**LLM Output Schema (v2.7)**:

{{code language="json"}}
{
  "verdicts": [
    {
      "contextId": "string",
      "contextName": "string",
      "claimId": "string",
      "answer": number (0-100),
      "confidence": number (0-100),
      "truthPercentage": number (0-100),
      "shortAnswer": "string",
      "keyFactors": [
        {
          "factor": "string",
          "explanation": "string",
          "supports": "strongly_supports" | "supports" | "neutral" | "contradicts" | "strongly_contradicts",
          "weight": "high" | "medium" | "low",
          "isContested": boolean,
          "contestedBy": "string?",
          "factualBasis": "established" | "disputed" | "opinion" | "alleged" | "unknown"
        }
      ]
    }
  ]
}
{{/code}}

**Contestation Fields (v2.8):**
* ##isContested##: Whether there is opposition to this factor
* ##contestedBy##: Who opposes (e.g., "opposition party", "industry group")
* ##factualBasis##: Type of opposition evidence
** ##established## = Strong documented counter-evidence (weight: 0.3x)
** ##disputed## = Some factual counter-evidence (weight: 0.5x)
** ##opinion##/##alleged##/##unknown## = DOUBTED, no evidence (weight: 1.0x)

See [[Terminology>>FactHarbor.Specification.Reference.Terminology.WebHome]] for "Doubted vs Contested" distinction.

**Zod Validation**: ##VerdictSchema## (in ##orchestrated.ts##)

----

== Terminology Bridges (Prompt <-> Code) ==

=== AnalysisContext Bridges ===

|= Layer |= Term |= Notes
| Prompt | "AnalysisContext" or "Context" | Primary prompt term (NEVER "Scope")
| LLM Output | ##analysisContexts## | JSON field name (v3.1)
| TypeScript | ##AnalysisContext## | Interface name
| Database | (embedded in ResultJson) | Stored as JSON blob

=== EvidenceScope Bridges ===

|= Layer |= Term |= Notes
| Prompt | "EvidenceScope" or "Scope" | Per-evidence metadata (NOT an AnalysisContext)
| LLM Output | ##evidenceScope## | Consistent across versions
| TypeScript | ##EvidenceScope## | Interface name
| Database | (embedded in evidence item objects) | Part of ResultJson

----

== Validation Flow ==

{{mermaid}}
graph TD
    A[TypeScript Input] -->|Variables| B[Prompt Template]
    B -->|Prompt String| C[LLM API Call]
    C -->|JSON String| D[Parse Response]
    D -->|Raw Object| E[Zod Validation]
    E -->|Valid?| F{Schema Match?}
    F -->|Yes| G[TypeScript Output]
    F -->|No| H[Validation Error]
    H --> I[Fallback or Retry]
{{/mermaid}}

=== Schema Validation Checkpoints ===

1. **Pre-LLM**: Variables validated (type-safe TypeScript)
1. **Post-LLM**: JSON parsed and Zod-validated
1. **Post-Validation**: TypeScript types enforced
1. **Runtime**: Additional business logic validation (e.g., ##contextId## exists in context list)

----

== Common Pitfalls ==

=== Pitfall 1: Field Name Mismatch ===

**Wrong** (Prompt says one thing, schema expects another):

{{code language="typescript"}}
// Prompt says: "Output as 'contexts'"
// But Zod schema expects: analysisContexts

// Result: Validation fails — field names must match exactly
{{/code}}

**Correct** (Prompt and schema aligned):

{{code language="typescript"}}
// Prompt says: "Output as 'analysisContexts'"
// Zod schema expects: analysisContexts
// Result: Validation succeeds
{{/code}}

=== Pitfall 2: Terminology Confusion in Prompts ===

**Wrong** (Confusing "scope" with "context"):

{{code}}
"Identify the distinct scopes..."
// WRONG: "Scope" means EvidenceScope (per-evidence metadata), not AnalysisContext
{{/code}}

**Correct** (Clear terminology):

{{code}}
"Identify AnalysisContexts (or Contexts)..."
// "Scope" reserved for EvidenceScope (per-evidence source methodology)
{{/code}}

=== Pitfall 3: Missing Glossary ===

**Wrong** (No term definitions in prompt):

{{code}}
"Extract the scopes from evidence."
// Ambiguous: Does "scope" mean AnalysisContext or EvidenceScope?
{{/code}}

**Correct** (Explicit glossary with CRITICAL distinction):

{{code}}
## TERMINOLOGY (CRITICAL)
- **AnalysisContext** (or "Context"): Top-level analytical frame requiring separate verdict
- **EvidenceScope** (or "Scope"): Per-evidence source methodology metadata (NOT an AnalysisContext)
{{/code}}

----

== Testing Checklist ==

When updating prompts or schemas:

* Prompt terminology matches Zod field names exactly
* Glossary section present in all base prompts
* Provider-specific variants use same core terms
* Example outputs in prompts match schema structure
* Validation errors are descriptive (mention expected vs actual field names)
* Documentation updated (this file, TERMINOLOGY.md)

----

== References ==

* [[Terminology>>FactHarbor.Specification.Reference.Terminology.WebHome]] - Core definitions
* Prompt_Engineering_Standards.md - How to write prompts
* types.ts - TypeScript interfaces
* Migration decision documented in ##types.ts## comments and ##TERMINOLOGY.md##

----

**Maintainer**: LLM Expert, Prompt Engineering Team
**Last Updated**: 2026-02-07
**Next Review**: After next major version