= Target Production Architecture =

{{info}}
This page describes **planned production capabilities** that are not yet implemented. The current implementation runs as a two-service application (Next.js + .NET API) with SQLite. See [[Architecture>>FactHarbor.Specification.Architecture.WebHome]] for the current system design.
{{/info}}

== Automated Systems ==

FactHarbor relies heavily on automation to achieve scale and quality.

=== AKEL (AI Knowledge Extraction Layer) ===

**What it does**: Primary AI processing engine that analyzes claims automatically

**Inputs**:
* User-submitted claim text or URL
* Web search results and fetched sources
* Source reliability cache (LLM-evaluated scores)

**Processing steps (Orchestrated Pipeline)**:
1. **UNDERSTAND**: Extract claims, detect AnalysisContexts, discover KeyFactors, apply Gate 1
2. **RESEARCH**: Iterative web search, fetch and parse sources, extract evidence items
3. **CONTEXT REFINEMENT**: Refine AnalysisContext assignments from evidence
4. **VERDICTS**: Generate per-claim verdicts with confidence, apply Gate 4
5. **SUMMARY**: Build two-panel summary (Overview + Key Findings)
6. **REPORT**: Generate full markdown analysis report

**Outputs**:
* ##ClaimUnderstanding## — extracted claims, AnalysisContexts, KeyFactors
* ##EvidenceItem[]## — evidence with source attribution and probative value
* ##ClaimVerdict[]## — per-claim verdicts on 7-point scale
* ##ArticleAnalysis## — overall analysis result with quality gates
* Markdown report

**Timing**: 30-300 seconds depending on claim complexity

=== Background Jobs (planned) ===

**Source Track Record Updates** (Scheduled Batch):
* Analyze claim outcomes from recent period
* Calculate source accuracy and reliability
* Update source_track_record table
* Never triggered by individual claims (prevents circular dependencies)

**Cache Management** (Continuous):
* Warm cache for popular claims
* Invalidate cache on claim updates
* Monitor cache hit rates

**Metrics Aggregation** (Recurring):
* Roll up detailed metrics
* Calculate system health indicators
* Generate performance reports

**Data Archival** (Scheduled):
* Move old AKEL logs to S3 (90+ days)
* Archive old processing logs
* Compress and backup data

=== Quality Monitoring (planned) ===

**Automated checks run continuously**:
* **Anomaly Detection**: Flag unusual patterns (confidence score changes, evidence distributions, source patterns)
* **Contradiction Detection**: Identify conflicts (evidence contradictions, internal claim contradictions, source anomalies)
* **Completeness Validation**: Ensure thoroughness (sufficient evidence, multiple source types, key scenarios identified)

=== Moderation Detection (planned) ===

**Automated abuse detection**:
* **Spam Identification**: Pattern matching for spam claims
* **Manipulation Detection**: Identify coordinated editing
* **Gaming Detection**: Flag attempts to game source scores
* **Suspicious Activity**: Log unusual behavior patterns

**Human Review**: Moderators review flagged items, system learns from decisions

== Scalability Strategy ==

=== Horizontal Scaling ===

Components scale independently:
* **AKEL Workers**: Add more processing workers as claim volume grows
* **Database Read Replicas**: Add replicas for read-heavy workloads
* **Cache Layer**: Redis cluster for distributed caching
* **API Servers**: Load-balanced API instances

=== Vertical Scaling ===

Individual components can be upgraded:
* **Database Server**: Increase CPU/RAM for PostgreSQL
* **Cache Memory**: Expand Redis memory
* **Worker Resources**: More powerful AKEL worker machines

=== Performance Optimization ===

Built-in optimizations:
* **Denormalized Data**: Cache summary data in claim records (70% fewer joins)
* **Parallel Processing**: AKEL pipeline processes in parallel (40% faster)
* **Intelligent Caching**: Redis caches frequently accessed data
* **Background Processing**: Non-urgent tasks run asynchronously

== Monitoring & Observability ==

=== Key Metrics ===

System tracks:
* **Performance**: AKEL processing time, API response time, cache hit rate
* **Quality**: Confidence score distribution, evidence completeness, contradiction rate
* **Usage**: Claims per day, active users, API requests
* **Errors**: Failed AKEL runs, API errors, database issues

=== Alerts ===

Automated alerts for:
* Processing time >30 seconds (threshold breach)
* Error rate >1% (quality issue)
* Cache hit rate <80% (cache problem)
* Database connections >80% capacity (scaling needed)

=== Dashboards ===

Real-time monitoring:
* **System Health**: Overall status and key metrics
* **AKEL Performance**: Processing time breakdown
* **Quality Metrics**: Confidence scores, completeness
* **User Activity**: Usage patterns, peak times

== Security Architecture ==

=== Authentication & Authorization ===

* **User Authentication**: Secure login with password hashing
* **Role-Based Access**: Reader, User (Registered), UCM Administrator, Moderator
* **API Keys**: For programmatic access
* **Rate Limiting**: Prevent abuse

=== Data Security ===

* **Encryption**: TLS for transport, encrypted storage for sensitive data
* **Audit Logging**: Track all significant changes
* **Input Validation**: Sanitize all user inputs
* **SQL Injection Protection**: Parameterized queries

=== Abuse Prevention ===

* **Rate Limiting**: Prevent flooding and DDoS
* **Automated Detection**: Flag suspicious patterns
* **Human Review**: Moderators investigate flagged content
* **Ban Mechanisms**: Block abusive users/IPs

== Deployment Architecture ==

=== Production Environment ===

**Components**:
* Load Balancer (HAProxy or cloud LB)
* Multiple API servers (stateless)
* AKEL worker pool (auto-scaling)
* PostgreSQL primary + read replicas
* Redis cluster
* S3-compatible storage

**Regions**: Single region for V1.0, multi-region when needed

=== Development & Staging ===

**Development**: Local Docker Compose setup
**Staging**: Scaled-down production replica
**CI/CD**: Automated testing and deployment

=== Disaster Recovery ===

* **Database Backups**: Automated backups to S3
* **Point-in-Time Recovery**: Transaction log archival
* **Replication**: Real-time replication to standby
* **Recovery Time Objective**: <4 hours

=== Federation Architecture ===

{{include reference="FactHarbor.Specification.Diagrams.Federation Architecture.WebHome"/}}

== Future Architecture Evolution ==

=== When to Add Complexity ===

See [[When to Add Complexity>>FactHarbor.Specification.When-to-Add-Complexity]] for specific triggers.

**Elasticsearch**: When PostgreSQL search consistently >500ms
**TimescaleDB**: When metrics queries consistently >1s
**Federation**: When 10,000+ users and explicit demand
**Advanced User Management**: When submission volume requires automated quota management

=== Federation (V2.0+) ===

**Deferred until**:
* Core product proven with 10,000+ users
* User demand for decentralization
* Single-node limits reached

See [[Federation & Decentralization>>FactHarbor.Specification.Federation & Decentralization.WebHome]] for future plans.
