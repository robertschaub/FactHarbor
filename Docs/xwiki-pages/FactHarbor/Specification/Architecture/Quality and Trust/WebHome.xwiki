= Quality and Trust =

FactHarbor employs multiple quality mechanisms to ensure analysis results are trustworthy: quality gates validate input and output, a 7-layer evidence filtering system ensures evidence quality, source reliability scoring evaluates source credibility, and a confidence calibration pipeline prevents misleading confidence scores.

== Quality Gates ==

Two quality gates are integrated into the AKEL pipeline: Gate 1 validates claims at input, Gate 4 assesses verdict confidence at output.

{{mermaid}}
flowchart TB
    subgraph Input["Step 1: Understand"]
        CLAIMS["Extracted Claims"]
        GATE1{{"Gate 1\nClaim Validation"}}
        PASS1["Factual claims\nproceed to research"]
        FAIL1["Opinions, predictions,\nnon-factual filtered out"]
    end

    subgraph Research["Step 2: Research"]
        EVIDENCE["Evidence gathered\nfrom web sources"]
    end

    subgraph Verdict["Step 3: Verdict"]
        VERDICTS["Claim verdicts\ngenerated"]
        GATE4{{"Gate 4\nConfidence Assessment"}}
        HIGH["HIGH / MEDIUM\nconfidence — publish"]
        LOW["LOW confidence —\nflag for review"]
        INSUF["INSUFFICIENT —\nmore research needed"]
    end

    CLAIMS --> GATE1
    GATE1 -->|"Pass"| PASS1
    GATE1 -->|"Fail"| FAIL1
    PASS1 --> EVIDENCE --> VERDICTS --> GATE4
    GATE4 -->|"HIGH/MEDIUM"| HIGH
    GATE4 -->|"LOW"| LOW
    GATE4 -->|"INSUFFICIENT"| INSUF

    style Input fill:#e8f5e9,stroke:#2e7d32,color:#000
    style Research fill:#e3f2fd,stroke:#1565c0,color:#000
    style Verdict fill:#fff9c4,stroke:#f9a825,color:#000
{{/mermaid}}

//Gate 1 filters non-factual claims (opinions, predictions) before research begins. Gate 4 evaluates verdict quality based on evidence count, source quality, and evidence agreement — only HIGH and MEDIUM confidence verdicts are published without flags.//

=== Gate 1: Claim Validation ===

|= Check |= Purpose |= Pass Criteria
| Factuality test | Can the claim be proven true or false? | Must be verifiable
| Opinion detection | Contains subjective language? | Opinion score <= 0.3
| Specificity check | Contains concrete, testable details? | Specificity score >= 0.3
| Future prediction | About future events? | Must be about past or present

=== Gate 4: Confidence Assessment ===

|= Tier |= Evidence Sources |= Avg Quality |= Agreement |= Action
| **HIGH** | 3+ | >= 0.7 | >= 80% | Publish
| **MEDIUM** | 2+ | >= 0.6 | >= 60% | Publish
| **LOW** | 2+ | >= 0.5 | >= 40% | Flag for review
| **INSUFFICIENT** | < 2 | Any | Any | More research needed

== Evidence Quality: 7-Layer Defence ==

Evidence goes through a multi-layer defence system to ensure only high-quality, relevant evidence supports verdicts.

{{mermaid}}
flowchart TB
    RAW["Raw Evidence\n(from LLM extraction)"]
    L1["Layer 1: LLM Prompt Instructions\n(guide extraction quality)"]
    L2["Layer 2: Deterministic Filter\n(min length, vague phrases, dedup)"]
    L3["Layer 3: Category-Specific Rules\n(statistics need numbers,\nquotes need attribution)"]
    L4["Layer 4: Probative Value Scoring\n(relevance to specific claim)"]
    L5["Layer 5: Provenance Validation\n(URL required, excerpt required)"]
    L6["Layer 6: Source Reliability\n(domain credibility weighting)"]
    L7["Layer 7: Verdict Corrections\n(inversion detection,\ndirection mismatch fix)"]
    CLEAN["Validated Evidence\n(supports verdicts)"]

    RAW --> L1 --> L2 --> L3 --> L4 --> L5 --> L6 --> L7 --> CLEAN

    style RAW fill:#ffcdd2,stroke:#b71c1c,color:#000
    style CLEAN fill:#c8e6c9,stroke:#2e7d32,color:#000
    style L1 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L2 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L3 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L4 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L5 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L6 fill:#e3f2fd,stroke:#1565c0,color:#000
    style L7 fill:#e3f2fd,stroke:#1565c0,color:#000
{{/mermaid}}

//Evidence passes through 7 layers: LLM-guided extraction (Layer 1) is followed by deterministic filtering (Layer 2), category-specific rules (Layer 3), relevance scoring (Layer 4), provenance checks (Layer 5), source credibility weighting (Layer 6), and verdict consistency corrections (Layer 7).//

|= Layer |= Type |= What It Filters
| 1. LLM Prompt Instructions | Soft (LLM) | Guides extraction: require excerpts, avoid vague statements, cite sources
| 2. Deterministic Filter | Hard (code) | Min 20 chars, 13 vague phrase patterns, Jaccard deduplication (0.85)
| 3. Category-Specific Rules | Hard (code) | Statistics require numbers, quotes require attribution, events require dates
| 4. Probative Value Scoring | Soft (scoring) | Relevance to the specific claim being evaluated
| 5. Provenance Validation | Hard (code) | URL must be present, source excerpt must be provided
| 6. Source Reliability | Soft (scoring) | Domain credibility score (0-100) weights evidence strength
| 7. Verdict Corrections | Hard (code) | Detects and corrects verdicts that contradict their own evidence

== Source Reliability ==

Source reliability scoring evaluates the credibility of web domains using LLM-based assessment with consensus scoring.

|= Feature |= Description
| **7-band credibility scale** | Authoritative (90+), Highly Credible (80-89), Credible (70-79), Moderately Credible (60-69), Mixed (50-59), Low Credibility (30-49), Unreliable (<30)
| **LLM evaluation** | Domain assessed for editorial standards, fact-checking history, transparency, bias indicators
| **Multi-model consensus** | Multiple LLM evaluations averaged for stability (configurable via UCM)
| **SQLite cache** | Evaluations cached for 90 days (configurable) to avoid redundant LLM calls
| **Evidence weighting** | Source reliability score directly influences evidence weight in verdict calculations

For implementation details, see [[Source Reliability Deep Dive>>FactHarbor.Specification.Architecture.Deep Dive.Source Reliability.WebHome]].

== Confidence Calibration ==

A 4-layer deterministic post-processing system prevents misleading confidence scores.

{{mermaid}}
flowchart LR
    RAW["Raw LLM\nConfidence"]
    D["Density\nAnchor"]
    B["Band\nSnapping"]
    V["Verdict\nCoupling"]
    C["Context\nConsistency"]
    CAL["Calibrated\nConfidence"]

    RAW --> D --> B --> V --> C --> CAL

    style RAW fill:#ffcdd2,stroke:#b71c1c,color:#000
    style CAL fill:#c8e6c9,stroke:#2e7d32,color:#000
    style D fill:#e3f2fd,stroke:#1565c0,color:#000
    style B fill:#e3f2fd,stroke:#1565c0,color:#000
    style V fill:#e3f2fd,stroke:#1565c0,color:#000
    style C fill:#e3f2fd,stroke:#1565c0,color:#000
{{/mermaid}}

//Raw LLM confidence passes through 4 calibration layers: density anchor sets a minimum floor based on evidence quality, band snapping reduces jitter by aligning to a 7-band system, verdict coupling ensures strong verdicts have adequate confidence, and context consistency penalises divergent confidence across analysis contexts.//

|= Layer |= Purpose |= Effect
| **Evidence density anchor** | Sets minimum confidence floor based on evidence quality and quantity | Floor ranges from 15% (minimal evidence) to 60% (strong evidence)
| **Band snapping** | Aligns confidence to a 7-band system with partial blending (strength 0.7) | Reduces run-to-run jitter by ~5-10pp
| **Verdict-confidence coupling** | Ensures strong verdicts (>=70% or <=30% truth) have confidence >= 50% | Prevents "TRUE with 20% confidence" anomalies
| **Context consistency** | Penalises confidence divergence >25pp across analysis contexts | Ensures consistent confidence across perspectives

=== Additional Confidence Penalties ===

|= Penalty |= Trigger |= Effect
| **Graduated recency penalty** | Evidence is dated (staleness x volatility x volume formula) | Reduces confidence proportionally to evidence age
| **Low-source penalty** | 2 or fewer sources found | -15pp confidence (configurable)
| **Confidence floor** | Always applied | Minimum 10% confidence (configurable)

All calibration layers are configurable via UCM (##confidenceCalibration## section in Calculation Config) and can be individually toggled on/off.

== Deep Dives ==

* [[Quality Gates>>FactHarbor.Specification.Architecture.Deep Dive.Quality Gates.WebHome]] — Detailed Gate 1 and Gate 4 reference with examples
* [[Evidence Quality Filtering>>FactHarbor.Specification.Architecture.Deep Dive.Evidence Quality Filtering.WebHome]] — Full 7-layer specification, filter rules, troubleshooting
* [[Source Reliability>>FactHarbor.Specification.Architecture.Deep Dive.Source Reliability.WebHome]] — Evaluation methodology, caching, multi-language support
* [[Confidence Calibration>>FactHarbor.Specification.Architecture.Deep Dive.Confidence Calibration.WebHome]] — Layer-by-layer detail, formulas, configuration reference
* [[Calculations and Verdicts>>FactHarbor.Specification.Architecture.Deep Dive.Calculations and Verdicts.WebHome]] — Aggregation hierarchy, weighting formulas

----

**Navigation:** [[Architecture>>FactHarbor.Specification.Architecture.WebHome]] | Prev: [[Storage and Configuration>>FactHarbor.Specification.Architecture.Storage and Configuration.WebHome]] | Next: [[Security and Operations>>FactHarbor.Specification.Architecture.Security and Operations.WebHome]]
