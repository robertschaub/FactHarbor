= AKEL Pipeline Flow =

=== High-Level Flow ===

{{mermaid}}
flowchart TB
    subgraph Input["ğŸ“¥ Input Layer"]
        URL[URL Input]
        TEXT[Text Input]
    end

    subgraph Retrieval["ğŸ” Content Retrieval"]
        FETCH[extractTextFromUrl]
        PDF[PDF Parser<br/>pdf2json]
        HTML[HTML Parser<br/>cheerio]
    end

    subgraph AKEL["ğŸ§  AKEL Pipeline"]
        direction TB

        subgraph Step1["Step 1: Understand"]
            UNDERSTAND[understandClaim<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Detect input type<br/>â€¢ Extract claims<br/>â€¢ Identify dependencies<br/>â€¢ Assign risk tiers]
            LLM1[("ğŸ¤– LLM Call #1<br/>Claude/GPT/Gemini")]
        end

        subgraph Step2["Step 2: Research (Iterative)"]
            DECIDE[decideNextResearch<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Generate queries<br/>â€¢ Focus areas]

            SEARCH[("ğŸŒ Web Search<br/>Google CSE / SerpAPI")]

            FETCHSRC[fetchSourceContent<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Parallel fetching<br/>â€¢ Timeout handling]

            EXTRACT[extractEvidence<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Parse sources<br/>â€¢ Extract evidence]
            LLM2[("ğŸ¤– LLM Call #2-N<br/>Per source")]
        end

        subgraph Step3["Step 3: Verdict Generation"]
            VERDICT[generateVerdicts<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Claim verdicts<br/>â€¢ Article verdict<br/>â€¢ Dependency propagation]
            LLM3[("ğŸ¤– LLM Call #N+1<br/>Final synthesis")]
        end

        subgraph Step4["Step 4: Summary"]
            SUMMARY[generateTwoPanelSummary<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Format results<br/>â€¢ Build two-panel summary]
        end

        subgraph Step5["Step 5: Report"]
            REPORT[generateReport<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Generate markdown]
        end
    end

    subgraph Output["ğŸ“¤ Output"]
        RESULT[AnalysisResult JSON]
        MARKDOWN[Report Markdown]
    end

    %% Flow connections
    URL --> FETCH
    TEXT --> UNDERSTAND
    FETCH --> PDF
    FETCH --> HTML
    PDF --> UNDERSTAND
    HTML --> UNDERSTAND

    UNDERSTAND --> LLM1
    LLM1 --> DECIDE

    DECIDE --> SEARCH
    SEARCH --> FETCHSRC
    FETCHSRC --> EXTRACT
    EXTRACT --> LLM2
    LLM2 --> DECIDE

    DECIDE -->|"Research Complete"| VERDICT
    VERDICT --> LLM3
    LLM3 --> SUMMARY
    SUMMARY --> REPORT

    REPORT --> RESULT
    REPORT --> MARKDOWN
{{/mermaid}}

=== Pipeline Steps Detail ===

**Step 1: Understand (understandClaim)**
* Detects input type: question | statement | article
* Extracts claims with dependencies
* Assigns risk tiers (A/B/C)
* Detects context(s) and temporal boundaries
* Discovers KeyFactors (optional decomposition questions)
* Applies Gate 1: Claim Validation

**Step 2: Research (decideNextResearch + extractEvidence)**
* Iterative research cycle (typically 2-3 rounds)
* Generates search queries targeting gaps
* Fetches and parses sources (HTML, PDF)
* Extracts evidence from each source
* Continues until research is complete or max rounds reached

**Step 3: Verdict Generation (generateVerdicts)**
* Generates verdicts for each claim
* Aggregates claim verdicts into KeyFactor verdicts
* Aggregates KeyFactor verdicts into context answers
* Generates overall article verdict
* Applies Gate 4: Verdict Confidence Assessment

**Step 4: Summary (generateTwoPanelSummary)**
* Builds two-panel summary (Overview + Key Findings)
* Formats verdict data for display

**Step 5: Report (generateReport)**
* Generates markdown report
* Includes all sections: Summary, Claims, Sources, Verdict

----

**Navigation:** [[Implementation>>FactHarbor.Specification.Implementation.WebHome]] | Related: [[Architecture>>FactHarbor.Specification.Architecture.WebHome]]
