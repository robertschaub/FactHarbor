{{info}}
**Current Implementation (v2.6.33)** - Single-context LLM analysis with tool calls, producing canonical schema output. File: ##monolithic-canonical.ts## (~1100 lines)
{{/info}}

= Monolithic Canonical Pipeline Internal Flow =

{{mermaid}}

flowchart TB
    subgraph Entry[Entry Point]
        INPUT[runMonolithicCanonical]
        BUDGET[Initialize Budget maxIterations 5 maxSearches 8]
        TIMEOUT[Start timeout 3 minutes]
    end

    subgraph Phase1[Phase 1: Claim Extraction]
        EXTRACT[LLM Call ClaimExtractionSchema]
        SCOPES[detectContexts heuristic fallback]
        CLAIMS[Build subClaims array]
    end

    subgraph Phase2[Phase 2: Research Loop]
        SEARCH[searchWebWithProvider]
        FETCH[fetchSourceContent parallel]
        EXTRACT_EV[LLM Call EvidenceExtractionSchema]
        PROVENANCE[filterEvidenceByProvenance]
        ITER_CHECK{Iteration limit?}
    end

    subgraph Phase3[Phase 3: Verdict Generation]
        VERDICT[LLM Call VerdictSchema]
        WEIGHT[calculateWeightedVerdictAverage]
        HARM[detectHarmPotential]
        CONTEST[detectClaimContestation]
    end

    subgraph Transform[Schema Transform]
        CANONICAL[Transform to canonical schema]
        REPORT[Generate markdown report]
    end

    subgraph Output[Output]
        RESULT[resultJson canonical]
        MARKDOWN[reportMarkdown]
    end

    subgraph Fallback[Fallback on Failure]
        FALLBACK[Fall back to Orchestrated]
    end

    INPUT --> BUDGET
    BUDGET --> TIMEOUT
    TIMEOUT --> EXTRACT

    EXTRACT --> SCOPES
    SCOPES --> CLAIMS

    CLAIMS --> SEARCH
    SEARCH --> FETCH
    FETCH --> EXTRACT_EV
    EXTRACT_EV --> PROVENANCE
    PROVENANCE --> ITER_CHECK
    ITER_CHECK -->|No| SEARCH
    ITER_CHECK -->|Yes| VERDICT

    VERDICT --> WEIGHT
    WEIGHT --> HARM
    HARM --> CONTEST
    CONTEST --> CANONICAL

    CANONICAL --> REPORT
    REPORT --> RESULT
    REPORT --> MARKDOWN

    EXTRACT -.->|Schema validation fail| FALLBACK
    VERDICT -.->|Schema validation fail| FALLBACK

{{/mermaid}}

= Key Characteristics =

|= Feature |= Description
| **Single Context** | All analysis in one LLM conversation context
| **Structured Output** | Uses AI SDK ##Output.object## with Zod schemas
| **Canonical Schema** | Output compatible with existing Jobs UI
| **Fail Closed** | Falls back to Orchestrated pipeline on validation failure
| **Budget Enforcement** | Hard limits on iterations, searches, fetches, time

= Budget Configuration =

|= Parameter |= Value |= Purpose
| maxIterations | 5 | Maximum research iterations
| maxSearches | 8 | Maximum web searches
| maxFetches | 10 | Maximum source fetches
| timeoutMs | 180000 | 3 minute hard timeout

= Zod Schemas Used =

|= Schema |= Purpose
| ##ClaimExtractionSchema## | Extract mainClaim, claimType, searchQueries, subClaims, analysisContexts
| ##EvidenceExtractionSchema## | Extract evidence items with source attribution
| ##VerdictSchema## | Generate verdicts with truthPercentage, confidence

= Shared Modules Used =

* ##analysis-contexts.ts## - detectContexts, formatDetectedContextsHint (heuristic fallback)
* ##aggregation.ts## - calculateWeightedVerdictAverage, detectHarmPotential, detectClaimContestation
* ##claim-decomposition.ts## - normalizeClaimText, deriveCandidateClaimTexts
* ##provenance-validation.ts## - filterEvidenceByProvenance
* ##budgets.ts## - createBudgetTracker, getBudgetConfig, recordLLMCall

= Differences from Orchestrated =

|= Aspect |= Orchestrated |= Monolithic Canonical
| LLM Context | Multiple calls, fresh context | Single conversation context
| Orchestration | TypeScript code controls flow | LLM decides next steps
| Research | Iterative decide-search-extract | Tool loop with budget limits
| Schema | Built-in TypeScript types | Zod schema validation
| Fallback | None (default) | Falls back to Orchestrated on failure
| Code Size | ~12000 lines | ~1100 lines