{{info}}
**Current Implementation (CB Pipeline v2.11.0+)** â€” This ERD shows the ClaimAssessmentBoundary pipeline data model as implemented in ##types.ts## and stored as JSON blobs in SQLite ##ResultJson## field.

Updated 2026-02-22 per source code audit against ##apps/web/src/lib/analyzer/types.ts## (CB pipeline interfaces: ##AtomicClaim##, ##ClaimAssessmentBoundary##, ##CBClaimVerdict##, ##BoundaryFinding##, ##OverallAssessment##, ##VerdictNarrative##, ##CBClaimUnderstanding##, etc.).
{{/info}}

= ClaimAssessmentBoundary Data Model (v2.11.0+) =

{{mermaid}}

erDiagram
    INPUT_ARTICLE ||--o{ ATOMIC_CLAIM : "extracts"
    ATOMIC_CLAIM ||--o{ SEARCH_QUERY : "generates"
    SEARCH_QUERY }o--o{ SOURCE : "discovers"
    SOURCE ||--o{ EVIDENCE_ITEM : "yields"
    EVIDENCE_ITEM |o--o| EVIDENCE_SCOPE : "has"
    EVIDENCE_SCOPE }o--|| CLAIM_ASSESSMENT_BOUNDARY : "clusters into"
    EVIDENCE_ITEM }o--|| CLAIM_ASSESSMENT_BOUNDARY : "assigned to"
    ATOMIC_CLAIM ||--o{ CB_CLAIM_VERDICT : "receives"
    CB_CLAIM_VERDICT }o--o{ EVIDENCE_ITEM : "cites"
    CB_CLAIM_VERDICT }o--o| CLAIM_ASSESSMENT_BOUNDARY : "scoped by"
    CB_CLAIM_VERDICT }o--|| OVERALL_ASSESSMENT : "aggregates into"
    OVERALL_ASSESSMENT ||--o{ CLAIM_ASSESSMENT_BOUNDARY : "presents"
    CB_CLAIM_VERDICT ||--o{ BOUNDARY_FINDING : "contains"
    BOUNDARY_FINDING }o--|| CLAIM_ASSESSMENT_BOUNDARY : "per boundary"

    INPUT_ARTICLE {
        string id_PK
        string inputType "text or url"
        string detectedInputType "claim or article"
        string impliedClaim "LLM-extracted thesis"
        string articleThesis
        string backgroundDetails
        string riskTier "A B or C"
    }

    ATOMIC_CLAIM {
        string id_PK "AC_01 AC_02"
        string statement "The verifiable assertion"
        string category "factual evaluative procedural"
        string centrality "high medium"
        string harmPotential "critical high medium low"
        boolean isCentral "Always true (filtered)"
        string claimDirection "supports_thesis contradicts_thesis contextual"
        string verifiability "high medium low none (optional)"
        string checkWorthiness "high medium"
        float specificityScore "0-1 Gate1 min 0.6"
        string groundingQuality "strong moderate weak none"
        json keyEntities "Named entities referenced"
        json expectedEvidenceProfile "methodologies metrics sourceTypes"
    }

    SEARCH_QUERY {
        string query
        int iteration
        string focus "Evidence type sought"
        int resultsCount
        string timestamp
        string searchProvider
    }

    SOURCE {
        string id_PK
        string url
        string title
        string fullText "Retrieved page content"
        float trackRecordScore "0.0-1.0"
        float trackRecordConfidence "0.0-1.0"
        boolean trackRecordConsensus
        string category
        boolean fetchSuccess
        string fetchedAt
    }

    EVIDENCE_ITEM {
        string id_PK "EV_001 EV_002"
        string statement "Extracted evidence text"
        string category "statistic expert_quote event legal_provision etc"
        string sourceId_FK
        string sourceUrl
        string sourceTitle
        string sourceExcerpt
        string claimDirection "supports contradicts neutral"
        string probativeValue "high medium low"
        float extractionConfidence "0-100"
        string claimBoundaryId_FK "Assigned in Stage 3"
        json relevantClaimIds "Which claims this relates to"
        string scopeQuality "complete partial incomplete"
        string sourceType "peer_reviewed_study news_primary etc"
        boolean isDerivative "Cites another source study"
        string derivedFromSourceUrl "Original source URL"
        boolean derivativeClaimUnverified "Original source not fetched"
    }

    EVIDENCE_SCOPE {
        string name "Short label: WTW TTW EU-LCA"
        string methodology "ISO 14040 EU RED II etc"
        string temporal "Source data time period"
        string boundaries "What is included or excluded"
        string geographic "Source data geography"
        string sourceType "peer_reviewed_study government_report etc"
        map additionalDimensions "Domain-specific scope data"
    }

    CLAIM_ASSESSMENT_BOUNDARY {
        string id_PK "CB_01 CB_02"
        string name "Human-readable label"
        string shortName "Short label for UI tabs"
        string description "What this boundary represents"
        string methodology "Dominant methodology"
        string boundaries "Scope boundaries"
        string geographic "Geographic scope"
        string temporal "Temporal scope"
        json constituentScopes "EvidenceScopes composing this boundary"
        float internalCoherence "0-1 consistency"
        int evidenceCount
    }

    CB_CLAIM_VERDICT {
        string id_PK
        string claimId_FK
        float truthPercentage "0-100"
        string verdict "7-point scale label"
        float confidence "0-100"
        string reasoning "LLM-generated explanation"
        string harmPotential "critical high medium low"
        boolean isContested
        json supportingEvidenceIds_FK
        json contradictingEvidenceIds_FK
        json boundaryFindings "Per-boundary signals"
        json consistencyResult "Self-consistency check"
        json challengeResponses "Adversarial challenge responses"
        json triangulationScore "Cross-boundary agreement"
        json truthPercentageRange "min max plausible range"
        string misleadingness "not_misleading potentially highly (optional)"
        string misleadingnessReason "Reason (optional)"
    }

    BOUNDARY_FINDING {
        string boundaryId_FK
        string boundaryName
        float truthPercentage "Per-boundary 0-100"
        float confidence "Per-boundary 0-100"
        string evidenceDirection "supports contradicts mixed neutral"
        int evidenceCount
    }

    OVERALL_ASSESSMENT {
        float truthPercentage "0-100 weighted"
        string verdict "7-point scale label"
        float confidence "0-100 weighted"
        boolean hasMultipleBoundaries
        json claimBoundaries "All ClaimAssessmentBoundary objects"
        json claimVerdicts "All CBClaimVerdict objects"
        json verdictNarrative "headline keyFinding limitations"
        json coverageMatrix "claims x boundaries"
        json qualityGates "gate1Stats gate4Stats"
        json truthPercentageRange "min max plausible range"
    }

{{/mermaid}}

== Key Implementation Notes ==

**7-Point Verdict Scale:**
* TRUE (86-100%) / MOSTLY-TRUE (72-85%) / LEANING-TRUE (58-71%)
* MIXED (43-57%, confidence >= 40%) / UNVERIFIED (43-57%, confidence < 40%)
* LEANING-FALSE (29-42%) / MOSTLY-FALSE (15-28%) / FALSE (0-14%)

**EvidenceScope (mandatory core fields):** Per-evidence metadata describing the methodology and boundaries of the source data. ##methodology## and ##temporal## are the primary scope dimensions populated when available from the source. All fields except ##name## are optional in the TypeScript interface, but the extraction prompt targets methodology and temporal as mandatory when source data permits. Embedded in EvidenceItem, not a separate stored entity. Extensible via ##additionalDimensions## (Decision D4).

**harmPotential (4-level, Decision D9):** ##critical## (1.5x weight) = death/injury allegations, ##high## (1.2x) = serious but not life-threatening, ##medium## (1.0x) = moderate, ##low## (1.0x) = minimal. Applied to both AtomicClaim and CBClaimVerdict.

**claimDirection "contextual" (Decision D6):** Evidence providing relevant background without directional stance. Renamed from "neutral" to clarify semantics. Used in AtomicClaim. Note: EvidenceItem still uses "supports" / "contradicts" / "neutral" for backward compatibility.

**Derivative evidence (CB pipeline):** Evidence items that cite another source's underlying study are flagged with ##isDerivative## and ##derivedFromSourceUrl##. If the original source was not fetched, ##derivativeClaimUnverified## = true. Derivative evidence receives reduced weight in aggregation.

**VerdictNarrative (Decision D7):** Structured type with ##headline##, ##evidenceBaseSummary##, ##keyFinding##, ##boundaryDisagreements[]##, and ##limitations##. LLM-generated (Sonnet, 1 call) after weighted aggregation. Stored within OverallAssessment.

**BoundaryFinding:** Per-boundary quantitative signals within a CBClaimVerdict. Provides nuance when different methodological boundaries yield different conclusions about the same claim. Each BoundaryFinding records truth percentage, confidence, evidence direction, and evidence count for one ClaimAssessmentBoundary.

**Self-Consistency & Triangulation:** CBClaimVerdict includes ##consistencyResult## (spread of truth percentages across multiple LLM runs) and ##triangulationScore## (cross-boundary agreement: strong/moderate/weak/conflicted). Both influence final confidence.

**Adversarial Challenge:** CBClaimVerdict includes ##challengeResponses## recording how each adversarial challenge point was addressed in reconciliation. Challenges must be evidence-backed to adjust verdicts; unsubstantiated objections do not reduce truth percentage.

**Misleadingness (B-7):** Optional independent assessment on CBClaimVerdict. Values: ##not_misleading##, ##potentially_misleading##, ##highly_misleading##. Output-only; not fed back into the debate.

**Storage:** All data stored as JSON blob in SQLite ##ResultJson## field. Schema version: ##3.0.0-cb##.

**See Also:** [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]] for multi-view field-level detail. [[Quality Gates Flow>>FactHarbor.Product Development.Diagrams.Quality Gates Flow.WebHome]] for Gate 1 and Gate 4 detail.
