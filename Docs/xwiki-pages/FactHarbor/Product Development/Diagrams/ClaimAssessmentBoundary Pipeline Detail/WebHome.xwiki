= ClaimAssessmentBoundary Pipeline Detail =

{{info}}
**Current Architecture (v2.11.0+):** The ClaimAssessmentBoundary pipeline is the production default pipeline. Source: ##claimboundary-pipeline.ts## and ##verdict-stage.ts##. For architecture reference, see [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]].

Updated 2026-02-19 — Stage 4 verdict steps corrected to match ##verdict-stage.ts## implementation.
{{/info}}

{{mermaid}}
flowchart TB
    subgraph Entry["Entry Point"]
        START["runClaimBoundaryAnalysis()"]
        INIT["Initialize State<br/>Budget tracker, timeline, config"]
    end

    subgraph Stage1["Stage 1: EXTRACT CLAIMS"]
        CLASSIFY["[LLM] Input Classification<br/>article vs claim, topic identification"]
        DECOMPOSE["[LLM] Claim Decomposition<br/>Extract atomic claims (maxAtomicClaims)"]
        PRELIM_SEARCH["[WEB] Preliminary Search<br/>Grounding pass (2 queries × 5 sources per claim)"]
        PRELIM_EXTRACT["[LLM] Preliminary Evidence<br/>Extract evidence from prelim sources"]
        GATE1["Gate 1: Claim Validation<br/>Filter opinion/prediction/vague<br/>Central claims auto-pass"]
        CLAIMS_OUT["AtomicClaim[] (5-15 claims)"]
    end

    subgraph Stage2["Stage 2: RESEARCH EVIDENCE"]
        RESEARCH_LOOP["Research Loop (maxResearchIterations)"]
        SUFFICIENCY["Claim Sufficiency Check<br/>claimSufficiencyThreshold (default: 3)"]
        CONTRADICTION["Contradiction Search<br/>Reserved iterations (default: 2)"]
        DECIDE_NEXT["decideNextResearch()<br/>Priority: unsufficient → central → high-harm"]
        SEARCH["[WEB] searchWebWithProvider()"]
        RELEVANCE["[LLM] assessSearchRelevance()<br/>Primary / secondary / unrelated"]
        FETCH["[WEB] fetchSourceContent()"]
        SR_PREFETCH["[EXT] prefetchSourceReliability()<br/>Batch lookup (async)"]
        EXTRACT["[LLM] extractEvidence()<br/>Per source → EvidenceItem[]"]
        EVIDENCE_OUT["EvidenceItem[] (boundary-unassigned)"]
    end

    subgraph Stage3["Stage 3: CLUSTER BOUNDARIES"]
        PROPOSE["[LLM] Propose ClaimAssessmentBoundaries<br/>Evidence-emergent clustering"]
        VALIDATE["Structural Validation<br/>Coverage, coherence, overlap checks"]
        MERGE{"Merge needed?<br/>(>maxClaimBoundaries)"}
        MERGE_BOUNDARIES["[LLM] Merge similar boundaries<br/>Reduce count, preserve coverage"]
        ASSIGN["Assign evidence to boundaries<br/>+ build coverage matrix"]
        BOUNDARIES_OUT["ClaimAssessmentBoundary[]<br/>CoverageMatrix"]
    end

    subgraph Stage4["Stage 4: VERDICT (verdict-stage.ts)"]
        ADVOCATE["[LLM] Step 1: Advocate Verdict (Sonnet)<br/>Initial verdicts for all claims<br/>with per-boundary signals"]
        SELF_CONSIST{"selfConsistencyMode?"}
        SC_CHECK["[LLM] Step 2: Self-Consistency (Sonnet x2)<br/>Re-run at temp=0.3, measure spread"]
        CHALLENGE["[LLM] Step 3: Adversarial Challenge (Sonnet)<br/>Argue against emerging verdicts"]
        RECONCILE["[LLM] Step 4: Reconciliation (Sonnet)<br/>Final verdicts incorporating challenges"]
        VALIDATE["[LLM] Step 5: Verdict Validation (Haiku x2)<br/>Grounding check + direction check"]
        STRUCT_CHECK["Structural Consistency Check<br/>(deterministic)"]
        TRIANGULATION["Triangulation Scoring<br/>Cross-boundary agreement"]
        VERDICTS_OUT["CBClaimVerdict[] (with triangulation)"]
    end

    subgraph Stage5["Stage 5: AGGREGATE ASSESSMENT"]
        WEIGHTED_AVG["calculateWeightedVerdictAverage()<br/>Centrality + harm + triangulation weights"]
        CONTEST_DETECT["detectClaimContestation()<br/>factualBasis classification"]
        HARM_DETECT["detectHarmPotential()<br/>4-level: critical/high/medium/low"]
        NARRATIVE["[LLM] Generate VerdictNarrative<br/>Headline, key finding, limitations"]
        GATE4["Gate 4: Verdict Confidence<br/>HIGH/MEDIUM/LOW/INSUFFICIENT distribution"]
        ENVELOPE["Result Envelope<br/>schemaVersion: 3.0.0-cb"]
    end

    START --> INIT
    INIT --> CLASSIFY
    CLASSIFY --> DECOMPOSE
    DECOMPOSE --> PRELIM_SEARCH
    PRELIM_SEARCH --> PRELIM_EXTRACT
    PRELIM_EXTRACT --> GATE1
    GATE1 --> CLAIMS_OUT

    CLAIMS_OUT --> RESEARCH_LOOP
    RESEARCH_LOOP --> SUFFICIENCY
    SUFFICIENCY -->|"insufficient"| DECIDE_NEXT
    SUFFICIENCY -->|"sufficient"| CONTRADICTION
    CONTRADICTION --> DECIDE_NEXT
    DECIDE_NEXT --> SEARCH
    SEARCH --> RELEVANCE
    RELEVANCE --> FETCH
    FETCH --> SR_PREFETCH
    SR_PREFETCH --> EXTRACT
    EXTRACT --> EVIDENCE_OUT
    EVIDENCE_OUT -->|"loop continues"| RESEARCH_LOOP

    EVIDENCE_OUT --> PROPOSE
    PROPOSE --> VALIDATE
    VALIDATE --> MERGE
    MERGE -->|"yes"| MERGE_BOUNDARIES
    MERGE_BOUNDARIES --> ASSIGN
    MERGE -->|"no"| ASSIGN
    ASSIGN --> BOUNDARIES_OUT

    BOUNDARIES_OUT --> ADVOCATE
    ADVOCATE --> SELF_CONSIST
    SELF_CONSIST -->|"enabled"| SC_CHECK
    SELF_CONSIST -->|"disabled"| CHALLENGE
    SC_CHECK --> CHALLENGE
    CHALLENGE --> RECONCILE
    RECONCILE --> VALIDATE
    VALIDATE --> STRUCT_CHECK
    STRUCT_CHECK --> TRIANGULATION
    TRIANGULATION --> VERDICTS_OUT

    VERDICTS_OUT --> WEIGHTED_AVG
    WEIGHTED_AVG --> CONTEST_DETECT
    CONTEST_DETECT --> HARM_DETECT
    HARM_DETECT --> NARRATIVE
    NARRATIVE --> GATE4
    GATE4 --> ENVELOPE

    style Stage1 fill:#e8f5e9,stroke:#2e7d32,color:#000
    style Stage2 fill:#fff9c4,stroke:#f57f17,color:#000
    style Stage3 fill:#e3f2fd,stroke:#1565c0,color:#000
    style Stage4 fill:#f3e5f5,stroke:#7b1fa2,color:#000
    style Stage5 fill:#fce4ec,stroke:#c2185b,color:#000
{{/mermaid}}

== Key Features ==

* **Evidence-emergent boundaries:** ClaimAssessmentBoundaries emerge from evidence clustering (Stage 3), not pre-detected
* **5-step LLM debate:** Each verdict goes through structured debate (advocate → self-consistency → adversarial challenge → reconciliation → validation). Steps 2+3 run in parallel.
* **Self-consistency checking:** Optional re-run with temperature variance to detect unstable verdicts (stable/moderate/unstable spread thresholds)
* **Triangulation scoring:** Cross-boundary agreement assessment (strong/moderate/weak/conflicted levels)
* **Quality gates:** Gate 1 (claim validation) and Gate 4 (verdict confidence distribution) are mandatory checkpoints
* **UCM-configurable:** 24 pipeline parameters organized by stage, editable in Admin UI

== Comparison to Legacy Pipelines ==

| Aspect | Orchestrated (removed v2.11.0) | ClaimAssessmentBoundary (v2.11.0+) |
|--------|-------------------------------|-----------------------------------|
| **Context detection** | Pre-detected AnalysisContexts | Evidence-emergent ClaimAssessmentBoundaries |
| **Verdict generation** | Single LLM call per claim | 5-step debate pattern |
| **Cross-boundary analysis** | None | Triangulation scoring |
| **Self-consistency** | None | Optional spread checking |
| **Budget control** | Per-context iteration limits | Claim sufficiency + reserved contradiction iterations |
| **Schema version** | 2.x or 3.0.0 | 3.0.0-cb |

== Sequence Diagram ==

Component interaction during a full ClaimAssessmentBoundary pipeline analysis.

{{mermaid}}
sequenceDiagram
    participant UI as Client/UI
    participant API as API (ASP.NET)
    participant Runner as Runner (Next.js)
    participant Pipeline as CB Pipeline
    participant LLM as LLM Service
    participant Search as Web Search
    participant SR as Source Reliability

    UI->>API: POST /api/jobs (create job)
    API->>Runner: POST /api/internal/run-job
    Runner->>Pipeline: runClaimBoundaryAnalysis(jobId)

    Note over Pipeline: Stage 1: EXTRACT CLAIMS
    Pipeline->>LLM: Pass 1: extractAtomicClaims (Haiku)
    LLM-->>Pipeline: AtomicClaim[] (rough)
    Pipeline->>Search: preliminarySearch (thesis + top claims)
    Search-->>Pipeline: SearchResult[]
    Pipeline->>LLM: extractPreliminaryEvidence (Haiku)
    LLM-->>Pipeline: EvidenceItem[] + EvidenceScope[]
    Pipeline->>LLM: Pass 2: groundedClaimExtraction (Sonnet)
    LLM-->>Pipeline: AtomicClaim[] (refined)
    Pipeline->>LLM: Gate 1: validateClaims (Haiku)
    LLM-->>Pipeline: Gate1Result

    Note over Pipeline: Stage 2: RESEARCH
    loop For each research iteration
        Pipeline->>LLM: generateSearchQueries (Haiku)
        Pipeline->>Search: execute(queries)
        Search-->>Pipeline: SearchResult[]
        Pipeline->>LLM: classifyRelevance (Haiku)
        Pipeline->>Pipeline: fetchSources(relevantUrls)
        Pipeline->>SR: prefetchSourceReliability(urls)
        Pipeline->>LLM: extractEvidence (Haiku)
        LLM-->>Pipeline: EvidenceItem[] + EvidenceScope[]
        Pipeline->>API: updateProgress(jobId, %)
    end

    Note over Pipeline: Stage 3: CLUSTER BOUNDARIES
    Pipeline->>LLM: clusterEvidenceScopes (Sonnet)
    LLM-->>Pipeline: ClaimAssessmentBoundary[] + assignments

    Note over Pipeline: Stage 4: VERDICT (verdict-stage.ts)
    Pipeline->>LLM: Step 1: Advocate Verdict (Sonnet)
    LLM-->>Pipeline: CBClaimVerdict[] (initial)
    par Steps 2+3 (parallel)
        Pipeline->>LLM: Step 2: Self-Consistency (Sonnet x2, temp=0.3)
        LLM-->>Pipeline: ConsistencyResult[]
    and
        Pipeline->>LLM: Step 3: Adversarial Challenge (Sonnet)
        LLM-->>Pipeline: ChallengeDocument
    end
    Pipeline->>LLM: Step 4: Reconciliation (Sonnet)
    LLM-->>Pipeline: CBClaimVerdict[] (final)
    Pipeline->>LLM: Step 5a: Grounding Validation (Haiku)
    Pipeline->>LLM: Step 5b: Direction Validation (Haiku)

    Note over Pipeline: Stage 5: AGGREGATE
    Pipeline->>Pipeline: computeCoverageMatrix + triangulation
    Pipeline->>Pipeline: weightedAggregation
    Pipeline->>LLM: generateVerdictNarrative (Sonnet)
    LLM-->>Pipeline: VerdictNarrative
    Pipeline->>API: submitResults(jobId, report)
    API-->>UI: Job complete
{{/mermaid}}

== LLM Call Budget ==

|= Stage |= LLM Calls |= Model Tier |= Purpose
| Pass 1 Extraction | 1 | Haiku | Quick rough claim scan
| Pass 1 Evidence | 1-3 | Haiku | Extract evidence from preliminary sources
| Pass 2 Extraction | 1 | Sonnet | Evidence-grounded claim extraction
| Gate 1 Validation | 1 | Haiku | Factual + specificity + fidelity check
| Research Queries | N (per claim per iteration) | Haiku | Search query generation
| Relevance Classification | N (per search result batch) | Haiku | Classify search result relevance
| Evidence Extraction | N (per relevant source) | Haiku | Extract evidence + EvidenceScope
| Boundary Clustering | 1 | Sonnet | Cluster EvidenceScopes into boundaries
| Step 1: Advocate | 1 | Sonnet | Initial per-claim verdicts
| Step 2: Self-Consistency | 0 or 2 | Sonnet | Verdict stability (if enabled)
| Step 3: Challenge | 1 | Sonnet | Adversarial challenge document
| Step 4: Reconciliation | 1 | Sonnet | Final verdicts with challenge responses
| Step 5: Validation | 2 | Haiku | Grounding + direction checks (advisory)
| VerdictNarrative | 1 | Sonnet | Structured narrative generation

//Typical total: 20-45 LLM calls per analysis (varies by claim count, research iterations, and self-consistency mode).//

== Related Documentation ==

* [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]] — Architecture reference (pipeline variants, shared modules, budget controls)
* [[Pipeline Variant Dispatch>>FactHarbor.Product Development.Diagrams.Pipeline Variant Dispatch.WebHome]] — How pipelines are selected
* [[Quality Gates Flow>>FactHarbor.Product Development.Diagrams.Quality Gates Flow.WebHome]] — Gate 1 and Gate 4 details
* [[Core Data Model ERD>>FactHarbor.Product Development.Diagrams.Core Data Model ERD.WebHome]] — Entity relationships
* [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]] — Multi-view entity reference
