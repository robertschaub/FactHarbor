= ClaimAssessmentBoundary Pipeline Detail =

{{info}}
**Current Architecture (v2.11.0+):** The ClaimAssessmentBoundary pipeline is the production default pipeline. Source: ##claimboundary-pipeline.ts## and ##verdict-stage.ts##. For architecture reference, see [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]].

Updated 2026-02-22 — B-sequence quality features (B-5a structured challenger, B-4 pro/con queries, B-6 verifiability annotation, B-7 misleadingness, B-8 explanation quality) documented in flowchart, sequence diagram, and LLM Call Budget.
{{/info}}

{{mermaid}}
flowchart TB
    subgraph Entry["Entry Point"]
        START["runClaimBoundaryAnalysis()"]
        INIT["Initialize State<br/>Budget tracker, timeline, config"]
    end

    subgraph Stage1["Stage 1: EXTRACT CLAIMS"]
        CLASSIFY["[LLM] Input Classification<br/>article vs claim, topic identification"]
        DECOMPOSE["[LLM] Claim Decomposition<br/>Extract atomic claims (maxAtomicClaims)"]
        PRELIM_SEARCH["[WEB] Preliminary Search<br/>Grounding pass (2 queries x 5 sources per claim)"]
        PRELIM_EXTRACT["[LLM] Preliminary Evidence<br/>Extract evidence from prelim sources"]
        GATE1["Gate 1: Claim Validation<br/>Filter opinion/prediction/vague<br/>Central claims auto-pass"]
        ANNOTATE["Verifiability Annotation (B-6)<br/>claimAnnotationMode: off|verifiability|...<br/>Assigns high/medium/low/none per claim"]
        CLAIMS_OUT["AtomicClaim[] (5-15 claims)"]
    end

    subgraph Stage2["Stage 2: RESEARCH EVIDENCE"]
        RESEARCH_LOOP["Research Loop (maxTotalIterations)"]
        SUFFICIENCY["Claim Sufficiency Check<br/>claimSufficiencyThreshold (default: 3)"]
        CONTRADICTION["Contradiction Search<br/>Reserved iterations (default: 2)"]
        DECIDE_NEXT["decideNextResearch()<br/>Priority: unsufficient > central > high-harm"]
        QUERY_GEN["[LLM] generateResearchQueries() (B-4)<br/>queryStrategyMode: legacy|pro_con<br/>pro_con: interleaved supporting/refuting<br/>Shared budget (max 3/call)"]
        SEARCH["[WEB] searchWebWithProvider()"]
        RELEVANCE["[LLM] classifyRelevance()<br/>Primary / secondary / unrelated"]
        FETCH["[WEB] fetchSourceContent()"]
        SR_PREFETCH["[EXT] prefetchSourceReliability()<br/>Batch lookup (async)"]
        EXTRACT["[LLM] extractEvidence()<br/>Per source > EvidenceItem[]"]
        EVIDENCE_OUT["EvidenceItem[] (boundary-unassigned)"]
    end

    subgraph Stage3["Stage 3: CLUSTER BOUNDARIES"]
        PROPOSE["[LLM] Propose ClaimAssessmentBoundaries<br/>Evidence-emergent clustering"]
        VALIDATE["Structural Validation<br/>Coverage, coherence, overlap checks"]
        MERGE{"Merge needed?<br/>(>maxClaimBoundaries)"}
        MERGE_BOUNDARIES["[LLM] Merge similar boundaries<br/>Reduce count, preserve coverage"]
        ASSIGN["Assign evidence to boundaries<br/>+ build coverage matrix"]
        BOUNDARIES_OUT["ClaimAssessmentBoundary[]<br/>CoverageMatrix"]
    end

    subgraph Stage4["Stage 4: VERDICT (verdict-stage.ts)"]
        ADVOCATE["[LLM] Step 1: Advocate Verdict (Sonnet)<br/>Initial verdicts for all claims<br/>with per-boundary signals"]
        SELF_CONSIST{"selfConsistencyMode?"}
        SC_CHECK["[LLM] Step 2: Self-Consistency (Sonnet x2)<br/>Re-run at temp=0.3, measure spread"]
        CHALLENGE["[LLM] Step 3: Adversarial Challenge (B-5a)<br/>Structured 5-point analysis (Sonnet):<br/>provenance, bidirectional challenge,<br/>coverage gaps, boundary agreement,<br/>quality asymmetry — evidence IDs mandatory"]
        RECONCILE["[LLM] Step 4: Reconciliation (Sonnet)<br/>Final verdicts incorporating challenges<br/>+ misleadingness assessment (B-7)<br/>when claimAnnotationMode includes it"]
        VERDICT_VAL["[LLM] Step 5: Verdict Validation (Haiku x2)<br/>Grounding check + direction check"]
        STRUCT_CHECK["Structural Consistency Check<br/>(deterministic)"]
        VERDICTS_OUT["CBClaimVerdict[]"]
    end

    subgraph Stage5["Stage 5: AGGREGATE (aggregateAssessment)"]
        TRIANG_STEP["computeTriangulationScore()<br/>Cross-boundary agreement per claim"]
        WEIGHTED_AGG["Weighted Aggregation<br/>Centrality x harm x confidence x<br/>triangulation x derivative weights"]
        NARRATIVE["[LLM] generateVerdictNarrative() (Sonnet)<br/>Headline, key finding, limitations"]
        EXPLAIN_QC["Explanation Quality Check (B-8)<br/>explanationQualityMode: off|structural|rubric<br/>Tier 1: structural (deterministic)<br/>Tier 2: rubric (LLM — Haiku, 5 dimensions)"]
        GATE4["Gate 4: buildQualityGates()<br/>Classify confidence tiers"]
        ENVELOPE["Result Envelope<br/>schemaVersion: 3.0.0-cb"]
    end

    START --> INIT
    INIT --> CLASSIFY
    CLASSIFY --> DECOMPOSE
    DECOMPOSE --> PRELIM_SEARCH
    PRELIM_SEARCH --> PRELIM_EXTRACT
    PRELIM_EXTRACT --> GATE1
    GATE1 --> ANNOTATE
    ANNOTATE --> CLAIMS_OUT

    CLAIMS_OUT --> RESEARCH_LOOP
    RESEARCH_LOOP --> SUFFICIENCY
    SUFFICIENCY -->|"insufficient"| DECIDE_NEXT
    SUFFICIENCY -->|"sufficient"| CONTRADICTION
    CONTRADICTION --> DECIDE_NEXT
    DECIDE_NEXT --> QUERY_GEN
    QUERY_GEN --> SEARCH
    SEARCH --> RELEVANCE
    RELEVANCE --> FETCH
    FETCH --> SR_PREFETCH
    SR_PREFETCH --> EXTRACT
    EXTRACT --> EVIDENCE_OUT
    EVIDENCE_OUT -->|"loop continues"| RESEARCH_LOOP

    EVIDENCE_OUT --> PROPOSE
    PROPOSE --> VALIDATE
    VALIDATE --> MERGE
    MERGE -->|"yes"| MERGE_BOUNDARIES
    MERGE_BOUNDARIES --> ASSIGN
    MERGE -->|"no"| ASSIGN
    ASSIGN --> BOUNDARIES_OUT

    BOUNDARIES_OUT --> ADVOCATE
    ADVOCATE --> SELF_CONSIST
    SELF_CONSIST -->|"enabled"| SC_CHECK
    SELF_CONSIST -->|"disabled"| CHALLENGE
    SC_CHECK --> CHALLENGE
    CHALLENGE --> RECONCILE
    RECONCILE --> VERDICT_VAL
    VERDICT_VAL --> STRUCT_CHECK
    STRUCT_CHECK --> VERDICTS_OUT

    VERDICTS_OUT --> TRIANG_STEP
    TRIANG_STEP --> WEIGHTED_AGG
    WEIGHTED_AGG --> NARRATIVE
    NARRATIVE --> EXPLAIN_QC
    EXPLAIN_QC --> GATE4
    GATE4 --> ENVELOPE

    style Stage1 fill:#e8f5e9,stroke:#2e7d32,color:#000
    style Stage2 fill:#fff9c4,stroke:#f57f17,color:#000
    style Stage3 fill:#e3f2fd,stroke:#1565c0,color:#000
    style Stage4 fill:#f3e5f5,stroke:#7b1fa2,color:#000
    style Stage5 fill:#fce4ec,stroke:#c2185b,color:#000
{{/mermaid}}

== Key Features ==

* **Evidence-emergent boundaries:** ClaimAssessmentBoundaries emerge from evidence clustering (Stage 3), not pre-detected
* **5-step LLM debate:** Each verdict goes through structured debate (advocate > self-consistency > adversarial challenge > reconciliation > validation). Steps 2+3 run in parallel.
* **Structured adversarial analysis (B-5a):** Step 3 challenger performs 5-point analysis — evidence provenance, bidirectional challenge, coverage gaps, boundary agreement scrutiny, quality asymmetry. Every challenge point must cite specific evidence IDs; baseless challenges are discounted by the reconciler.
* **Pro/con query separation (B-4):** UCM ##queryStrategyMode## ("legacy" or "pro_con"). In pro_con mode, research queries are split into supporting and refuting variants, interleaved within a shared budget (max 3 per call).
* **Verifiability annotation (B-6):** UCM ##claimAnnotationMode## controls optional per-claim verifiability assessment (high/medium/low/none) at Gate 1. Independent of claim category — evaluates fact-checkability.
* **Misleadingness detection (B-7):** When ##claimAnnotationMode## = "verifiability_and_misleadingness", the reconciler (Step 4) assesses misleadingness independently of truthPercentage. A claim can be true yet misleading (cherry-picked, missing context, false causation).
* **Explanation quality checks (B-8):** UCM ##explanationQualityMode## ("off", "structural", "rubric"). Tier 1: deterministic structural checks (evidence cited, verdict stated, confidence, limitations). Tier 2: LLM rubric evaluation (clarity, completeness, neutrality, evidence support, hedging — scored 1-5 each).
* **Self-consistency checking:** Optional re-run with temperature variance to detect unstable verdicts (stable/moderate/unstable spread thresholds)
* **Triangulation scoring:** Cross-boundary agreement assessment (strong/moderate/weak/conflicted levels)
* **Quality gates:** Gate 1 (claim validation) and Gate 4 (verdict confidence distribution) are mandatory checkpoints
* **UCM-configurable:** Pipeline parameters organized by stage, editable in Admin UI

== Comparison to Legacy Pipelines ==

| Aspect | Orchestrated (removed v2.11.0) | ClaimAssessmentBoundary (v2.11.0+) |
|--------|-------------------------------|-----------------------------------|
| **Context detection** | Pre-detected AnalysisContexts | Evidence-emergent ClaimAssessmentBoundaries |
| **Verdict generation** | Single LLM call per claim | 5-step debate pattern |
| **Cross-boundary analysis** | None | Triangulation scoring |
| **Self-consistency** | None | Optional spread checking |
| **Budget control** | Per-context iteration limits | Claim sufficiency + reserved contradiction iterations |
| **Schema version** | 2.x or 3.0.0 | 3.0.0-cb |

== Sequence Diagram ==

Component interaction during a full ClaimAssessmentBoundary pipeline analysis, including UCM configuration loading, contradiction search, and evidence quality filtering.

{{mermaid}}
sequenceDiagram
    participant UI as Client/UI
    participant API as API (ASP.NET)
    participant Runner as Runner (Next.js)
    participant Pipeline as ClaimAssessmentBoundary Pipeline
    participant LLM as LLM Service
    participant Search as Web Search
    participant SR as Source Reliability
    participant UCM as Config (UCM)

    UI->>API: POST /api/jobs (create job)
    API->>Runner: POST /api/internal/run-job
    Runner->>Pipeline: runClaimBoundaryAnalysis(jobId)

    Note over Pipeline: Stage 1: EXTRACT CLAIMS
    Pipeline->>UCM: getConfig("pipeline")
    Pipeline->>LLM: [LLM] Pass 1: extractAtomicClaims(inputText) — Haiku
    LLM-->>Pipeline: AtomicClaim[] (with centrality)
    Pipeline->>Search: [Search] preliminarySearch(thesis + top claims)
    Search-->>Pipeline: SearchResult[]
    Pipeline->>LLM: [LLM] Pass 1: extractPreliminaryEvidence(sources) — Haiku
    LLM-->>Pipeline: EvidenceItem[] + EvidenceScope[]
    Pipeline->>LLM: [LLM] Pass 2: groundedClaimExtraction(input + prelim evidence) — Sonnet
    LLM-->>Pipeline: AtomicClaim[] (refined, with groundingQuality)
    Pipeline->>Pipeline: filterCentralClaims()
    Pipeline->>LLM: [LLM] Gate 1: validateClaims(centralClaims) — Haiku
    LLM-->>Pipeline: Gate1Result
    Note right of Pipeline: B-6: If claimAnnotationMode != "off",<br/>verifiability (high/medium/low/none)<br/>retained on each AtomicClaim

    Note over Pipeline: Stage 2: RESEARCH
    loop For each research iteration
        Pipeline->>LLM: [LLM] generateSearchQueries(claim, queryStrategyMode) — Haiku
        Note right of Pipeline: B-4: queryStrategyMode="pro_con"<br/>splits into supporting + refuting variants,<br/>interleaved, shared budget (max 3/call)
        LLM-->>Pipeline: SearchQuery[] (with optional variantType)
        Pipeline->>Search: [Search] execute(queries)
        Search-->>Pipeline: SearchResult[]
        Pipeline->>LLM: [LLM] classifyRelevance(results) — Haiku
        Pipeline->>Pipeline: [Ext] fetchSources(relevantUrls)
        Pipeline->>SR: [Ext] prefetchSourceReliability(urls)
        SR-->>Pipeline: reliabilityScores
        Pipeline->>LLM: [LLM] extractEvidence(sourceText) — Haiku
        LLM-->>Pipeline: EvidenceItem[] + EvidenceScope[] (incl. additionalDimensions)
        Pipeline->>LLM: [LLM] evidenceQualityFilter(items) — Haiku
        Pipeline->>API: [Ext] updateProgress(jobId, stage, %)
    end

    Note over Pipeline: Contradiction Search (reserved)
    Pipeline->>LLM: [LLM] generateContradictionQueries(claims, evidence) — Haiku
    Pipeline->>Search: [Search] execute(contraQueries)
    Pipeline->>LLM: [LLM] extractContraryEvidence(sources) — Haiku

    Note over Pipeline: Stage 3: CLUSTER BOUNDARIES
    Pipeline->>LLM: [LLM] clusterEvidenceScopes(allScopes, allEvidence) — Sonnet
    LLM-->>Pipeline: ClaimAssessmentBoundary[] + assignments
    Pipeline->>Pipeline: assignEvidenceToBoundaries()

    Note over Pipeline: Stage 4: VERDICT (LLM Debate — verdict-stage.ts)
    Pipeline->>LLM: [LLM] Step 1: advocateVerdict(claims, evidence, boundaries) — Sonnet
    LLM-->>Pipeline: ClaimVerdict[] (with per-boundary quantitative signals)

    par Self-Consistency + Adversarial Challenge (parallel)
        Pipeline->>LLM: [LLM] Step 2: selfConsistencyCheck(advocatePrompt x 2, temp=0.3) — Sonnet
        LLM-->>Pipeline: ConsistencyResult[] (spread per claim)
    and
        Pipeline->>LLM: [LLM] Step 3: adversarialChallenge(advocateVerdicts) — Sonnet
        Note right of Pipeline: B-5a: Structured 5-point analysis —<br/>provenance, bidirectional challenge,<br/>coverage gaps, boundary agreement,<br/>quality asymmetry. Evidence IDs mandatory.
        LLM-->>Pipeline: ChallengeDocument (per-claim challenges with evidence IDs)
    end

    Pipeline->>LLM: [LLM] Step 4: reconciliation(verdicts + challenges + consistency) — Sonnet
    Note right of Pipeline: B-7: If claimAnnotationMode includes<br/>misleadingness, reconciler assesses<br/>misleadingness independently of truth%
    LLM-->>Pipeline: Final ClaimVerdict[] (with challenge responses + optional misleadingness)
    Pipeline->>LLM: [LLM] Step 5a: validateVerdictGrounding(verdicts, evidence) — Haiku
    Pipeline->>LLM: [LLM] Step 5b: validateVerdictDirection(verdicts, evidence) — Haiku
    Pipeline->>Pipeline: structuralConsistencyCheck()
    Pipeline->>Pipeline: gate4ConfidenceCheck()

    Note over Pipeline: Stage 5: AGGREGATE
    Pipeline->>Pipeline: computeCoverageMatrix(claims, boundaries, evidence)
    Pipeline->>Pipeline: computeTriangulation(coverageMatrix, verdicts)
    Pipeline->>Pipeline: weightedAggregation(verdicts, triangulation, derivatives)
    Pipeline->>LLM: [LLM] generateVerdictNarrative(verdicts, boundaries, matrix) — Sonnet
    LLM-->>Pipeline: VerdictNarrative
    Note right of Pipeline: B-8: If explanationQualityMode != "off",<br/>run structural check (deterministic).<br/>If "rubric", also LLM evaluation (Haiku).
    Pipeline->>Pipeline: checkExplanationStructure(narrative)
    opt explanationQualityMode = "rubric"
        Pipeline->>LLM: [LLM] evaluateExplanationRubric(narrative) — Haiku
        LLM-->>Pipeline: ExplanationRubricScores (5 dimensions, 1-5 each)
    end
    Pipeline->>Pipeline: assembleReport(claims, evidence, boundaries, verdicts, narrative)
    Pipeline->>API: [Ext] submitResults(jobId, report)
    API-->>UI: Job complete (poll/webhook)
{{/mermaid}}

== LLM Call Budget ==

|= Stage |= LLM Calls |= Model Tier |= Purpose
| Pass 1 Extraction | 1 | Haiku | Quick rough claim scan
| Pass 1 Evidence | 1-3 | Haiku | Extract evidence from preliminary sources
| Pass 2 Extraction | 1 | Sonnet | Evidence-grounded claim extraction (incl. groundingQuality)
| Gate 1 Validation | 1 | Haiku | Factual + specificity + grounding check
| Decomposition Retry | 0-1 | Haiku | Split vague claims (if needed)
| Gate 1 Retry | 0-4 | Haiku+Sonnet | If >50% fail, re-search + re-extract (max 1 retry)
| Research Queries | N (per claim per iteration) | Haiku | Search query generation
| Relevance Classification | N (per search result batch) | Haiku | Accept/reject search results
| Evidence Extraction | N (per relevant source) | Haiku | Extract evidence + mandatory EvidenceScope + isDerivative
| Scope Validation Retry | 0-N | Haiku | Re-extract items with missing scope (if needed)
| Evidence Quality | N (per evidence batch) | Haiku | Quality assessment
| Contradiction Queries | 1 | Haiku | Generate opposing search terms
| Boundary Clustering | 1 | Sonnet | Congruence-based scope clustering
| Step 1: Advocate | 1 | Sonnet | Advocate verdicts with per-boundary signals
| Step 2: Self-Consistency | 0 or 2 | Sonnet | Re-run advocate at elevated temp (parallel with Step 3)
| Step 3: Challenge | 1 | Sonnet | Devil's advocate challenges (parallel with Step 2)
| Step 4: Reconciliation | 1 | Sonnet | Final verdicts incorporating challenges + consistency
| Step 5: Validation | 2 (grounding + direction) | Haiku | Validate verdict quality
| Verdict Narrative | 1 | Sonnet | Generate structured VerdictNarrative for overall assessment
| Explanation Quality Rubric (B-8) | 0 or 1 | Haiku | LLM rubric evaluation (5 dimensions) — only when ##explanationQualityMode## = "rubric"

//Expected total: 18-38 LLM calls per analysis. The 5-7 added calls for the debate pattern + narrative (advocate + 0-2 consistency + challenger + reconciliation + narrative) are offset by eliminating context detection, canonicalization, refinement, and supplemental context calls. B-8 rubric adds 0-1 Haiku call.//

== Related Documentation ==

* [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]] — Architecture reference (pipeline variants, shared modules, budget controls)
* [[Pipeline Variant Dispatch>>FactHarbor.Product Development.Diagrams.Pipeline Variant Dispatch.WebHome]] — How pipelines are selected
* [[Quality Gates Flow>>FactHarbor.Product Development.Diagrams.Quality Gates Flow.WebHome]] — Gate 1 and Gate 4 details
* [[Core Data Model ERD>>FactHarbor.Product Development.Diagrams.Core Data Model ERD.WebHome]] — Entity relationships
* [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]] — Multi-view entity reference
