{{info}}
**Multi-View Entity Reference (CB Pipeline v2.11.0+)** — Five complementary ERD views of the FactHarbor entity landscape. Each view highlights a different aspect: overview, analysis result, target database, runtime processing, and UI visibility.

**Source of truth**: ##apps/web/src/lib/analyzer/types.ts##, ##apps/api/Data/Entities.cs##, ##config-schemas.ts##

Updated 2026-02-19 per CB pipeline interfaces in ##types.ts##.
{{/info}}

= Entity Views =

Five views of the same entity landscape, each serving a different audience and purpose.

|= View |= Purpose |= Audience
| **[[Overview>>||anchor="HOverviewERD"]]** | Bird's-eye view of all entity groups | Everyone (entry point)
| **[[Analysis Result>>||anchor="HAnalysisResultEntities"]]** | Everything persisted in ##resultJson## | Developers, data architects
| **[[Target Database>>||anchor="HTargetDatabaseEntities"]]** | Future PostgreSQL table design | Database architects, backend developers
| **[[Runtime Process>>||anchor="HRuntimeProcessEntities"]]** | Transient entities during pipeline execution | Pipeline developers
| **[[UI Visible>>||anchor="HUI-VisibleEntities"]]** | What users see in the browser | Frontend developers, UX designers

=== Color Legend ===

All views use a consistent color scheme:

|= Color |= Meaning
| (% style="background-color:#c8e6c9; padding:4px;" %)Green | Core analysis (verdicts, claims)
| (% style="background-color:#e3f2fd; padding:4px;" %)Blue | Infrastructure (jobs, config, metrics)
| (% style="background-color:#fff3e0; padding:4px;" %)Orange | Evidence and sources
| (% style="background-color:#e1bee7; padding:4px;" %)Purple | Understanding and decomposition
| (% style="background-color:#fff9c4; padding:4px;" %)Yellow | Quality and validation
| (% style="background-color:#f5f5f5; padding:4px;" %)Grey | Runtime-only / transient
| (% style="background-color:#ffcdd2; padding:4px;" %)Red | Planned / not yet implemented

----

== Overview ERD ==

Bird's-eye view showing all major entity groups and their primary relationships. Minimal field detail — use the other views for field-level information.

{{mermaid}}

erDiagram
    JOB ||--|| ANALYSIS_RESULT : produces
    JOB ||--o{ JOB_EVENT : logs
    JOB }o--|| CONFIG_SNAPSHOT : uses

    ANALYSIS_RESULT ||--|| CB_CLAIM_UNDERSTANDING : contains
    ANALYSIS_RESULT ||--o{ CB_CLAIM_VERDICT : contains
    ANALYSIS_RESULT ||--|| OVERALL_ASSESSMENT : aggregates
    ANALYSIS_RESULT ||--o{ EVIDENCE_ITEM : contains
    ANALYSIS_RESULT ||--o{ FETCHED_SOURCE : contains
    ANALYSIS_RESULT ||--o{ CLAIM_BOUNDARY : contains
    ANALYSIS_RESULT ||--|| QUALITY_GATES : validated_by
    ANALYSIS_RESULT ||--|| TWO_PANEL_SUMMARY : summarized_as

    CB_CLAIM_UNDERSTANDING ||--o{ ATOMIC_CLAIM : extracts

    ATOMIC_CLAIM ||--o{ CB_CLAIM_VERDICT : receives
    CB_CLAIM_VERDICT }o--o{ EVIDENCE_ITEM : cites
    CB_CLAIM_VERDICT ||--o{ BOUNDARY_FINDING : contains
    BOUNDARY_FINDING }o--|| CLAIM_BOUNDARY : per_boundary
    EVIDENCE_ITEM }o--|| FETCHED_SOURCE : extracted_from
    EVIDENCE_ITEM }o--|| CLAIM_BOUNDARY : assigned_to

    OVERALL_ASSESSMENT ||--|| VERDICT_NARRATIVE : has
    OVERALL_ASSESSMENT ||--|| COVERAGE_MATRIX : has

    JOB {
        string jobId_PK
        string status
        string pipelineVariant
    }

    ANALYSIS_RESULT {
        string schemaVersion "3.0.0-cb"
        json meta
    }

    CB_CLAIM_UNDERSTANDING {
        string detectedInputType
        string articleThesis
        string riskTier
    }

    ATOMIC_CLAIM {
        string id_PK
        string statement
        string centrality
        string harmPotential
    }

    CLAIM_BOUNDARY {
        string id_PK
        string name
        string shortName
    }

    CB_CLAIM_VERDICT {
        string claimId_PK
        int truthPercentage
        int confidence
        string verdict
    }

    BOUNDARY_FINDING {
        string boundaryId_FK
        int truthPercentage
        string evidenceDirection
    }

    EVIDENCE_ITEM {
        string id_PK
        string statement
        string probativeValue
    }

    FETCHED_SOURCE {
        string id_PK
        string url
        float trackRecordScore
    }

    OVERALL_ASSESSMENT {
        int truthPercentage
        string verdict
        int confidence
    }

    VERDICT_NARRATIVE {
        string headline
        string keyFinding
    }

    COVERAGE_MATRIX {
        json claims_x_boundaries
    }

    QUALITY_GATES {
        boolean passed
        json gate1Stats
        json gate4Stats
    }

    TWO_PANEL_SUMMARY {
        json articleSummary
        json factharborAnalysis
    }

    CONFIG_SNAPSHOT {
        text hash_PK
        text config_type
    }

    JOB_EVENT {
        long id_PK
        string jobId_FK
        string level
        string message
    }

{{/mermaid}}

//Overview: JOB produces an ANALYSIS_RESULT containing decomposed claims (CB_CLAIM_UNDERSTANDING with ATOMIC_CLAIMs), per-claim verdicts (CB_CLAIM_VERDICT with per-boundary BOUNDARY_FINDINGs) supported by evidence (EVIDENCE_ITEM) from web sources (FETCHED_SOURCE), grouped into evidence-emergent CLAIM_BOUNDARYs, and aggregated into an OVERALL_ASSESSMENT with VERDICT_NARRATIVE and COVERAGE_MATRIX. Quality validation (QUALITY_GATES) and a user-facing summary (TWO_PANEL_SUMMARY) complete the result.//

----

== Analysis Result Entities ==

Everything persisted in the ##resultJson## blob at the end of an analysis. This is the complete entity model inside the JSON. Grouped by pipeline stage.

=== Stage 1: Extract Claims ===

{{mermaid}}

erDiagram
    CB_CLAIM_UNDERSTANDING ||--o{ ATOMIC_CLAIM : extracts
    CB_CLAIM_UNDERSTANDING ||--|| GATE_1_STATS : produces

    CB_CLAIM_UNDERSTANDING {
        string detectedInputType
        string impliedClaim
        string articleThesis
        string backgroundDetails
        string riskTier
        json distinctEvents
        json preliminaryEvidence
    }

    ATOMIC_CLAIM {
        string id_PK "AC_01 AC_02"
        string statement
        string category "factual evaluative procedural"
        string centrality "high medium"
        string harmPotential "critical high medium low"
        boolean isCentral "Always true (filtered)"
        string claimDirection "supports_thesis contradicts_thesis contextual"
        string checkWorthiness "high medium"
        string_array keyEntities "Named entities referenced"
        float specificityScore "0-1"
        string groundingQuality "strong moderate weak none"
        json expectedEvidenceProfile
    }

    GATE_1_STATS {
        int totalClaims
        int passedOpinion
        int passedSpecificity
        int passedFidelity
        int filteredCount
        boolean overallPass
    }

{{/mermaid}}

//Stage 1 output: CB_CLAIM_UNDERSTANDING with ATOMIC_CLAIMs (replacing Orchestrated SUB_CLAIMs). Each claim has centrality, harmPotential (4-level), groundingQuality, and specificityScore. Gate 1 stats include passedFidelity (claim-to-input fidelity check).//

=== Stage 2: Research ===

{{mermaid}}

erDiagram
    EVIDENCE_ITEM }o--|| FETCHED_SOURCE : extracted_from
    EVIDENCE_ITEM ||--|| EVIDENCE_SCOPE : has_scope

    SEARCH_QUERY ||--o{ FETCHED_SOURCE : found

    EVIDENCE_ITEM {
        string id_PK "EV_001 EV_002"
        string statement
        string category "statistic expert_quote event legal_provision etc"
        string sourceId_FK
        string sourceUrl
        string sourceTitle
        string sourceExcerpt
        string claimDirection "supports contradicts neutral"
        string sourceAuthority "primary secondary opinion"
        string evidenceBasis "scientific documented anecdotal theoretical pseudoscientific"
        string probativeValue "high medium low"
        float extractionConfidence "0-100"
        string sourceType "peer_reviewed_study etc"
        string_array relevantClaimIds
        string claimBoundaryId_FK "Assigned in Stage 3"
        boolean isDerivative
        string derivedFromSourceUrl
        boolean derivativeClaimUnverified
        string scopeQuality "complete partial incomplete"
    }

    EVIDENCE_SCOPE {
        string name
        string methodology "Optional"
        string temporal "Optional"
        string boundaries
        string geographic
        string sourceType
        map additionalDimensions
    }

    FETCHED_SOURCE {
        string id_PK
        string url
        string title
        string fullText
        float trackRecordScore "0.0-1.0"
        float trackRecordConfidence
        boolean trackRecordConsensus
        string category
        boolean fetchSuccess
        string fetchedAt
        string searchQuery
    }

    SEARCH_QUERY {
        string query
        int iteration
        string focus
        int resultsCount
        string searchProvider
        string timestamp
        string error
    }

{{/mermaid}}

//Stage 2 output: EVIDENCE_ITEMs with EVIDENCE_SCOPEs from FETCHED_SOURCEs. CB pipeline additions: relevantClaimIds (which claims evidence relates to), claimBoundaryId (assigned in Stage 3), isDerivative/derivedFromSourceUrl (derivative tracking), scopeQuality assessment.//

=== Stage 3: Cluster Boundaries ===

{{mermaid}}

erDiagram
    CLAIM_BOUNDARY ||--o{ EVIDENCE_SCOPE : "composed of"
    EVIDENCE_ITEM }o--|| CLAIM_BOUNDARY : "assigned to"

    CLAIM_BOUNDARY {
        string id_PK "CB_01 CB_02"
        string name "Human-readable label"
        string shortName "Short label for UI tabs"
        string description
        string methodology "Dominant methodology (optional)"
        string boundaries "Scope boundaries (optional)"
        string geographic "Geographic scope (optional)"
        string temporal "Temporal scope (optional)"
        json constituentScopes "EvidenceScope[] composing this boundary"
        float internalCoherence "0-1"
        int evidenceCount
    }

    EVIDENCE_SCOPE {
        string name
        string methodology "Optional"
        string temporal "Optional"
    }

    EVIDENCE_ITEM {
        string claimBoundaryId_FK
    }

{{/mermaid}}

//Stage 3 output: CLAIM_BOUNDARYs emerge from clustering compatible EVIDENCE_SCOPEs. Each boundary has internal coherence and count. Evidence items are assigned to their boundary.//

=== Stage 4: Verdict (LLM Debate) ===

{{mermaid}}

erDiagram
    CB_CLAIM_VERDICT ||--o{ BOUNDARY_FINDING : contains
    CB_CLAIM_VERDICT ||--|| CONSISTENCY_RESULT : has
    CB_CLAIM_VERDICT ||--o{ CHALLENGE_RESPONSE : has
    CB_CLAIM_VERDICT }o--o{ EVIDENCE_ITEM : "cites supporting"
    CB_CLAIM_VERDICT }o--o{ EVIDENCE_ITEM : "cites contradicting"
    CB_CLAIM_VERDICT ||--|| TRIANGULATION_SCORE : has

    CB_CLAIM_VERDICT {
        string id_PK
        string claimId_FK
        float truthPercentage "0-100"
        string verdict "7-point label"
        float confidence "0-100"
        string reasoning "Includes challenge responses"
        string harmPotential "critical high medium low"
        boolean isContested
        string_array supportingEvidenceIds
        string_array contradictingEvidenceIds
        json boundaryFindings "BoundaryFinding[]"
        json consistencyResult "ConsistencyResult"
        json challengeResponses "ChallengeResponse[]"
        json triangulationScore "TriangulationScore"
    }

    BOUNDARY_FINDING {
        string boundaryId_FK
        string boundaryName
        float truthPercentage "Per-boundary 0-100"
        float confidence "Per-boundary 0-100"
        string evidenceDirection "supports contradicts mixed neutral"
        int evidenceCount
    }

    CONSISTENCY_RESULT {
        string claimId_FK
        float_array percentages
        float average
        float spread
        boolean stable
        boolean assessed "false if disabled"
    }

    CHALLENGE_RESPONSE {
        string challengeType "assumption missing_evidence methodology_weakness independence_concern"
        string response
        boolean verdictAdjusted
    }

    TRIANGULATION_SCORE {
        int boundaryCount
        int supporting
        int contradicting
        string level "strong moderate weak conflicted"
        float factor "Weight adjustment"
    }

{{/mermaid}}

//Stage 4 output: CB_CLAIM_VERDICTs via 5-step LLM debate (Advocate → Self-Consistency → Adversarial Challenge → Reconciliation → Validation). Each verdict includes per-boundary BOUNDARY_FINDINGs, CONSISTENCY_RESULT (self-consistency spread), CHALLENGE_RESPONSEs (addressed challenges), and TRIANGULATION_SCORE (cross-boundary agreement).//

=== Stage 5: Aggregate + Quality ===

{{mermaid}}

erDiagram
    OVERALL_ASSESSMENT ||--o{ CB_CLAIM_VERDICT : aggregates
    OVERALL_ASSESSMENT ||--o{ CLAIM_BOUNDARY : presents
    OVERALL_ASSESSMENT ||--|| VERDICT_NARRATIVE : has
    OVERALL_ASSESSMENT ||--|| COVERAGE_MATRIX : has
    OVERALL_ASSESSMENT ||--|| QUALITY_GATES : has

    QUALITY_GATES ||--|| GATE1_STATS : claim_validation
    QUALITY_GATES ||--|| GATE4_STATS : verdict_confidence

    OVERALL_ASSESSMENT {
        float truthPercentage "0-100 weighted"
        string verdict "7-point label"
        float confidence "0-100 weighted"
        boolean hasMultipleBoundaries
        json verdictNarrative "VerdictNarrative"
        json claimBoundaries "ClaimAssessmentBoundary[]"
        json claimVerdicts "CBClaimVerdict[]"
        json coverageMatrix "CoverageMatrix"
        json qualityGates "QualityGates"
    }

    VERDICT_NARRATIVE {
        string headline
        string evidenceBaseSummary
        string keyFinding
        string_array boundaryDisagreements
        string limitations
    }

    COVERAGE_MATRIX {
        string_array claims "Rows"
        string_array boundaries "Columns"
        int_array_array counts "Evidence per cell"
    }

    QUALITY_GATES {
        boolean passed
    }

    GATE1_STATS {
        int totalClaims
        int passedClaims
        int filteredClaims
        int passedFidelity
    }

    GATE4_STATS {
        int totalVerdicts
        int highConfidence
        int mediumConfidence
        int lowConfidence
        int insufficient
    }

    ANALYSIS_WARNING {
        string type
        string severity "error warning info"
        string message
        json details
    }

    TWO_PANEL_SUMMARY {
        json articleSummary
        json factharborAnalysis
    }

    PSEUDOSCIENCE_ANALYSIS {
        boolean isPseudoscience
        int confidence
        json categories
        json matchedPatterns
    }

{{/mermaid}}

//Stage 5 output: OVERALL_ASSESSMENT aggregates CB_CLAIM_VERDICTs with weighted averaging (centrality, harm, confidence, triangulation, derivative). VERDICT_NARRATIVE provides structured summary. COVERAGE_MATRIX maps claims to boundaries. QUALITY_GATES summarize Gate 1 (claim validation) and Gate 4 (verdict confidence). TWO_PANEL_SUMMARY and PSEUDOSCIENCE_ANALYSIS complete the result.//

----

== Target Database Entities ==

Entities that should become PostgreSQL tables in the target architecture. Color indicates implementation status: green = exists as table, blue = target (currently in JSON blob), red = planned but not implemented.

{{mermaid}}

erDiagram
    JOBS ||--o{ JOB_EVENTS : logs
    JOBS ||--o| ANALYSIS_METRICS : tracked_by
    JOBS ||--o{ CONFIG_USAGE : snapshot
    CONFIG_USAGE }o--|| CONFIG_BLOBS : references
    CONFIG_ACTIVE }o--|| CONFIG_BLOBS : points_to

    JOBS ||--o{ ATOMIC_CLAIMS : produces
    JOBS ||--o{ CB_CLAIM_VERDICTS : produces
    JOBS ||--o{ EVIDENCE_ITEMS : produces
    JOBS ||--o{ FETCHED_SOURCES : produces
    JOBS ||--o{ CLAIM_BOUNDARIES : produces

    CB_CLAIM_VERDICTS }o--o{ EVIDENCE_ITEMS : supported_by
    CB_CLAIM_VERDICTS }o--|| ATOMIC_CLAIMS : for_claim
    EVIDENCE_ITEMS }o--|| FETCHED_SOURCES : from
    EVIDENCE_ITEMS }o--o| CLAIM_BOUNDARIES : assigned_to
    FETCHED_SOURCES }o--o| SOURCE_RELIABILITY : cached_score

    USERS ||--o{ FLAGS : reports
    FLAGS }o--|| JOBS : targets

    JOBS {
        string JobId_PK
        string Status
        int Progress
        string InputType
        string InputValue
        string PipelineVariant
        datetime CreatedUtc
        datetime UpdatedUtc
        json ResultJson
        text ReportMarkdown
    }

    JOB_EVENTS {
        long Id_PK
        string JobId_FK
        datetime TsUtc
        string Level
        string Message
    }

    ANALYSIS_METRICS {
        guid Id_PK
        string JobId_FK
        json MetricsJson
        datetime CreatedUtc
    }

    CONFIG_BLOBS {
        text hash_PK
        text config_type
        json content
        text changed_by
        text change_reason
        datetime created_at
    }

    CONFIG_ACTIVE {
        text config_type_PK
        text blob_hash_FK
        datetime activated_at
    }

    CONFIG_USAGE {
        string job_id_FK
        text config_type
        text blob_hash_FK
        datetime snapshot_at
    }

    SOURCE_RELIABILITY {
        text domain_PK
        float score
        float confidence
        boolean consensus
        datetime evaluated_at
        int ttl_days
    }

    ATOMIC_CLAIMS {
        string id_PK "AC_01"
        string jobId_FK
        string statement
        string category
        string centrality
        string harmPotential "critical high medium low"
        float specificityScore
        string groundingQuality
    }

    CB_CLAIM_VERDICTS {
        string id_PK
        string jobId_FK
        string claimId_FK
        int truthPercentage
        int confidence
        string verdict
        string reasoning
        json supportingEvidenceIds
        json contradictingEvidenceIds
        json boundaryFindings
        json consistencyResult
        json challengeResponses
        json triangulationScore
    }

    EVIDENCE_ITEMS {
        string id_PK
        string jobId_FK
        string statement
        string category
        string sourceId_FK
        string probativeValue
        string claimDirection
        string claimBoundaryId_FK
        json relevantClaimIds
        boolean isDerivative
        string scopeQuality
    }

    FETCHED_SOURCES {
        string id_PK
        string jobId_FK
        string url
        string domain
        string title
        float trackRecordScore
        boolean fetchSuccess
        datetime fetchedAt
    }

    CLAIM_BOUNDARIES {
        string id_PK "CB_01"
        string jobId_FK
        string name
        string shortName
        string description
        string methodology
        float internalCoherence
        int evidenceCount
    }

    USERS {
        uuid id_PK
        string username
        string email
        string role
        datetime created_at
    }

    FLAGS {
        uuid id_PK
        string entity_type
        string entity_id_FK
        uuid reported_by_FK
        string issue_type
        string status
    }

    QUALITY_METRICS {
        uuid id_PK
        string metric_type
        string category
        float value
        float target
        datetime timestamp
    }

{{/mermaid}}

=== Implementation Status ===

|= Table |= Status |= Technology |= Notes
| ##jobs## | Exists | .NET EF Core (SQLite) | Analysis results stored as JSON blob in ##ResultJson##
| ##job_events## | Exists | .NET EF Core (SQLite) | Event log with SSE streaming
| ##analysis_metrics## | Exists | .NET EF Core (SQLite) | Metrics as JSON blob
| ##config_blobs## | Exists | Next.js better-sqlite3 | Immutable, content-addressed
| ##config_active## | Exists | Next.js better-sqlite3 | Activation pointers
| ##config_usage## | Exists | Next.js better-sqlite3 | Per-job config snapshots
| ##source_reliability## | Exists | Next.js better-sqlite3 | LLM-evaluated cache (90-day TTL)
| ##atomic_claims## | **Target** | PostgreSQL | Normalised from JSON blob (replaces Orchestrated ##claim_verdicts## scope)
| ##cb_claim_verdicts## | **Target** | PostgreSQL | Normalised from JSON blob (includes boundary findings, consistency, challenges)
| ##evidence_items## | **Target** | PostgreSQL | Normalised from JSON blob (includes claimBoundaryId, derivative flags)
| ##fetched_sources## | **Target** | PostgreSQL | Normalised from JSON blob
| ##claim_boundaries## | **Target** | PostgreSQL | Normalised from JSON blob (replaces Orchestrated ##analysis_contexts##)
| ##users## | **Planned** | PostgreSQL | Not yet implemented (Alpha phase)
| ##flags## | **Planned** | PostgreSQL | Not yet implemented (Alpha phase)
| ##quality_metrics## | **Planned** | PostgreSQL | Not yet implemented (time-series)

For detailed field descriptions, denormalisation strategy, and cost projections, see [[Target Data Model>>FactHarbor.Product Development.Specification.Data Model.WebHome]].

----

== Runtime Process Entities ==

Entities that exist only during pipeline execution. These are transient — they facilitate processing but are not directly stored in the result JSON. Some contribute data that flows into stored entities.

{{mermaid}}

flowchart TD
    subgraph Extract["EXTRACT CLAIMS (Stage 1)"]
        ICR["InputClassificationResult\nisComparative, isCompound\nclaimType, complexity"]
        G1M["Gate 1 Validation\nclaims filtered, fidelity check"]
    end

    subgraph Research["RESEARCH (Stage 2)"]
        RS["CBResearchState\n(main mutable container)\nunderstanding, evidenceItems\nsources, searchQueries, llmCalls\nmainIterationsUsed, contradictionIterations"]
        RD["ResearchDecision\ncomplete, focus, queries"]
        EQR["EvidenceQualityResult\nqualityAssessment, issues\nreasoning (per evidence)"]
        PV["ProvenanceValidation\nURL validation, excerpt check"]
        BT["BudgetTracker\ntokens, iterations\nllmCalls, budgetExceeded"]
    end

    subgraph Cluster["CLUSTER BOUNDARIES (Stage 3)"]
        SCOPE_CLUSTER["Scope Clustering\nEvidenceScope compatibility\nmerge vs separate decision"]
    end

    subgraph Verdict["VERDICT (Stage 4)"]
        ADV["Advocate Verdict\ninitial per-claim verdicts"]
        SC["Self-Consistency Check\ntemp=0.3, spread measurement"]
        CHAL["Adversarial Challenge\nchallenge points per claim"]
        REC["Reconciliation\nfinal verdicts"]
        VV["Verdict Validation\ngrounding + direction checks"]
        G4M["Gate 4 Assessment\nconfidence distribution"]
    end

    subgraph Metrics["METRICS (Full Pipeline)"]
        MC["MetricsCollector\naccumulates all telemetry"]
        LCM["LLMCallMetric\ntokens, duration, success"]
        SQM["SearchQueryMetric\nquery, provider, duration"]
    end

    ICR -->|"data flows into"| CU["CBClaimUnderstanding\n(STORED in result)"]
    G1M -->|"summary"| QG["gate1Stats\n(STORED in result)"]
    EQR -->|"filters"| EI["EvidenceItems\n(STORED in result)"]
    PV -->|"filters"| EI
    SCOPE_CLUSTER -->|"creates"| CB["ClaimBoundaries\n(STORED in result)"]
    ADV -->|"initial"| VERD["CBClaimVerdicts\n(STORED in result)"]
    SC -->|"consistency"| VERD
    CHAL -->|"challenges"| VERD
    REC -->|"final"| VERD
    VV -->|"validates"| VERD
    G4M -->|"summary"| QG4["gate4Stats\n(STORED in result)"]
    BT -->|"summary"| BS["meta.budgetStats\n(STORED in result)"]
    RD -->|"discarded"| DISC["Discarded"]
    MC -->|"sent to API"| AM["AnalysisMetrics\n(STORED in separate DB)"]
    LCM --> MC
    SQM --> MC
    RS -->|"fields flow into"| RES["resultJson fields\n(STORED in result)"]

    style CU fill:#c8e6c9,stroke:#2e7d32,color:#000
    style QG fill:#fff9c4,stroke:#f9a825,color:#000
    style EI fill:#fff3e0,stroke:#e65100,color:#000
    style CB fill:#e1bee7,stroke:#7b1fa2,color:#000
    style VERD fill:#c8e6c9,stroke:#2e7d32,color:#000
    style QG4 fill:#fff9c4,stroke:#f9a825,color:#000
    style BS fill:#e3f2fd,stroke:#1565c0,color:#000
    style AM fill:#e3f2fd,stroke:#1565c0,color:#000
    style RES fill:#c8e6c9,stroke:#2e7d32,color:#000
    style DISC fill:#f5f5f5,stroke:#9e9e9e,color:#666

    style ICR fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style G1M fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style RS fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style RD fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style EQR fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style PV fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style BT fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style SCOPE_CLUSTER fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style ADV fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style SC fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style CHAL fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style REC fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style VV fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style G4M fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style MC fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style LCM fill:#f5f5f5,stroke:#9e9e9e,color:#000
    style SQM fill:#f5f5f5,stroke:#9e9e9e,color:#000

{{/mermaid}}

//Grey boxes = transient runtime entities. Colored boxes = stored destinations. Arrows show how runtime data flows into (or is discarded from) the final result. Source files: ##types.ts##, ##metrics.ts##, ##budgets.ts##, ##claimboundary-pipeline.ts##, ##verdict-stage.ts##.//

=== Runtime Entity Reference ===

|= Entity |= Source File |= Lifecycle |= Destination
| ##CBResearchState## | ##types.ts:922## | Full pipeline | Container — fields distributed into resultJson
| ##BudgetTracker## | ##budgets.ts## | Full pipeline | ##meta.budgetStats##
| ##ResearchDecision## | ##types.ts:599## | Per iteration | Discarded after use
| ##InputClassificationResult## | ##text-analysis-types.ts## | Extract phase | Data flows into ##CBClaimUnderstanding##
| ##EvidenceQualityResult## | ##text-analysis-types.ts## | Research phase | Filters ##EvidenceItems## (pass/fail)
| ##VerdictValidationResult## | ##types.ts:121## | Verdict phase | Advisory checks on ##CBClaimVerdicts##
| ##MetricsCollector## | ##metrics.ts## | Full pipeline | ##AnalysisMetrics## (separate DB)
| ##LLMCallMetric## | ##metrics.ts## | Per LLM call | Aggregated in ##MetricsCollector##
| ##SearchQueryMetric## | ##metrics.ts## | Per search call | Aggregated in ##MetricsCollector##
| ##ProvenanceValidation## | ##evidence-filter.ts## | Research phase | Filters evidence (pass/fail)
| ##ChallengeDocument## | ##types.ts:814## | Verdict Step 3 | Challenge points consumed by Reconciliation (Step 4)
| ##ConsistencyResult## | ##types.ts:800## | Verdict Step 2 | Stored in ##CBClaimVerdict.consistencyResult##

----

== UI-Visible Entities ==

Entities and fields that surface to users in the browser. Grouped by UI page.

{{mermaid}}

flowchart TD
    subgraph JobsList["/jobs - Jobs List Page"]
        JL_JOB["JOB\nstatus, progress\ninputPreview\npipelineVariant\ncreatedUtc"]
    end

    subgraph JobDetail["/jobs/id - Job Detail Page"]

        subgraph VerdictBanner["Verdict Banner"]
            JD_OA["OVERALL_ASSESSMENT\ntruthPercentage, verdict\nconfidence"]
            JD_VN["VERDICT_NARRATIVE\nheadline, keyFinding\nlimitations"]
            JD_TPS["TWO_PANEL_SUMMARY\narticleSummary\nfactharborAnalysis"]
        end

        subgraph BoundarySection["ClaimAssessmentBoundary Tabs"]
            JD_CB["CLAIM_BOUNDARY\nname, shortName\nmethodology, temporal"]
            JD_BF["BOUNDARY_FINDING\ntruthPercentage, confidence\nevidenceDirection"]
        end

        subgraph ClaimsSection["Claims Analyzed"]
            JD_CV["CB_CLAIM_VERDICT\nstatement, verdict\nconfidence, reasoning\nharmPotential, isContested"]
        end

        subgraph EvidenceSection["Evidence Panel"]
            JD_EI["EVIDENCE_ITEM\nstatement, category\nsourceTitle, claimDirection\nprobativeValue"]
            JD_ES["EVIDENCE_SCOPE\n(tooltip: methodology\nboundaries, geographic)"]
        end

        subgraph SourcesSection["Sources Tab"]
            JD_FS["FETCHED_SOURCE\nurl, title\ntrackRecordScore\nfetchSuccess"]
        end

        subgraph QualitySection["Quality Panel"]
            JD_QG["QUALITY_GATES\npassed, gate1Stats\ngate4Stats"]
            JD_AW["ANALYSIS_WARNING\ntype, severity\nmessage"]
        end

        subgraph SearchSection["Search Queries"]
            JD_SQ["SEARCH_QUERY\nquery, resultsCount\nsearchProvider"]
        end
    end

    subgraph Admin["/admin - Admin Pages"]
        AD_HEALTH["Provider Health\nstate, consecutiveFailures"]
        AD_METRICS["ANALYSIS_METRICS\navgDuration, avgCost\ngate1PassRate\ngate4HighConfidenceRate"]
        AD_CONFIG["CONFIG_SNAPSHOT\npipelineConfig\nsearchConfig"]
    end

    JL_JOB -->|"click job"| JobDetail
    JD_CV -->|"references"| JD_EI
    JD_EI -->|"from"| JD_FS
    JD_CB -->|"findings"| JD_BF

    style JL_JOB fill:#e3f2fd,stroke:#1565c0,color:#000
    style JD_OA fill:#c8e6c9,stroke:#2e7d32,color:#000
    style JD_VN fill:#c8e6c9,stroke:#2e7d32,color:#000
    style JD_TPS fill:#c8e6c9,stroke:#2e7d32,color:#000
    style JD_CB fill:#e1bee7,stroke:#7b1fa2,color:#000
    style JD_BF fill:#e1bee7,stroke:#7b1fa2,color:#000
    style JD_CV fill:#c8e6c9,stroke:#2e7d32,color:#000
    style JD_EI fill:#fff3e0,stroke:#e65100,color:#000
    style JD_ES fill:#fff3e0,stroke:#e65100,color:#000
    style JD_FS fill:#fff3e0,stroke:#e65100,color:#000
    style JD_QG fill:#fff9c4,stroke:#f9a825,color:#000
    style JD_AW fill:#fff9c4,stroke:#f9a825,color:#000
    style JD_SQ fill:#fff3e0,stroke:#e65100,color:#000
    style AD_HEALTH fill:#e3f2fd,stroke:#1565c0,color:#000
    style AD_METRICS fill:#e3f2fd,stroke:#1565c0,color:#000
    style AD_CONFIG fill:#e3f2fd,stroke:#1565c0,color:#000

{{/mermaid}}

//UI visibility: The Jobs list shows minimal JOB metadata. The Job detail page renders the full analysis result across multiple sections: verdict banner (OVERALL_ASSESSMENT + VERDICT_NARRATIVE), ClaimAssessmentBoundary tabs with BOUNDARY_FINDINGs, claims with CB_CLAIM_VERDICTs, evidence panel, sources, quality gates, and search queries. Admin pages show operational data (provider health, aggregated metrics, config snapshots).//

=== What Users See vs. What's Internal ===

|= Entity |= User-Visible Fields |= Internal-Only Fields
| **CBClaimVerdict** | statement, verdict, confidence, reasoning, isContested, harmPotential | triangulationScore, consistencyResult details, challengeResponses
| **EvidenceItem** | statement, category, sourceTitle, claimDirection, probativeValue | sourceId, extractionConfidence, scopeQuality, sourceAuthority, evidenceBasis, isDerivative, derivedFromSourceUrl
| **FetchedSource** | url, title, trackRecordScore | fullText, fetchedAt, searchQuery
| **ClaimBoundary** | name, shortName, description, methodology | internalCoherence, constituentScopes
| **BoundaryFinding** | truthPercentage, confidence, evidenceDirection | boundaryId (used for cross-referencing)
| **QualityGates** | passed, gate1Stats (counts), gate4Stats (counts) | Individual ClaimValidationResult, VerdictValidationResult per claim

----

**Navigation:** [[Diagrams Index>>FactHarbor.Product Development.Diagrams.WebHome]] | [[Architecture Data Model>>FactHarbor.Product Development.Specification.Architecture.Data Model.WebHome]] | [[Target Data Model>>FactHarbor.Product Development.Specification.Data Model.WebHome]]
