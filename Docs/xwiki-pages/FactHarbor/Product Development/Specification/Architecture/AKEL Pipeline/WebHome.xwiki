= AKEL Pipeline =

The **AI Knowledge Extraction Layer (AKEL)** is FactHarbor's core analysis engine. It takes an article or claim as input and produces a structured verdict report through a 5-step process: Understand, Research, Verdict, Summary, and Report.

== Pipeline Overview ==

{{include reference="FactHarbor.Product Development.Diagrams.AKEL Pipeline Detail.WebHome"/}}

=== Step-by-Step ===

**Step 1: Understand** — Analyses the input to determine what needs checking.
* Detects input type: question, statement, or article
* Extracts individual claims with dependency chains
* Identifies analysis contexts (bounded analytical frames for multi-perspective topics)
* Assigns risk tiers (A=high, B=medium, C=low) to guide research depth
* Applies **Gate 1** (Claim Validation): filters opinions, predictions, and non-factual statements

**Step 2: Research** — Iteratively searches the web for evidence.
* Generates targeted search queries based on claims and gaps
* Fetches and parses source content (HTML via cheerio, PDF via pdf2json)
* Extracts evidence items from each source (statements, statistics, expert quotes)
* Applies evidence quality filtering (probative value, deduplication, provenance)
* Repeats until research is complete or iteration/token budget is exhausted (default: 5 iterations, 750K tokens)

**Step 3: Verdict** — Evaluates each claim against the evidence.
* Generates per-claim verdicts on the 7-point scale (TRUE → FALSE)
* Propagates dependency failures (if prerequisite claim fails, dependent claims inherit)
* Aggregates claim verdicts into an overall article verdict using weighted averages (centrality, harm potential, evidence quality, source reliability)
* Applies **Gate 4** (Confidence Assessment): flags low-confidence verdicts

**Step 4: Summary** — Structures results for presentation.
* Builds a two-panel summary (Overview + Key Findings)

**Step 5: Report** — Generates the final output.
* Produces a markdown report with all sections: Summary, Claims, Sources, Verdict

== Pipeline Variants ==

FactHarbor supports two pipeline variants. The **orchestrated** pipeline is the comprehensive default; the **monolithic dynamic** variant is a fast, lower-cost alternative.

{{mermaid}}
flowchart LR
    INPUT["User Input"] --> DISPATCH{{"Pipeline\nDispatch"}}

    DISPATCH -->|"orchestrated\n(default)"| ORCH["Orchestrated\nMulti-step workflow\nFull quality gates"]
    DISPATCH -->|"monolithic_dynamic"| DYN["Monolithic Dynamic\nSingle LLM call\nFlexible output"]

    ORCH --> RESULT["AnalysisResult\nJSON"]
    DYN --> RESULT

    style ORCH fill:#c8e6c9,stroke:#2e7d32,color:#000
    style DYN fill:#f3e5f5,stroke:#6a1b9a,color:#000
{{/mermaid}}

//Both variants produce an AnalysisResult JSON output. The orchestrated pipeline is the default and most capable; the monolithic dynamic variant trades depth for speed and flexibility.//

|= Variant |= Approach |= Quality |= Speed |= Use Case
| **Orchestrated** | Multi-step workflow with iterative research, quality gates, evidence filtering | Highest | Slower (multiple LLM calls) | Production analysis
| **Monolithic Dynamic** | Single LLM tool-loop call, flexible output | Streamlined | Fastest | Fast analysis, second opinion

== Shared Analysis Modules ==

All pipeline variants share a common set of analysis modules. This ensures consistency in verdict calculations, evidence quality, and source reliability across pipelines.

{{include reference="FactHarbor.Product Development.Diagrams.AKEL Shared Modules.WebHome"/}}

|= Module |= Used By |= Purpose
| ##aggregation.ts## | Orch | Verdict weighting by centrality/harm/evidence quality, contestation validation
| ##claim-decomposition.ts## | Orch | Claim text parsing and normalisation
| ##analysis-contexts.ts## | Orch | Heuristic context pre-detection before LLM
| ##evidence-filter.ts## | Orch | Probative value filtering, false positive rate calculation
| ##quality-gates.ts## | Orch | Gate 1 (claim validation) and Gate 4 (verdict confidence)
| ##verdict-corrections.ts## | Orch | Post-hoc verdict direction mismatch corrections
| ##source-reliability.ts## | Orch, Dyn | LLM-based source credibility evaluation with SQLite cache
| ##truth-scale.ts## | Dyn | Percentage-to-verdict label mapping (7-point scale)
| ##budgets.ts## | Orch, Dyn | Token and cost budget tracking and enforcement

== Budget Controls ==

The orchestrated pipeline enforces budgets to prevent runaway LLM costs:

|= Budget |= Default |= Purpose
| Max iterations per context | 5 | Limits research rounds per analysis context
| Max total tokens | 750,000 | Caps total LLM token consumption across all steps
| Max total iterations | 20 | Hard limit on total research iterations across all contexts

== Deep Dives ==

For detailed implementation references:
* [[Orchestrated Pipeline>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Orchestrated Pipeline.WebHome]] — Step-by-step with function names, LLM call points, and budget controls
* [[Pipeline Variants>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Pipeline Variants.WebHome]] — Invariants, shared primitives, result model, configuration
* [[Quality Gates>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]] — Gate 1 and Gate 4 criteria, confidence penalties

----

**Navigation:** [[Architecture>>FactHarbor.Product Development.Specification.Architecture.WebHome]] | Prev: [[System Design>>FactHarbor.Product Development.Specification.Architecture.System Design.WebHome]] | Next: [[Data Model>>FactHarbor.Product Development.Specification.Architecture.Data Model.WebHome]]
