= Data Model =

FactHarbor's data model centres on the **analysis result** — a structured representation of how claims are decomposed, researched, and evaluated. This page defines the complete entity landscape derived from the source code, the 7-point verdict scale, and the job lifecycle.

== Entity Overview ==

The following diagram shows all major entity groups and their primary relationships at a glance. For detailed views (result fields, target database, runtime entities, UI visibility), see [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]].

{{include reference="FactHarbor.Product Development.Diagrams.Entity Views.WebHome" section="HOverviewERD"/}}

== Analysis Entity Model ==

The ClaimAssessmentBoundary pipeline produces a hierarchy of entities: the input is decomposed into AtomicClaims (Stage 1), evidence is gathered from web sources (Stage 2), evidence is clustered into ClaimAssessmentBoundaries (Stage 3), verdicts are generated per-claim via LLM debate (Stage 4), and aggregated into an OverallAssessment (Stage 5).

{{include reference="FactHarbor.Product Development.Diagrams.Analysis Entity Model ERD.WebHome"/}}

//For complete field-level detail per entity and per pipeline phase, see [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]].//

== Entity Descriptions ==

|= Entity |= Purpose |= Source Interface |= Key Relationships
| **CBClaimUnderstanding** | Stage 1 output: decomposition of input into AtomicClaims with Gate 1 stats | ##types.ts:893## | Parent of AtomicClaim[]
| **AtomicClaim** | Single verifiable assertion extracted from user input; the analytical unit | ##types.ts:704## | Receives CBClaimVerdict[]; has centrality, harmPotential, groundingQuality
| **ClaimAssessmentBoundary** | Evidence-emergent grouping of compatible EvidenceScopes; the top-level analytical frame | ##types.ts:733## | Contains EvidenceItem[] and EvidenceScope[]; referenced by BoundaryFinding[]
| **CBClaimVerdict** | Per-claim verdict with truth percentage, confidence, reasoning, boundary findings, and challenge responses | ##types.ts:777## | References EvidenceItem[] (supporting + contradicting); contains BoundaryFinding[], ConsistencyResult, ChallengeResponse[]
| **EvidenceItem** | Extracted statement from a web source with quality metadata (probative value, scope quality, derivative tracking) | ##types.ts:385## | References FetchedSource; assigned to ClaimAssessmentBoundary; has mandatory EvidenceScope
| **FetchedSource** | Web source with URL, content, and source reliability score (0.0-1.0 from LLM evaluation) | ##types.ts:447## | Referenced by EvidenceItem[]
| **OverallAssessment** | Final aggregated result: weighted truth percentage, verdict, confidence, narrative, coverage matrix | ##types.ts:949## | Aggregates CBClaimVerdict[], ClaimAssessmentBoundary[]; has VerdictNarrative, CoverageMatrix, QualityGates
| **VerdictNarrative** | Structured narrative: headline, evidence base summary, key finding, boundary disagreements, limitations | ##types.ts:878## | Contained by OverallAssessment

=== Additional Entities ===

* **EvidenceScope** (##types.ts:226##) — Per-evidence methodology metadata (methodology [REQUIRED], temporal [REQUIRED], boundaries, geographic, sourceType, additionalDimensions). Embedded in EvidenceItem.
* **BoundaryFinding** (##types.ts:759##) — Per-boundary quantitative signals within a CBClaimVerdict: truthPercentage, confidence, evidenceDirection, evidenceCount.
* **ConsistencyResult** (##types.ts:800##) — Self-consistency check output: verdict stability across multiple LLM runs (percentages, spread, stable flag).
* **ChallengeResponse** (##types.ts:838##) — How adversarial challenges were addressed in reconciliation: challengeType, response, verdictAdjusted.
* **TriangulationScore** (##types.ts:849##) — Cross-boundary agreement assessment: supporting/contradicting boundary counts, level (strong/moderate/weak/conflicted), factor.
* **CoverageMatrix** (##types.ts:863##) — Claims x boundaries evidence distribution: counts per cell.
* **CBResearchState** (##types.ts:922##) — Top-level research container holding CBClaimUnderstanding, EvidenceItem[], FetchedSource[], SearchQuery[], iteration tracking, ClaimAssessmentBoundary[].

== Quality Gate Entities ==

Two quality gates produce validation entities that attach to the analysis result.

|= Entity |= Gate |= Purpose |= Key Fields |= Source
| **ClaimValidationResult** | Gate 1 | Per-claim factuality + fidelity check | ##isFactual##, ##opinionScore##, ##specificityScore##, ##passedFidelity##, ##claimType## | ##types.ts:105##
| **VerdictValidationResult** | Gate 4 | Per-verdict confidence assessment | ##evidenceCount##, ##averageSourceQuality##, ##evidenceAgreement##, ##confidenceTier## | ##types.ts:121##
| **QualityGatesSummary** | Both | Aggregate pass/fail with Gate1Stats and Gate4Stats | ##passed##, ##gate1Stats##, ##gate4Stats## | ##types.ts:161##

For detailed quality gate criteria and examples, see [[Quality Gates Deep Dive>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]].

== Configuration Entities ==

Four configuration profiles are stored as immutable JSON blobs in the UCM (Unified Config Management) system. Each analysis job records the exact config snapshot used for reproducibility.

|= Config |= Purpose |= Key Settings |= Source
| **PipelineConfig** | Pipeline operational settings | LLM provider selection, model tiering, budget controls, context detection, confidence calibration | ##config-schemas.ts:86##
| **CalcConfig** | Calculation and aggregation | Verdict bands, centrality weights, contestation penalties, quality gate thresholds, deduplication | ##config-schemas.ts:751##
| **SearchConfig** | Search provider settings | Provider selection, max results, timeout, domain whitelist/blacklist | ##config-schemas.ts:52##
| **SourceReliabilityConfig** | Source reliability service | Multi-model consensus, confidence/consensus thresholds, cache TTL, platform skip lists | ##config-schemas.ts:598##

For configuration storage and versioning, see [[Storage and Configuration>>FactHarbor.Product Development.Specification.Architecture.Storage and Configuration.WebHome]].

== 7-Point Verdict Scale ==

{{include reference="FactHarbor.Product Development.Diagrams.Verdict Scale.WebHome"/}}

//The 7-point verdict scale maps truth percentages to verdict labels. MIXED (evidence on both sides, confidence >= 40%) and UNVERIFIED (insufficient evidence, confidence < 40%) share the same percentage range but differ in their confidence interpretation.//

|= Verdict |= Truth % Range |= Meaning
| **TRUE** | 86-100% | Claim is well-supported by strong evidence
| **MOSTLY TRUE** | 72-85% | Claim is largely supported with minor caveats
| **LEANING TRUE** | 58-71% | More evidence supports than contradicts, but not conclusive
| **MIXED** | 43-57% (confidence >= 40%) | Significant evidence on both sides
| **UNVERIFIED** | 43-57% (confidence < 40%) | Insufficient evidence to determine truth
| **LEANING FALSE** | 29-42% | More evidence contradicts than supports
| **MOSTLY FALSE** | 15-28% | Claim is largely contradicted by evidence
| **FALSE** | 0-14% | Claim is strongly contradicted by evidence

=== MIXED vs. UNVERIFIED ===

Both occupy the 43-57% truth range. The distinction is **confidence-based**:
* **MIXED**: The system found substantial evidence but it points in opposing directions (high confidence in the conflict)
* **UNVERIFIED**: The system could not find enough evidence to make a determination (low confidence due to insufficient data)

== Job Lifecycle ==

{{include reference="FactHarbor.Product Development.Diagrams.Job Lifecycle ERD.WebHome"/}}

=== Job Status Transitions ===

|= Status |= Meaning
| **QUEUED** | Job submitted, waiting for runner capacity
| **RUNNING** | AKEL pipeline is executing
| **SUCCEEDED** | Analysis complete, results available
| **FAILED** | Analysis failed (provider error, timeout, or input issue)
| **PAUSED** | System auto-paused due to provider outage (jobs resume when system recovers)

== Audit Trail ==

{{include reference="FactHarbor.Product Development.Diagrams.Audit Trail ERD.WebHome"/}}

== Storage ==

Analysis results are currently stored as **JSON blobs** in SQLite (via the .NET Entity Framework ##ResultJson## field). The full entity model above lives within this JSON blob — it is not normalised into separate database tables.

|= Database |= Technology |= Contents
| ##factharbor.db## | .NET Entity Framework Core | Jobs, events, analysis results (JSON), metrics
| ##config.db## | Next.js better-sqlite3 | UCM configuration blobs, activation pointers, usage tracking
| ##source-reliability.db## | Next.js better-sqlite3 | Source credibility evaluation cache

**Target Evolution:** PostgreSQL for primary storage (enabling full-text search, user accounts), with the JSON blob approach preserved for backwards compatibility during migration. See [[Storage and Configuration>>FactHarbor.Product Development.Specification.Architecture.Storage and Configuration.WebHome]] for details, and [[Target Data Model>>FactHarbor.Product Development.Specification.Data Model.WebHome]] for the normalised design specification.

== Deep Dives ==

* [[Calculations and Verdicts>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Calculations and Verdicts.WebHome]] — Verdict calculation formulas, aggregation hierarchy, weighting factors
* [[Confidence Calibration>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Confidence Calibration.WebHome]] — 4-layer confidence system, penalty calculations
* [[KeyFactors Design>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.KeyFactors Design.WebHome]] — KeyFactor design decisions, contestation structure, conceptual target ERD

----

**Navigation:** [[Architecture>>FactHarbor.Product Development.Specification.Architecture.WebHome]] | Prev: [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]] | Next: [[External Dependencies>>FactHarbor.Product Development.Specification.Architecture.External Dependencies.WebHome]]
