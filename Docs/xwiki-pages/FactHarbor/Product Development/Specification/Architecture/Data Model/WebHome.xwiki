= Data Model =

FactHarbor's data model centres on the **analysis result** — a structured representation of how claims are decomposed, researched, and evaluated. This page defines the complete entity landscape derived from the source code, the 7-point verdict scale, and the job lifecycle.

== Entity Overview ==

The following diagram shows all major entity groups and their primary relationships at a glance. For detailed views (result fields, target database, runtime entities, UI visibility), see [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]].

{{include reference="FactHarbor.Product Development.Diagrams.Entity Views.WebHome" section="HOverviewERD"/}}

== Analysis Entity Model ==

The ClaimAssessmentBoundary pipeline produces a hierarchy of entities: the input is decomposed into AtomicClaims (Stage 1), evidence is gathered from web sources (Stage 2), evidence is clustered into ClaimAssessmentBoundaries (Stage 3), verdicts are generated per-claim via LLM debate (Stage 4), and aggregated into an OverallAssessment (Stage 5).

{{include reference="FactHarbor.Product Development.Diagrams.Analysis Entity Model ERD.WebHome"/}}

//For complete field-level detail per entity and per pipeline phase, see [[Entity Views>>FactHarbor.Product Development.Diagrams.Entity Views.WebHome]].//

== Entity Descriptions ==

|= Entity |= Purpose |= Source Interface |= Key Relationships
| **CBClaimUnderstanding** | Stage 1 output: decomposition of input into AtomicClaims with Gate 1 stats and preliminary evidence | ##types.ts:942## | Parent of AtomicClaim[]; contains gate1Stats, preliminaryEvidence
| **AtomicClaim** | Single verifiable assertion extracted from user input; the analytical unit. Only central claims (high/medium centrality) survive extraction. | ##types.ts:715## | Receives CBClaimVerdict[]; has centrality, harmPotential, groundingQuality, expectedEvidenceProfile
| **ClaimAssessmentBoundary** | Evidence-emergent grouping of compatible EvidenceScopes; the top-level analytical frame. Created post-research by clustering EvidenceScopes. | ##types.ts:747## | Contains EvidenceItem[] and constituentScopes[]; referenced by BoundaryFinding[]; has internalCoherence
| **CBClaimVerdict** | Per-claim verdict with truth percentage, confidence, reasoning, boundary findings, challenge responses, and misleadingness assessment | ##types.ts:791## | References EvidenceItem[] (supporting + contradicting); contains BoundaryFinding[], ConsistencyResult, ChallengeResponse[], TriangulationScore, TruthPercentageRange
| **EvidenceItem** | Extracted statement from a web source with quality metadata (probativeValue, scopeQuality, sourceType, derivative tracking) | ##types.ts:385## | References FetchedSource; assigned to ClaimAssessmentBoundary via claimBoundaryId; has EvidenceScope
| **FetchedSource** | Web source with URL, content, and source reliability score (0.0-1.0 from LLM evaluation, with confidence and consensus) | ##types.ts:447## | Referenced by EvidenceItem[]
| **OverallAssessment** | Final aggregated result: weighted truth percentage, verdict, confidence, narrative, coverage matrix, quality gates, explanation quality check | ##types.ts:1035## | Aggregates CBClaimVerdict[], ClaimAssessmentBoundary[]; has VerdictNarrative, CoverageMatrix, QualityGates, ExplanationQualityCheck, TruthPercentageRange
| **VerdictNarrative** | Structured narrative: headline, evidence base summary, key finding, boundary disagreements, limitations | ##types.ts:927## | Contained by OverallAssessment

=== Additional Entities ===

* **EvidenceScope** (##types.ts:226##) — Per-evidence methodology metadata (methodology [optional], temporal [optional], boundaries, geographic, sourceType, additionalDimensions). All fields except ##name## are optional; populated when available from the source. Embedded in EvidenceItem.
* **BoundaryFinding** (##types.ts:773##) — Per-boundary quantitative signals within a CBClaimVerdict: boundaryId, boundaryName, truthPercentage, confidence, evidenceDirection, evidenceCount.
* **ConsistencyResult** (##types.ts:820##) — Self-consistency check output: verdict stability across multiple LLM runs (percentages[], average, spread, stable flag, assessed flag).
* **ChallengeDocument** (##types.ts:845##) — Output of the adversarial challenge step (Stage 4, Step 3): contains per-claim arrays of ChallengePoints.
* **ChallengePoint** (##types.ts:857##) — A single adversarial challenge against a verdict: id, type (assumption/missing_evidence/methodology_weakness/independence_concern), description, evidenceIds, severity, challengeValidation.
* **ChallengeValidation** (##types.ts:874##) — Structural validation of a challenge point's evidence references: evidenceIdsValid, validIds[], invalidIds[]. Populated by ##validateChallengeEvidence()## before reconciliation.
* **ChallengeResponse** (##types.ts:885##) — How adversarial challenges were addressed in reconciliation: challengeType, response, verdictAdjusted, adjustmentBasedOnChallengeIds.
* **TriangulationScore** (##types.ts:898##) — Cross-boundary agreement assessment: supporting/contradicting boundary counts, level (strong/moderate/weak/conflicted), factor.
* **CoverageMatrix** (##types.ts:912##) — Claims x boundaries evidence distribution: claim IDs (rows), boundary IDs (columns), counts[][] per cell. Provides ##getBoundariesForClaim()## and ##getClaimsForBoundary()## accessors.
* **TruthPercentageRange** (##types.ts:835##) — Plausible range for a truth percentage verdict (min, max), computed from self-consistency spread and optionally widened by boundary variance. Attached to both CBClaimVerdict and OverallAssessment.
* **CBResearchState** (##types.ts:971##) — Top-level research container holding CBClaimUnderstanding, EvidenceItem[], FetchedSource[], SearchQuery[], query budget tracking, iteration tracking, ClaimAssessmentBoundary[], and accumulated AnalysisWarning[].

=== Explanation Quality Entities (B-8) ===

* **ExplanationQualityCheck** (##types.ts:1023##) — Explanation quality check result, attached to OverallAssessment: mode (structural or rubric), structuralFindings, rubricScores (when mode is rubric).
* **ExplanationStructuralFindings** (##types.ts:998##) — Tier 1 deterministic structural check: hasCitedEvidence, hasVerdictCategory, hasConfidenceStatement, hasLimitations.
* **ExplanationRubricScores** (##types.ts:1009##) — Tier 2 LLM-powered rubric evaluation: clarity, completeness, neutrality, evidenceSupport, appropriateHedging (each scored 1-5), overallScore (weighted average), flags[].

== Quality Gate Entities ==

Two quality gates produce validation entities that attach to the analysis result.

|= Entity |= Gate |= Purpose |= Key Fields |= Source
| **ClaimValidationResult** | Gate 1 | Per-claim factuality + fidelity check | ##isFactual##, ##opinionScore##, ##specificityScore##, ##claimType##, ##passed## | ##types.ts:105##
| **VerdictValidationResult** | Gate 4 | Per-verdict confidence assessment | ##evidenceCount##, ##averageSourceQuality##, ##evidenceAgreement##, ##confidenceTier## | ##types.ts:121##
| **QualityGates** | Both | Aggregate pass/fail with Gate1Stats and Gate4Stats | ##passed##, ##gate1Stats##, ##gate4Stats##, ##summary## | ##types.ts:172##

Gate 1 statistics (##Gate1Stats##, ##types.ts:137##) track total claims evaluated, passed, filtered, and central claims kept despite failing validation. The CB pipeline's ##CBClaimUnderstanding.gate1Stats## additionally tracks ##passedFidelity## — the count of claims passing the fidelity check.

Gate 4 statistics (##Gate4Stats##, ##types.ts:148##) track verdict confidence distribution across HIGH, MEDIUM, LOW, and INSUFFICIENT tiers.

For detailed quality gate criteria and examples, see [[Quality Gates Deep Dive>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]].

== Configuration Entities ==

Four configuration profiles are stored as immutable JSON blobs in the UCM (Unified Config Management) system. Each analysis job records the exact config snapshot used for reproducibility.

|= Config |= Purpose |= Key Settings |= Source
| **PipelineConfig** | Pipeline operational settings | LLM provider selection, model tiering, budget controls, context detection, confidence calibration | ##config-schemas.ts:86##
| **CalcConfig** | Calculation and aggregation | Verdict bands, centrality weights, contestation penalties, quality gate thresholds, deduplication | ##config-schemas.ts:751##
| **SearchConfig** | Search provider settings | Provider selection, max results, timeout, domain whitelist/blacklist | ##config-schemas.ts:52##
| **SourceReliabilityConfig** | Source reliability service | Multi-model consensus, confidence/consensus thresholds, cache TTL, platform skip lists | ##config-schemas.ts:598##

For configuration storage and versioning, see [[Storage and Configuration>>FactHarbor.Product Development.Specification.Architecture.Storage and Configuration.WebHome]].

== 7-Point Verdict Scale ==

{{include reference="FactHarbor.Product Development.Diagrams.Verdict Scale.WebHome"/}}

//The 7-point verdict scale maps truth percentages to verdict labels. MIXED (evidence on both sides, confidence >= 40%) and UNVERIFIED (insufficient evidence, confidence < 40%) share the same percentage range but differ in their confidence interpretation.//

|= Verdict |= Truth % Range |= Meaning
| **TRUE** | 86-100% | Claim is well-supported by strong evidence
| **MOSTLY TRUE** | 72-85% | Claim is largely supported with minor caveats
| **LEANING TRUE** | 58-71% | More evidence supports than contradicts, but not conclusive
| **MIXED** | 43-57% (confidence >= 40%) | Significant evidence on both sides
| **UNVERIFIED** | 43-57% (confidence < 40%) | Insufficient evidence to determine truth
| **LEANING FALSE** | 29-42% | More evidence contradicts than supports
| **MOSTLY FALSE** | 15-28% | Claim is largely contradicted by evidence
| **FALSE** | 0-14% | Claim is strongly contradicted by evidence

=== MIXED vs. UNVERIFIED ===

Both occupy the 43-57% truth range. The distinction is **confidence-based**:
* **MIXED**: The system found substantial evidence but it points in opposing directions (high confidence in the conflict)
* **UNVERIFIED**: The system could not find enough evidence to make a determination (low confidence due to insufficient data)

== Job Lifecycle ==

{{include reference="FactHarbor.Product Development.Diagrams.Job Lifecycle ERD.WebHome"/}}

=== Job Status Transitions ===

|= Status |= Meaning
| **QUEUED** | Job submitted, waiting for runner capacity
| **RUNNING** | ClaimAssessmentBoundary pipeline is executing
| **SUCCEEDED** | Analysis complete, results available
| **FAILED** | Analysis failed (provider error, timeout, or input issue)
| **PAUSED** | System auto-paused due to provider outage (jobs resume when system recovers)

== Audit Trail ==

{{include reference="FactHarbor.Product Development.Diagrams.Audit Trail ERD.WebHome"/}}

== Storage ==

Analysis results are currently stored as **JSON blobs** in SQLite (via the .NET Entity Framework ##ResultJson## field). The full entity model above lives within this JSON blob — it is not normalised into separate database tables.

|= Database |= Technology |= Contents
| ##factharbor.db## | .NET Entity Framework Core | Jobs, events, analysis results (JSON), metrics
| ##config.db## | Next.js better-sqlite3 | UCM configuration blobs, activation pointers, usage tracking
| ##source-reliability.db## | Next.js better-sqlite3 | Source credibility evaluation cache

**Target Evolution:** PostgreSQL for primary storage (enabling full-text search, user accounts), with the JSON blob approach preserved for backwards compatibility during migration. See [[Storage and Configuration>>FactHarbor.Product Development.Specification.Architecture.Storage and Configuration.WebHome]] for details, and [[Target Data Model>>FactHarbor.Product Development.Specification.Data Model.WebHome]] for the normalised design specification.

== Deep Dives ==

* [[Calculations and Verdicts>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Calculations and Verdicts.WebHome]] — Verdict calculation formulas, aggregation hierarchy, weighting factors
* [[Confidence Calibration>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Confidence Calibration.WebHome]] — 4-layer confidence system, penalty calculations
* [[KeyFactors Design>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.KeyFactors Design.WebHome]] — //Historical (Orchestrated pipeline).// Retained for design context on how CB pipeline's boundary-based approach evolved.

----

**Navigation:** [[Architecture>>FactHarbor.Product Development.Specification.Architecture.WebHome]] | Prev: [[AKEL Pipeline>>FactHarbor.Product Development.Specification.Architecture.AKEL Pipeline.WebHome]] | Next: [[External Dependencies>>FactHarbor.Product Development.Specification.Architecture.External Dependencies.WebHome]]
