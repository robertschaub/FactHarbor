= FactHarbor Terminology Reference =

**Version**: 4.0.0-cb
**Date**: 2026-02-16
**Audience**: Developers, Prompt Engineers, LLM Systems
**Status**: ClaimBoundary pipeline (default) - Orchestrated pipeline removed

----

== Purpose ==

This document provides the **authoritative glossary** for FactHarbor's ClaimBoundary pipeline terminology across all layers: TypeScript code, JSON schema, database storage, and LLM prompts. Use this as the single source of truth when encountering ambiguous terms.

{{info}}
**ClaimBoundary is now the default pipeline** (as of Phase 2: Cutover, February 2026). The Orchestrated pipeline (which used AnalysisContext) has been completely removed.

* **All code** uses ClaimBoundary, AtomicClaim, claimBoundaryId.
* **NEVER use** in new code: AnalysisContext, contextId, analysisContexts.
* Full architecture: [[ClaimBoundary Pipeline Architecture>>path:/Docs/WIP/ClaimBoundary_Pipeline_Architecture_2026-02-15.md]]
* Migration state: See [[CB Execution State>>path:/Docs/WIP/CB_Execution_State.md]]
{{/info}}

----

== Field Mapping Table (v4.0.0-cb) ==

**ClaimBoundary Pipeline**: All code uses ClaimBoundary terminology. AnalysisContext fields removed.

|= Concept |= TypeScript Type |= JSON Field (v4.0.0-cb) |= JSON Field (Legacy - removed) |= Prompt Term
| Atomic claim | ##AtomicClaim## | ##atomicClaims## | ~~##claims##~~ | AtomicClaim
| Claim boundary | ##ClaimBoundary## | ##claimBoundaries## | ~~##analysisContexts##~~ | ClaimBoundary
| Per-evidence metadata | ##EvidenceScope## | ##evidenceScope## | ##evidenceScope## (unchanged) | EvidenceScope
| Boundary finding | ##BoundaryFinding## | ##boundaryFindings## | (new field) | BoundaryFinding
| Claim verdict | ##ClaimVerdict## | ##claimVerdicts## | ~~##claimAssessments##~~ | ClaimVerdict
| Evidence item | ##EvidenceItem## | ##evidenceItems## | ##evidenceItems## (unchanged) | EvidenceItem
| Evidence statement | ##statement## | ##statement## | ##statement## (unchanged) | statement
| Evidence ID prefix | ##EV_001, EV_002...## | ##EV_001, EV_002...## | ~~##E1, E2, E3...##~~ | EV-prefix
| Coverage matrix | ##CoverageMatrix## | ##coverageMatrix## | (new field) | CoverageMatrix
| Verdict narrative | ##VerdictNarrative## | ##verdictNarrative## | (new field) | VerdictNarrative

**Schema Version**: 3.0.0-cb (resultJson schema)

----

== Pipeline Hierarchy: Understanding the Flow ==

FactHarbor's ClaimBoundary pipeline follows a sequential 5-stage flow:

=== Stage 1: EXTRACT CLAIMS (Two-Pass, Evidence-Grounded) ===

* **What:** Parse input and extract central, verifiable AtomicClaims
* **When:** First stage of pipeline (before research)
* **Output:** ##AtomicClaim[]## — only claims with ##isCentral: true##
* **Key fields:** ##statement##, ##centrality##, ##harmPotential##, ##specificityScore##, ##groundingQuality##, ##expectedEvidenceProfile##
* **JSON field:** ##atomicClaims##

=== Stage 2: RESEARCH ===

* **What:** Gather evidence for each claim via web search and extraction
* **When:** After claims extracted, before boundary clustering
* **Output:** ##EvidenceItem[]## — each with mandatory ##EvidenceScope##
* **Key principle:** Claims drive all research (no context-driven queries)
* **ID format:** ##EV_001, EV_002, ...## (EV-prefix for Evidence)
* **JSON field:** ##evidenceItems##

=== Stage 3: CLUSTER BOUNDARIES ===

* **What:** Organize evidence into ClaimBoundaries by clustering compatible EvidenceScopes
* **When:** After research complete, before verdict generation
* **Output:** ##ClaimBoundary[]## + evidence assignments
* **Key principle:** Boundaries emerge from evidence (not predetermined)
* **Clustering factors:** Methodology, boundaries, geographic, temporal congruence
* **JSON field:** ##claimBoundaries##

=== Stage 4: VERDICT (LLM Debate Pattern) ===

* **What:** Generate per-claim verdicts using 5-step debate (advocate → self-consistency → challenge → reconciliation → validation)
* **When:** After boundary clustering complete
* **Output:** ##ClaimVerdict[]## — one per AtomicClaim, with ##boundaryFindings[]##
* **Module:** ##verdict-stage.ts## (separate module)
* **JSON field:** ##claimVerdicts##

=== Stage 5: AGGREGATE ===

* **What:** Compute coverage matrix, triangulation, and overall assessment with narrative
* **When:** Final stage
* **Output:** ##OverallAssessment## with ##VerdictNarrative##
* **Key artifacts:** ##CoverageMatrix## (claims × boundaries), triangulation scores
* **JSON field:** ##overallAssessment##

----

**Key Distinctions:**

* **AtomicClaim** = "What verifiable assertion am I checking?" (extracted from user input)
* **EvidenceScope** = "What methodology/boundaries did THIS source use?" (per-evidence metadata)
* **ClaimBoundary** = "Which evidence items can be grouped together?" (compatible EvidenceScopes)
* **BoundaryFinding** = "What does evidence in THIS boundary say about THIS claim?" (per-boundary verdict component)

----

== Core Concepts ==

=== 1. ClaimBoundary Pipeline Terminology — NEW PIPELINE (DEFAULT) ===

{{info}}
**ClaimBoundary is now the default pipeline.** The Orchestrated pipeline (which used AnalysisContext) has been removed as of Phase 2a. All new code must use ClaimBoundary terminology.

Full architecture: [[ClaimBoundary Pipeline Architecture>>path:/Docs/WIP/ClaimBoundary_Pipeline_Architecture_2026-02-15.md]]
{{/info}}

==== 1.1 AtomicClaim ====

**What it is**: A single verifiable assertion extracted from user input. The atomic unit of analysis in the ClaimBoundary pipeline.

**Why it matters**: Each claim drives independent research. Claims must be specific enough to generate targeted search queries without additional framing.

**Examples (generic)**:
* "Entity A performed Action X during Period Y"
* "Metric M for Process P exceeds Value V"
* "Framework F applies to Situation S"

**Code representation**:

{{code language="typescript"}}
export interface AtomicClaim {
  id: string;                     // AC_01, AC_02, ...
  statement: string;              // The verifiable assertion
  category: "factual" | "evaluative" | "procedural";
  centrality: "high" | "medium";
  harmPotential: "critical" | "high" | "medium" | "low";
  isCentral: boolean;             // true (only central claims survive)
  claimDirection: "supports_thesis" | "contradicts_thesis" | "contextual";
  keyEntities: string[];
  specificityScore: number;       // 0-1 (≥0.6 required)
  groundingQuality: "strong" | "moderate" | "weak" | "none";
  expectedEvidenceProfile: {
    methodologies: string[];
    expectedMetrics: string[];
    expectedSourceTypes: SourceType[];
  };
}
{{/code}}

**Variable names**: ##atomicClaim##, ##atomicClaims##

**NEVER call it**: "context", "fact"

----

==== 1.2 ClaimBoundary ====

**What it is**: An evidence-emergent grouping of compatible EvidenceScopes, created //after// research by clustering evidence with congruent methodology, temporal, boundaries, and geographic dimensions.

**Why it matters**: ClaimBoundaries organize evidence for verdict generation. Instead of pre-creating analytical frames (which caused instability), boundaries emerge from the evidence itself.

**Key principle**: Evidence tells us what boundaries exist. We don't guess.

**Examples (generic)**:
* "Methodology A studies" (evidence using Framework A)
* "Jurisdiction J proceedings" (evidence from legal domain J)
* "Period P data" (evidence from temporal range P)

**Code representation**:

{{code language="typescript"}}
export interface ClaimBoundary {
  id: string;                     // CB_01, CB_02, ...
  name: string;                   // Human-readable label
  shortName: string;              // Short label for UI tabs
  description: string;            // What this boundary represents
  methodology?: string;           // Dominant methodology (if applicable)
  boundaries?: string;            // Scope boundaries
  geographic?: string;            // Geographic scope
  temporal?: string;              // Temporal scope
  internalCoherence: number;      // 0-1: consistency of evidence within
  evidenceCount: number;          // Number of evidence items
}
{{/code}}

**Variable names**: ##claimBoundary##, ##claimBoundaries##, ##claimBoundaryId##

**NEVER call it**: "context", "scope", "analysisContext"

----

==== 1.3 BoundaryFinding ====

**What it is**: Per-boundary quantitative evidence assessment for a specific claim. Each ClaimVerdict contains boundaryFindings[] showing how evidence within each boundary supports or contradicts the claim.

**Why it matters**: Enables multi-perspective verdicts — the same claim may have different support levels across different ClaimBoundaries.

**Code representation**:

{{code language="typescript"}}
export interface BoundaryFinding {
  boundaryId: string;                           // Which ClaimBoundary
  truthPercentage: number;                      // 0-100 per-boundary assessment
  confidence: number;                           // 0-100 per-boundary confidence
  evidenceDirection: "supports" | "contradicts" | "mixed" | "neutral";
  evidenceCount: number;                        // Evidence items in this boundary for this claim
}
{{/code}}

**Used in**: ##ClaimVerdict.boundaryFindings[]##

----

==== 1.4 ClaimVerdict ====

**What it is**: Final verdict for a single AtomicClaim, produced by the 5-step LLM debate pattern (advocate → self-consistency → challenge → reconciliation → validation).

**Code representation**:

{{code language="typescript"}}
export interface ClaimVerdict {
  id: string;
  claimId: string;                              // Which AtomicClaim
  truthPercentage: number;                      // 0-100 overall
  verdict: string;                              // 7-point scale label
  confidence: number;                           // 0-100 overall
  reasoning: string;                            // LLM-generated explanation
  harmPotential: "critical" | "high" | "medium" | "low";
  isContested: boolean;                         // Documented counter-evidence exists
  supportingEvidenceIds: string[];
  contradictingEvidenceIds: string[];
  boundaryFindings: BoundaryFinding[];          // Per-boundary assessments
  challengeResponses?: string[];                // From reconciliation step
}
{{/code}}

**Variable names**: ##claimVerdict##, ##claimVerdicts##

----

==== 1.5 CoverageMatrix ====

**What it is**: A deterministic claims × boundaries matrix showing which claims have been evaluated in which boundaries.

**Why it matters**: Ensures analytical completeness — every claim must have evidence across relevant boundaries. Logged to job events for transparency.

**Code representation**:

{{code language="typescript"}}
export interface CoverageMatrix {
  claims: string[];                            // AtomicClaim IDs
  boundaries: string[];                        // ClaimBoundary IDs
  coverage: boolean[][];                       // claims[i] × boundaries[j] → has evidence?
  missingCoverage: Array<{
    claimId: string;
    boundaryId: string;
    reason: string;
  }>;
}
{{/code}}

----

==== 1.6 VerdictNarrative ====

**What it is**: Structured summary of the overall assessment, including boundary disagreements and limitations. LLM-generated (Sonnet, 1 call) during Stage 5: AGGREGATE.

**Code representation**:

{{code language="typescript"}}
export interface VerdictNarrative {
  headline: string;                           // 1-sentence summary
  evidenceBaseSummary: string;                // What evidence was found
  keyFinding: string;                         // Most important conclusion
  boundaryDisagreements: Array<{
    boundaryIds: string[];
    disagreementSummary: string;
  }>;
  limitations: string[];                      // Gaps, uncertainties, caveats
}
{{/code}}

**Used in**: ##OverallAssessment.verdictNarrative##

----

=== 2. EvidenceScope (Per-Evidence Source Metadata) — SHARED CONCEPT ===

**What it is**: Metadata attached to individual evidence items describing the methodology, boundaries, geography, and time period that **the source document** used when producing that evidence.

**Why it matters**: Evidence stating "Metric X = Value Y" from a study using Methodology A with Boundary Set B cannot be directly compared to a study using Methodology C with Boundary Set D. EvidenceScope captures these methodological differences so the pipeline can cluster compatible evidence into ClaimBoundaries.

**Examples (generic)**:
* Methodology: "Standard S", "Framework F", "Protocol P"
* Boundaries: "Full system", "Subsystem only", "Phases 1-3"
* Geographic: "Jurisdiction J", "Region R", "Multi-national"
* Temporal: "Period P data", "Year Y baseline", "Historical range"

**Primary fields (always extracted when available)**:
* ##methodology##: The analytical approach used by the source (e.g., "Standard ISO-X", "Regulatory Framework Y")
* ##temporal##: When the source data was collected or applies (e.g., "Data from Period P", "Baseline Year Y")

**Other fields**:
* ##boundaries##: What was included/excluded in the analysis (e.g., "Full lifecycle", "Operation phase only")
* ##geographic##: Geographic scope of the source data (e.g., "Region R", "Country C")
* ##additionalDimensions##: Domain-specific scope data (e.g., `{ "sample_size": "N=12000", "blinding": "double-blind" }`)

//Note: All fields except ##name## are optional in the TypeScript type (##types.ts:226##). The LLM is instructed to extract ##methodology## and ##temporal## for every evidence item, but extraction is best-effort — ##scopeQuality## on EvidenceItem tracks completeness.//

**Code representation**:

{{code language="typescript"}}
export interface EvidenceScope {
  name: string;                             // Short label (e.g., "Methodology A", "Framework B")
  methodology?: string;                     // Optional — extracted when source provides it
  temporal?: string;                        // Optional — extracted when source provides it
  boundaries?: string;                      // Optional
  geographic?: string;                      // Optional
  sourceType?: SourceType;                  // Optional classification
  additionalDimensions?: Record<string, string>; // Optional domain-specific data
}

// Attached to evidence items
export interface EvidenceItem {
  id: string;                               // EV_001, EV_002, ... (EV-prefix)
  statement: string;                        // The evidence statement
  evidenceScope: EvidenceScope;             // MANDATORY (not optional)
  claimBoundaryId?: string;                 // Assigned during CLUSTER stage
  relevantClaimIds: string[];               // Which claims this evidence relates to
  isDerivative: boolean;                    // Derives from another source's study
  derivedFromSourceUrl?: string;            // URL of original source (optional)
  scopeQuality: "complete" | "partial" | "incomplete"; // Scope metadata quality
  // ...
}
{{/code}}

**JSON field name**:

{{code language="json"}}
{
  "evidenceItems": [
    {
      "id": "EV_001",
      "statement": "Entity A achieved Metric X using Method M",
      "evidenceScope": {
        "name": "Method M Analysis",
        "methodology": "Standard S with Approach A",
        "temporal": "Period P data (Year-Year)",
        "boundaries": "Full system boundary",
        "geographic": "Region R",
        "additionalDimensions": {
          "sample_size": "N=12000",
          "confidence_level": "95%"
        }
      },
      "scopeQuality": "complete",
      "claimBoundaryId": "CB_01",
      "relevantClaimIds": ["AC_01", "AC_03"]
    }
  ]
}
{{/code}}

**Prompt terminology**:
* Always: "EvidenceScope"
* NEVER: "scope" (ambiguous), "context"

**Key differences from ClaimBoundary**:
* **EvidenceScope** = Per-evidence metadata ("What methodology did THIS source use?")
* **ClaimBoundary** = Cluster of compatible EvidenceScopes ("Which evidence can be grouped together?")
* Multiple evidence items share the same EvidenceScope → they cluster into the same ClaimBoundary
* EvidenceScopes with incompatible methodology/boundaries/temporal/geographic → separate ClaimBoundaries

----

=== 3. Background Details (Narrative Background) ===

**What it is**: The narrative/rhetorical framing or background context of the input article. This describes **how the article presents** the information, but is NOT a reason to split into separate AnalysisContexts.

**Why it matters**: Helps understand the user's intent and article structure, but does NOT affect verdict logic.

**Examples**:
* "Brazilian political crisis following January 8th events"
* "Climate policy debate in European Union"
* "Legal proceedings against former president"

**Code representation**:

{{code language="typescript"}}
// Stored as string in ClaimUnderstanding
export interface ClaimUnderstanding {
  backgroundDetails: string; // Narrative background
  // ...
}
{{/code}}

**JSON field name** (v3.1):

{{code language="json"}}
{
  "backgroundDetails": "Brazilian political crisis following January 8th events"
}
{{/code}}

**UI Display**: Shown in ##BackgroundBanner.tsx## component with label "Background"

**Prompt terminology**:
* Preferred: "backgroundDetails" or "Background"
* Removed: ~~"ArticleFrame"~~, ~~"analysisContext" (singular)~~ (legacy terms)

**Common confusion**:
* backgroundDetails is NOT an AnalysisContext (not a reason to split analysis)
* backgroundDetails does NOT get its own verdict
* backgroundDetails IS purely descriptive/informational

----

=== 4. Doubted vs Contested (Contestation Classification) - v2.8 ===

**What it is**: A distinction between two types of opposition to a claim, which affects how the opposition impacts the verdict weight.

**Why it matters**: Not all criticism is equal. Political statements without evidence shouldn't reduce a claim's weight as much as documented counter-evidence. This ensures:
* **Evidence-based contestation** appropriately reduces certainty
* **Opinion-based doubt** doesn't unfairly penalize well-evidenced claims

**Two Categories**:

|= Category |= factualBasis |= Weight Multiplier |= Example
| **DOUBTED** | ##"opinion"## | 1.0x (full) | "Government says trial was unfair" (no specifics)
| **DOUBTED** | ##"alleged"## | 1.0x (full) | "Critics claim bias" (no evidence cited)
| **CONTESTED** | ##"disputed"## | 0.7x (reduced) | "Defense presented conflicting expert testimony"
| **CONTESTED** | ##"established"## | 0.5x (reduced) | "Audit found violation of Regulation 47(b)"

**Weight calculation** (in ##getClaimWeight()##, v3.1 — updated in v2.9.0):

{{code language="typescript"}}
if (claim.isContested) {
  if (basis === "established") weight *= 0.5;  // Strong counter-evidence (updated v2.9.0: was 0.3x)
  else if (basis === "disputed") weight *= 0.7; // Some counter-evidence (updated v2.9.0: was 0.5x)
  // "opinion"/"alleged"/"unknown" -> full weight (just doubted)
}
{{/code}}

**Common confusion**:
* "contested" does NOT mean "disputed politically" (that's "doubted")
* "contested" means there IS documented counter-evidence
* Political statements alone do NOT reduce claim weight
* Only factual counter-evidence reduces claim weight

----

== Terminology Mapping Tables ==

=== Table 1: Primary Entities (v4.0.0-cb) ===

|= Concept |= TypeScript Name (CB) |= JSON Field |= Prompt Term |= Formerly (Orchestrated — removed)
| Top-level analytical frame | ##ClaimAssessmentBoundary## | ##claimBoundaries## | "ClaimBoundary" | ~~##AnalysisContext## / ##analysisContexts##~~
| Atomic verifiable assertion | ##AtomicClaim## | ##atomicClaims## | "AtomicClaim" | ~~##SubClaim##~~
| Per-evidence source metadata | ##EvidenceScope## | ##evidenceScope## | "EvidenceScope" | ##EvidenceScope## (unchanged)
| Evidence item | ##EvidenceItem## | ##evidenceItems## | "EvidenceItem" | ##EvidenceItem## (unchanged)
| Per-boundary verdict component | ##BoundaryFinding## | ##boundaryFindings## | "BoundaryFinding" | (new in CB)
| Per-claim verdict | ##CBClaimVerdict## | ##claimVerdicts## | "ClaimVerdict" | ~~##ClaimVerdict##~~ (restructured)
| Narrative background | (string) | ##backgroundDetails## | "Background" | ##backgroundDetails## (unchanged)

=== Table 2: Reference Fields (v4.0.0-cb) ===

|= Field Purpose |= TypeScript Field |= JSON Field |= Prompt Term |= Valid Values
| Evidence → ClaimAssessmentBoundary | ##claimBoundaryId?: string## | ##claimBoundaryId## | "claimBoundaryId" | Must match ##ClaimAssessmentBoundary.id##
| Claim → relevant evidence | ##relevantClaimIds: string[]## | ##relevantClaimIds## | "relevantClaimIds" | Array of AC-prefix IDs
| Supporting evidence | ##supportingEvidenceIds## | ##supportingEvidenceIds## | "supportingEvidenceIds" | Array of EV-prefix IDs

{{warning}}
**Removed reference fields** (Orchestrated pipeline — do not use in new code):
~~##contextId##~~ (claim/evidence → AnalysisContext — removed), ~~##analysisContexts##~~ (top-level context array — removed), ~~##claimAssessments##~~ (renamed to ##claimVerdicts##)
{{/warning}}

=== Table 3: Special Constants ===

{{info}}
**Orchestrated-era constants removed**: ~~##CTX_UNSCOPED##~~, ~~##CTX_MAIN##~~, ~~##CTX_GENERAL##~~ no longer exist in the CB pipeline. ClaimAssessmentBoundaries emerge from evidence clustering and do not use fixed fallback constants.
{{/info}}

----

== Quick Reference: "Which term should I use?" ==

=== In TypeScript Code ===

{{code language="typescript"}}
// CORRECT (v4.0-cb)
import { AtomicClaim, ClaimAssessmentBoundary, EvidenceScope, EvidenceItem } from './types';

function processBoundaries(boundaries: ClaimAssessmentBoundary[]) {
  // ...
}

function processEvidence(items: EvidenceItem[]) {
  // ...
}

// REMOVED in v4.0-cb - do not use:
// AnalysisContext    → use ClaimAssessmentBoundary
// SubClaim           → use AtomicClaim
// ContextAnswer      → removed (no equivalent in CB)
// ExtractedFact      → use EvidenceItem (removed in v3.0)
{{/code}}

=== In JSON Schema (Zod) ===

{{code language="typescript"}}
// CORRECT (v4.0-cb field names)
const schema = z.object({
  atomicClaims: z.array(AtomicClaimSchema),
  claimBoundaries: z.array(ClaimAssessmentBoundarySchema),
  evidenceItems: z.array(EvidenceItemSchema),
  backgroundDetails: z.string(),
});
{{/code}}

=== In LLM Prompts ===

{{code language="typescript"}}
// CORRECT (v4.0-cb terminology)
const prompt = `
## TERMINOLOGY

**AtomicClaim**: Single verifiable assertion extracted from user input (stored as atomicClaims)
**EvidenceScope**: Per-evidence source metadata (stored as evidenceItem.evidenceScope)
**ClaimBoundary**: Evidence-emergent grouping of compatible EvidenceScopes (stored as claimBoundaries)
**EvidenceItem**: Individual evidence with id (EV-prefix) and statement

Your task: Extract AtomicClaims from user input...
`;

// AVOID (Orchestrated-era terms — pipeline removed)
const prompt = `Identify AnalysisContexts from evidence...`;  // Orchestrated-only concept
const prompt = `Extract facts...`;  // Use "evidence" not "facts"
{{/code}}

=== In UI/Documentation ===

{{code language="typescript"}}
// CORRECT (v4.0-cb)
<h2>Claim Boundaries</h2>
<p>This analysis identified 2 evidence-emergent boundaries:</p>

<BackgroundBanner backgroundDetails={background} />

// REMOVED in v4.0-cb:
// <h2>Analysis Contexts</h2>  → use "Claim Boundaries"
// <ArticleFrameBanner articleFrame={...} />  → removed
{{/code}}

----

== Pipeline Stage Functions (v4.0.0-cb) ==

|= Stage Function |= Description |= Pipeline Module
| ##extractClaims## | Two-pass LLM claim extraction (PASS1 → PASS2); Gate 1 application | ##claimboundary-pipeline.ts## Stage 1
| ##researchEvidence## | Iterative web research: query generation, fetch, EvidenceItem extraction | ##claimboundary-pipeline.ts## Stage 2
| ##clusterBoundaries## | LLM clustering of EvidenceScopes into ClaimAssessmentBoundaries | ##claimboundary-pipeline.ts## Stage 3
| ##generateVerdicts## | Advocate → Challenger → Reconciliation debate per boundary | ##verdict-stage.ts## Stage 4
| ##aggregateAssessment## | Gate 4, weighted aggregation, VerdictNarrative generation | ##claimboundary-pipeline.ts## Stage 5

{{warning}}
**Removed Orchestrated task names** (do not use): ~~##extract_evidence##~~, ~~##context_refinement##~~, ~~##understand##~~, ~~##verdict##~~ — these are Orchestrated pipeline function names, not CB stages. Also removed: ~~##extract_facts##~~, ~~##scope_refinement##~~ (pre-v3.0 names).
{{/warning}}

----

== Config Field Names (CB Pipeline) ==

{{warning}}
**Orchestrated-era config fields removed**: ~~##contextDetectionMethod##~~, ~~##contextDetectionEnabled##~~, ~~##contextDetectionMinConfidence##~~, ~~##contextDetectionMaxContexts##~~, ~~##contextDedupThreshold##~~ no longer exist. These were part of the removed Orchestrated pipeline's context detection system.
{{/warning}}

Current CB pipeline config fields (UCM-managed — see [[Quality Gates>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]] and [[Pipeline Variants>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Pipeline Variants.WebHome]]):

|= Config Field |= Description |= Default
| ##gate1Enabled## | Enable Gate 1 claim validation | ##true##
| ##gate1KeepCentralClaims## | Always keep ##isCentral## claims through Gate 1 | ##true##
| ##gate4Enabled## | Enable Gate 4 verdict confidence assessment | ##true##
| ##maxResearchIterations## | Max research rounds per ClaimAssessmentBoundary | ##3##
| ##maxTotalTokens## | Token budget cap across all pipeline stages | ##750000##

----

== Decision Trees ==

=== "Should I create a ClaimAssessmentBoundary?" ===

ClaimBoundaries are **NOT manually created** — they emerge from EvidenceScope clustering during Stage 3 (##clusterBoundaries##). The decision below applies to the LLM's clustering logic:

{{code}}
START: Can these EvidenceScopes be compared directly for the same claim?
  |
  +-- YES -> Same ClaimBoundary (compatible methodology, temporal, geographic)
  |   Example: Multiple sources using the same analytical framework
  |
  +-- NO -> Are they incompatible in methodology, temporal, or geographic scope?
      |
      +-- YES -> Separate ClaimBoundaries
      |   Example: Studies using different analytical frameworks
      |
      +-- NO -> Same ClaimBoundary with noted caveats
          Example: Minor reporting period differences within same framework
{{/code}}

=== "Is this an EvidenceScope or backgroundDetails?" ===

{{code}}
START: Where does this information come from?
  |
  +-- FROM SOURCE DOCUMENT -> EvidenceScope
  |   Example: "Study used ISO 14040 methodology"
  |   Attach to evidenceItem.evidenceScope
  |
  +-- FROM USER INPUT / ARTICLE FRAMING -> backgroundDetails
      Example: "Article is written as opinion piece"
      Store as backgroundDetails string (NOT a ClaimAssessmentBoundary)
{{/code}}

----

== Common Pitfalls & Solutions ==

=== Pitfall 1: Using "Scope" Without Qualifier ===

**Problem**:

{{code language="typescript"}}
// Ambiguous - which scope?
function getScope(id: string) { ... }
{{/code}}

**Solution**:

{{code language="typescript"}}
// Explicit
function getClaimAssessmentBoundary(id: string): ClaimAssessmentBoundary { ... }
function getEvidenceScope(evidence: EvidenceItem): EvidenceScope | null { ... }
{{/code}}

=== Pitfall 2: Conflating backgroundDetails with ClaimAssessmentBoundary ===

**Problem** (creates spurious boundaries):

{{code language="json"}}
{
  "claimBoundaries": [
    { "name": "Article frames as conspiracy theory" }
  ]
}
{{/code}}

**Solution** (background → string field, boundaries → evidence-emergent):

{{code language="json"}}
{
  "backgroundDetails": "Article frames as conspiracy theory",
  "claimBoundaries": [
    { "name": "Peer-reviewed study evidence (Framework A)" }
  ]
}
{{/code}}

=== Pitfall 3: Using Legacy Field Names ===

**Problem** (v4.0-cb schema will reject):

{{code language="typescript"}}
const facts = result.facts;               // REMOVED (v3.x)
const ctx = understanding.analysisContext; // REMOVED (v4.0)
const ctxs = result.analysisContexts;      // REMOVED (v4.0)
{{/code}}

**Solution**:

{{code language="typescript"}}
const evidenceItems = result.evidenceItems;    // v4.0-cb
const background = result.backgroundDetails;   // v4.0-cb
const boundaries = result.claimBoundaries;     // v4.0-cb
{{/code}}

----

== Validation Checklist ==

Use this checklist when reviewing code that involves claims/evidence/boundaries:

* Is "scope" qualified as ##ClaimAssessmentBoundary## or ##EvidenceScope##?
* Do JSON field names use v4.0-cb names (##atomicClaims##, ##claimBoundaries##, ##evidenceItems##, ##backgroundDetails##)?
* Does prompt include terminology glossary header with CB term definitions?
* Are ##claimBoundaryId## values validated against ##claimBoundaries[]##?
* Are fallbacks logged (not silent)?
* Does ##EvidenceScope## capture source methodology (not artificially create new ##ClaimAssessmentBoundaries##)?
* Is ##backgroundDetails## separate from ##claimBoundaries##?
* Are evidence IDs using EV-prefix (##EV_001, EV_002, EV_003...##)?

----

== FAQ ==

**Q: When should I use EvidenceScope vs ClaimAssessmentBoundary?**

A: If the information describes **how a source document computed its data** (methodology, temporal bounds, geographic scope), it's ##EvidenceScope## — attached to an evidence item. ##ClaimAssessmentBoundary## is NOT manually assigned; it emerges from Stage 3 clustering of compatible EvidenceScopes. You never "create" a ClaimBoundary in code — the LLM creates them.

**Q: Can an evidence item have BOTH claimBoundaryId AND evidenceScope?**

A: Yes. ##claimBoundaryId## says **which ClaimAssessmentBoundary the evidence belongs to** (assigned during Stage 3 clustering), while ##evidenceScope## says **how the source computed the data** (assigned during Stage 2 extraction). They serve orthogonal purposes.

**Q: Should prompts say "ClaimBoundary", "ClaimAssessmentBoundary", or "Boundary"?**

A: Use "ClaimBoundary" for schema-facing precision (matches JSON field prefix), "ClaimAssessmentBoundary" for full clarity in documentation. "Boundary" is acceptable shorthand in prompts where context is clear. **NEVER use "AnalysisContext"** in new code or prompts — that term is from the removed Orchestrated pipeline.

**Q: What if the LLM produces zero ClaimBoundaries during Stage 3?**

A: This indicates no compatible EvidenceScopes were clustered. The pipeline has a safety net: if Stage 3 produces zero actionable boundaries, the highest-centrality claim is rescued to prevent silent empty results. First check research quality (Stage 2) and verify the ##BOUNDARY_CLUSTERING## prompt is receiving evidence items.

----

== Related Documentation ==

* [[Prompt Architecture>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Prompt Architecture.WebHome]] — Runtime UCM prompt system for CB pipeline
* [[Pipeline Variants>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Pipeline Variants.WebHome]] — Pipeline design, stage configuration, CB invariants
* AGENTS.md — High-level rules for terminology and code standards
* ##types.ts## — TypeScript interface definitions (AtomicClaim, ClaimAssessmentBoundary, EvidenceScope, EvidenceItem)

----

**Document Maintainer**: Lead Developer
**Last Reviewed**: 2026-02-19 (Updated for v4.0.0-cb ClaimAssessmentBoundary pipeline)
**Next Review**: 2026-05 (or after next major version)