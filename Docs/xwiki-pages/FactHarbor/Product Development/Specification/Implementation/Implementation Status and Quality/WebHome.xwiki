= Implementation Status and Quality =

== Implementation Status ==

=== Specification Alignment ===

|= Area |= Status |= Notes
| **Job orchestration** | Implemented | API stores job + events in SQLite; Web runner updates via internal endpoints; SSE endpoint for live events
| **Quality Gates (POC)** | Partially implemented | Analyzer applies Gate 1 (claim validation) and Gate 4 (verdict confidence); gate stats included in result JSON; display of per-item gate reasons still missing in UI/report
| **Source reliability** | Implemented | LLM-powered Source Reliability Service with sequential refinement (Claude + OpenAI), SQLite cache, multi-language support; sources store trackRecordScore/category; configured via UCM
| **Evidence model** | Partial | Claims + extracted evidence + verdicts exist in result JSON; KeyFactors implemented; AnalysisContext embedded in result JSON (not separate table)
| **KeyFactors** | Implemented | Discovered in Understanding, emergent and optional, claim-to-factor mapping via ##keyFactorId##, aggregated from claim verdicts, displayed in reports (aggregation fixed 2026-01-06)
| **AuthN/AuthZ & rate limiting** | Missing | Public UI and endpoints are open; admin test endpoints are unauthenticated; CORS is permissive in API
| **Persistence (normalized)** | Missing | API persists job metadata + JSON/markdown results; no normalized tables for claims/evidence/sources/verdicts
| **Caching & separated architecture** | Missing | Docs propose claim cache; current pipeline recomputes per job
| **Testing** | Partial | Web has unit/integration tests for analyzer; API has no tests; CI only builds

=== Working Features (v2.6.38) ===

**Core Analysis:**
* Multi-context detection and display
* Context overlap detection with LLM-driven merge heuristics (v2.6.38)
* Defensive validation: context count warnings, claim assignment validation (v2.6.38)
* Input neutrality (question ~ statement within +/-5%)
* Context extraction from sources
* Temporal reasoning (current date awareness)
* Claim deduplication for fair aggregation
* KeyFactors aggregation
* Dependency tracking and propagation
* Pseudoscience detection and escalation
* 7-point verdict scale (TRUE to FALSE)
* MIXED vs UNVERIFIED distinction (confidence-based)
* UI reliability signals for multi-context verdicts (v2.6.38)

**Infrastructure:**
* Job lifecycle management (QUEUED -> RUNNING -> SUCCEEDED/FAILED)
* Real-time progress updates via SSE
* Exponential backoff retry with jitter in RunnerClient
* PDF and HTML content extraction
* Multi-provider LLM support (Anthropic, OpenAI, Google, Mistral)
* Multi-provider search support (Google CSE, SerpAPI)

=== Known Gaps and Issues ===

**High Priority:**
1. **SSRF Protection**: URL fetching needs IP range blocking, size limits, redirect caps
1. **Admin Endpoint Security**: ##/admin/test-config## is publicly accessible and can trigger paid LLM calls
1. **Rate Limiting**: No per-IP or per-user rate limits
1. **Quality Gate Display**: Gate stats exist but not shown in UI with per-item reasons

**Medium Priority:**
1. **Metrics Tracking**: LLM token usage, search API calls, cost estimation not persisted
1. **Error Pattern Tracking**: No database schema for error patterns
1. **Model Knowledge Toggle**: ##FH_ALLOW_MODEL_KNOWLEDGE=false## not fully respected
1. **Provider-Specific Optimization**: Same prompts used for all LLM providers

**Low Priority:**
1. **URL Analyses**: URL string highlighted in reports as "claim"
1. **LLM Fallback**: Config documented but not implemented
1. **Rich Report Mode**: ##FH_REPORT_STYLE=rich## documented but not implemented

=== Recent Fixes (January 2026) ===

**v2.6.25:**
* Question-to-statement handling improvements
* ArticleSummary data generation logic
* UI layout improvements for summary page

**v2.6.24:**
* Fixed critical ##isValidImpliedClaim## bug
* Rating direction instructions strengthened
* Centrality over-marking reduced
* Question label misapplication fixed

**v2.6.23:**
* Input neutrality divergence fixed (4% -> 1%)
* Canonicalization context detection corrected
* Generic recency detection enhanced

**v2.6.18-v2.6.22:**
* Runner resilience with exponential backoff
* Job lifecycle tests added
* Analyzer modularization started
* KeyFactors aggregation fixed
* PDF fetch error handling improved

----

== Quality & Optimization ==

=== Quality Gates ===

> For detailed quality gates reference, see [[Quality Gates>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]].

**Gate 1: Claim Validation**
* Filters out opinions, predictions, low-specificity claims
* Keeps central claims regardless of specificity
* Tracks excluded claims with reasons
* Stats included in ##qualityGates.gate1Stats##

**Gate 4: Verdict Confidence Assessment**
* Requires minimum number of sources
* Source quality threshold
* Agreement threshold between sources
* Central claims remain publishable even if low confidence
* Stats included in ##qualityGates.gate4Stats##

**Implementation Location:**
* Gate 1: Applied in ##understandClaim()## during claim extraction
* Gate 4: Applied in ##generateVerdicts()## during verdict generation

=== Verdict Calculation ===

See Calculations.md (see Calculations.md in local docs) for detailed verdict calculation methodology, including:
* 7-point scale mapping
* MIXED vs UNVERIFIED distinction
* Counter-evidence handling
* Aggregation hierarchy (Evidence -> Claims -> KeyFactors -> Contexts -> Overall)
* Dependency handling
* Pseudoscience escalation
* Benchmark guard

=== Cost Optimization Opportunities ===

**Multi-Tier Model Strategy** (not yet implemented):
* Use cheaper models (Claude Haiku) for extraction tasks
* Use premium models (Claude Sonnet) for reasoning tasks
* Estimated savings: 50-70% on LLM costs

**Claim Caching** (not yet implemented):
* Cache normalized claim verdicts
* Reuse verdicts across analyses
* Estimated savings: 30-50% on repeat claims

**Search Optimization:**
* Limit sources by setting Pipeline config ##analysisMode## (quick vs deep) and iteration limits in UCM (Admin -> Config -> Pipeline). Defaults live in ##apps/web/src/lib/analyzer/config.ts##.
* Use Search config ##domainWhitelist## to improve relevance
* Use Search config ##dateRestrict## for recent topics

=== Performance Characteristics ===

**Typical Analysis Time:**
* Short text (1-2 claims): 30-60 seconds
* Medium article (5-10 claims): 2-5 minutes
* Long article (20+ claims): 5-15 minutes

**LLM Calls:**
* Understanding: 1 call
* Research: 2-6 calls (per source)
* Verdict: 1-3 calls (depending on claim count)
* Total: Typically 10-20 calls per analysis

**Search Queries:**
* Typically 3-6 queries per analysis
* Fetches 4-8 sources total
* Parallel source fetching with 5-second timeout per source

----

== Future Enhancements ==

=== Planned Improvements ===

**Security (Pre-Release):**
* SSRF protection implementation
* Authentication and authorization system
* Rate limiting and quota enforcement
* CORS tightening for production

**Performance:**
* Tiered LLM model routing
* Claim-level caching and separated architecture
* Parallel verdict generation
* Optimized prompt templates per provider

**Features:**
* Quality gate visualization in UI
* Metrics dashboard with cost tracking
* Error pattern analysis
* Historical track record for sources
* Multi-language support

**Data Model:**
* Normalized database tables for claims/evidence/sources/verdicts
* Provenance chain tracking
* Normalized AnalysisContext persistence

----

== Testing Infrastructure ==

=== Promptfoo Test Coverage (v2.8.2) ===

{{include reference="FactHarbor.Product Development.Diagrams.Promptfoo Test Coverage.WebHome"/}}

=== Test Summary ===

|= Config |= Description |= Test Cases |= Prompts Covered
| ##source-reliability## | Source reliability evaluation | 7 | 1
| ##verdict## | Verdict generation accuracy | 5 | 1
| ##text-analysis## | LLM text analysis pipeline | 26 | 4
| **Total** | | **38** | **6**

=== Running Tests ===

{{code language="bash"}}
# Run all tests
npm run promptfoo:all

# Run specific test suite
npm run promptfoo:sr              # Source reliability
npm run promptfoo:verdict         # Verdict generation
npm run promptfoo:text-analysis   # Text analysis pipeline

# View results
npm run promptfoo:view
{{/code}}

See: Promptfoo Testing Guide (in User Guides)

----

== References ==

=== Related Documentation ===

* **Context Detection**: [[Context Detection>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Context Detection.WebHome]] - Consolidated context detection guide
* **Quality Gates**: [[Quality Gates>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Quality Gates.WebHome]] - Quality gates reference
* **Calculations**: [[Calculations and Verdicts>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Calculations and Verdicts.WebHome]] - Verdict calculation methodology
* **KeyFactors Design**: [[KeyFactors Design>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.KeyFactors Design.WebHome]] - KeyFactors implementation details
* **Source Reliability**: [[Source Reliability>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Source Reliability.WebHome]] - Source scoring system
* **Prompt Architecture**: [[Prompt Architecture>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Prompt Architecture.WebHome]] - Modular prompt composition system
* **Promptfoo Testing**: [[Promptfoo Testing>>FactHarbor.Product Development.DevOps.Tooling.Promptfoo Testing.WebHome]] - Prompt testing guide
* **Pipeline Architecture**: [[Pipeline Variants>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Pipeline Variants.WebHome]] - Twin-path pipeline design
* **Getting Started**: [[Getting Started>>FactHarbor.Product Development.DevOps.Guidelines.Getting Started.WebHome]] - Setup and installation
* **LLM Configuration**: [[LLM Configuration>>FactHarbor.Product Development.DevOps.Subsystems and Components.LLM Configuration.WebHome]] - Provider configuration

=== Key Environment Variables ===

**Configuration Management:**
* **LLM Provider Selection:** Configure via UCM pipeline config (##pipeline.llmProvider##)
* **Analysis Behavior:** Configure via UCM (pipeline/search/calculation/SR configs)
* **DEPRECATED:** ##LLM_PROVIDER## environment variable is no longer used (removed 2026-02-02)

**Environment variables are only for:**
* API keys and secrets (ANTHROPIC_API_KEY, OPENAI_API_KEY, etc.)
* Deployment settings (PORT, NODE_ENV, etc.)
* Infrastructure config (DATABASE_URL, FH_ADMIN_KEY, etc.)

|= Variable |= Default |= Purpose
| ##ANTHROPIC_API_KEY## | - | Anthropic Claude API key (required if using Anthropic)
| ##OPENAI_API_KEY## | - | OpenAI API key (required if using OpenAI)
| ##GOOGLE_GENERATIVE_AI_API_KEY## | - | Google Gemini API key (required if using Google)
| ##MISTRAL_API_KEY## | - | Mistral API key (required if using Mistral)
| ##SERPAPI_API_KEY## | - | SerpAPI search key (required if using SerpAPI)
| ##GOOGLE_CSE_API_KEY## | - | Google Custom Search API key (required if using Google CSE)
| ##GOOGLE_CSE_ID## | - | Google Custom Search Engine ID (required if using Google CSE)
| ##FH_RUNNER_MAX_CONCURRENCY## | ##3## | Max parallel analysis jobs
| ##FH_ADMIN_KEY## | - | Admin endpoints authentication
| ##FH_INTERNAL_RUNNER_KEY## | - | Internal job execution authentication
| ~~##LLM_PROVIDER##~~ | ~~-~~ | **DEPRECATED** (use UCM ##pipeline.llmProvider##)

----

== Recent Updates ==

=== v2.6.38 (January 26, 2026) ===
* **Context Overlap Detection**: LLM-driven merge heuristics with temporal guidance clarification
* **Defensive Validation**: Context count warnings (5+ threshold) and claim assignment validation
* **UI Reliability Signals**: ##articleVerdictReliability## field added to signal when overall average is meaningful
* **Transparency**: De-emphasize unreliable averages, emphasize individual context verdicts in UI

----

**Last Updated**: February 3, 2026
**Document Status**: Living document - updated as architecture evolves

----

**Navigation:** [[Implementation>>FactHarbor.Product Development.Specification.Implementation.WebHome]] | Related: [[Architecture>>FactHarbor.Product Development.Specification.Architecture.WebHome]]
