# LLM-Only Contract & Env Fallback Removal Plan

**Status:** Draft for Review
**Owner:** FactHarbor Team
**Date:** 2026-02-01
**Scope:** apps/web analysis pipeline, UCM configuration, docs
**Environment:** POC (Proof of Concept)

---

## üèóÔ∏è PRINCIPAL ARCHITECT REVIEW

**Reviewed By:** Principal Architect
**Review Date:** 2026-02-01
**Environment Context:** POC (Proof of Concept)
**Overall Assessment:** APPROVED FOR POC with recommended production safeguards documented for future reference

### Executive Summary
This plan provides a solid strategic direction for enforcing LLM-only contracts and removing environment-based fallbacks. **For POC deployment**, the core implementation is sound and can proceed. The additional sections (12-15) on operational readiness, deployment strategy, and monitoring are documented as **future production requirements** but are not blockers for POC execution.

### Critical Gaps Identified

#### 1. **CRITICAL: Migration Safety & Rollback Strategy**
- ‚ùå **Missing:** In-flight analysis handling during migration
- ‚ùå **Missing:** Rollback procedure if v2 causes production issues
- ‚ùå **Missing:** Backward compatibility strategy for historical analyses
- ‚ö†Ô∏è **Risk:** Database migration without rollback = potential data loss/corruption

#### 2. **CRITICAL: Operational Resilience**
- ‚ùå **Missing:** LLM provider outage/degradation handling beyond "retry/backoff"
- ‚ùå **Missing:** Circuit breaker pattern for cascading LLM failures
- ‚ùå **Missing:** Service Level Objectives (SLOs) and error budgets
- ‚ùå **Missing:** Cost impact analysis (LLM-only vs hybrid approach)
- ‚ùå **Missing:** Rate limiting and quota exhaustion handling
- ‚ö†Ô∏è **Risk:** Strict LLM-only = single point of failure with no graceful degradation

#### 3. **CRITICAL: Deployment Strategy**
- ‚ùå **Missing:** Gradual rollout mechanism (feature flags, canary deployment)
- ‚ùå **Missing:** A/B testing strategy to validate LLM-only approach
- ‚ùå **Missing:** Deployment phases with go/no-go criteria
- ‚ö†Ô∏è **Risk:** Big-bang deployment could impact all users simultaneously

#### 4. **HIGH: Testing & Validation**
- ‚ö†Ô∏è **Insufficient:** Testing strategy too limited (only basic verification)
- ‚ùå **Missing:** Integration testing with real LLM providers
- ‚ùå **Missing:** Performance/latency testing (LLM-only may be slower)
- ‚ùå **Missing:** Chaos engineering tests (LLM failures, timeouts, rate limits)
- ‚ùå **Missing:** Regression test suite for all analysis types

#### 5. **HIGH: Schema & Configuration Details**
- ‚ùå **Missing:** Actual `pipeline.v2` schema definition
- ‚ùå **Missing:** Example configurations showing before/after
- ‚ùå **Missing:** Config validation rules and JSON schema
- ‚ùå **Missing:** Migration mapping table (v1 field ‚Üí v2 field)

#### 6. **MEDIUM: Error Handling Taxonomy**
- ‚ö†Ô∏è **Insufficient:** "Strict failure" is too broad
- ‚ùå **Missing:** Error classification (transient vs permanent, retryable vs fatal)
- ‚ùå **Missing:** User-facing error messages and guidance
- ‚ùå **Missing:** Error logging and debugging strategy

#### 7. **MEDIUM: Monitoring & Observability**
- ‚ùå **Missing:** Metrics to track (LLM call success rate, latency, cost)
- ‚ùå **Missing:** Alerting thresholds and runbooks
- ‚ùå **Missing:** Dashboard requirements
- ‚ùå **Missing:** Distributed tracing for LLM call chains

#### 8. **MEDIUM: Dependency Analysis**
- ‚ùå **Missing:** Complete inventory of affected services/modules
- ‚ùå **Missing:** API contract changes and versioning strategy
- ‚ùå **Missing:** Impact on downstream consumers
- ‚ùå **Missing:** Third-party integration impacts

### Recommendations

#### **MUST HAVE (Before Phase B):**

1. **Add Section 6.5: Migration Safety**
   - Define in-flight analysis handling (pause? complete with v1? force-migrate?)
   - Document rollback procedure with database backup strategy
   - Create migration dry-run tooling for validation
   - Define success criteria for migration completion

2. **Add Section 12: Operational Readiness**
   - Define SLOs (e.g., "99.5% of analyses complete successfully")
   - Document circuit breaker implementation (e.g., 50% failure rate over 5min ‚Üí alert)
   - Define graceful degradation policy (even if it's "fail fast with clear messaging")
   - Create cost model comparing LLM-only vs previous hybrid approach
   - Document rate limiting strategy per LLM provider

3. **Add Section 13: Deployment Strategy**
   - Phase D should include feature flag: `ENABLE_PIPELINE_V2` (env var acceptable for deployment control)
   - Define canary deployment: 5% ‚Üí 25% ‚Üí 50% ‚Üí 100% with 24hr soak times
   - Document rollback triggers (e.g., error rate >5%, latency p95 >10s)

4. **Expand Section 8: Verification/Test Plan**
   - Add integration tests with mock LLM failures/timeouts/rate limits
   - Add performance benchmarks (p50, p95, p99 latencies)
   - Add regression test suite covering all analysis input types
   - Add load testing scenarios

5. **Add Section 14: Pipeline v2 Schema Definition**
   - Provide complete TypeScript interface
   - Show example JSON configurations
   - Document all removed fields and their replacements
   - Provide migration mapping table

#### **SHOULD HAVE (Before Phase D):**

6. **Enhance Section 9: Risks & Mitigations**
   - Add row: "Config migration errors" ‚Üí "Automated validation + rollback"
   - Add row: "Incomplete heuristic migration" ‚Üí "Audit all text analysis code paths"
   - Add row: "Performance degradation" ‚Üí "Load testing + latency SLOs"

7. **Add Section 15: Monitoring & Observability**
   - Define metrics: `llm_analysis_success_rate`, `llm_analysis_latency_ms`, `llm_cost_per_analysis`
   - Define alerts with thresholds and severity levels
   - Create runbook templates for common failure scenarios

8. **Enhance Phase C: Heuristic Migration**
   - Add discovery process: grep for all hardcoded strings, pattern matching, etc.
   - Define lexicon config format/schema
   - Provide migration examples
   - Create validation tool to ensure no hardcoded logic remains

#### **NICE TO HAVE:**

9. **Add Section 16: Success Metrics**
   - Target: 0 `FH_LLM_*` references (already in DoD)
   - Target: Analysis latency p95 < Xms (define X)
   - Target: LLM call success rate > 99.5%
   - Target: Cost per analysis < $Y (define Y)

10. **Add Appendix A: Code Inventory**
    - List all files to be modified/deleted
    - Dependency graph showing affected modules
    - LOC impact estimate

11. **Add Appendix B: API Contract Changes**
    - Document any breaking changes to REST/GraphQL APIs
    - Versioning strategy for backward compatibility

### Quality Concerns

#### **Architecture:**
‚úÖ **Strong:** Clear separation of concerns (UCM as single source of truth)
‚úÖ **Strong:** Eliminates non-deterministic behavior
‚ö†Ô∏è **Concern:** No fallback creates single point of failure (acceptable if mitigated with monitoring/alerting)

#### **Implementation:**
‚úÖ **Strong:** Phased approach allows incremental validation
‚ö†Ô∏è **Concern:** Phase dependencies unclear (can C run parallel to B?)
‚ö†Ô∏è **Concern:** No code inventory = unknown scope

#### **Testing:**
‚ùå **Weak:** Testing strategy insufficient for production readiness
‚ö†Ô∏è **Concern:** No mention of test coverage requirements

#### **Documentation:**
‚úÖ **Strong:** Comprehensive doc update list
‚ö†Ô∏è **Concern:** Missing API docs, runbooks, troubleshooting guides

### Blocking Issues for POC vs Production

**FOR POC IMPLEMENTATION (Required Now):**
2. ‚ö†Ô∏è **Pipeline v2 schema definition** (Section 14) - Define basic schema structure
5. ‚ö†Ô∏è **Basic test plan** (Section 8) - Unit tests + basic integration tests

**DEFERRED TO PRODUCTION (Future Requirements):**
1. üìã **Migration rollback strategy** (Section 12) - Not needed for POC; document for production
3. üìã **Operational resilience plan** (Section 12: SLOs, circuit breakers, cost model) - Not needed for POC
4. üìã **Deployment strategy with gradual rollout** (Section 13) - Not needed for POC

> **POC Scope:** Items 1, 3, 4 are documented as best practices for production but are **NOT BLOCKERS** for POC deployment. Sections 12-15 serve as reference architecture for future production migration.

### Approval Recommendation

**STATUS: ‚úÖ APPROVED FOR POC IMPLEMENTATION**

This plan may proceed to POC implementation immediately. The two required items (schema definition and basic testing) can be completed during Phase B-D implementation. Sections 12-15 are documented for future production use and serve as valuable reference architecture but do not block POC deployment.

### Next Steps for POC

1. **Immediate:** Begin Phase B (Code Cleanup) - remove FH_LLM_* flags and fallback logic
2. **During Phase C-D:** Define pipeline.v2 schema (simplified for POC)
3. **During Phase D:** Basic testing (unit tests + smoke tests)
4. **Phase E:** Update documentation

**Future Production Migration:**
- When promoting POC ‚Üí Production, revisit Sections 12-15 for operational safeguards
- Implement gradual rollout, monitoring, and resilience patterns at that time

---

---

## 1) Background & Motivation

Unified Configuration Management (UCM) is marked ‚Äúcomplete,‚Äù yet analysis behavior is still governed by:

- `FH_LLM_*` environment flags in code.
- Hybrid/heuristic fallback paths for text analysis.
- Env-based overrides that can replace DB configs at runtime.

This creates **non-deterministic analysis behavior** (varies by env), **contradicts UCM as the single source of truth**, and violates the ‚Äúgeneric-by-design‚Äù principle by keeping analysis-affecting logic in code. This plan enforces an **LLM-only contract** for text analysis and eliminates analysis-affecting env toggles and fallback behavior.

---

## 2) Goals

1) **LLM-only contract** for text analysis: no hybrid/heuristic fallback.  
2) **Remove all `FH_LLM_*` env controls** and any code paths that depend on them.  
3) **Remove analysis-affecting env overrides** (e.g., config overrides that change pipeline behavior).  
4) **Move remaining heuristic logic to UCM** (lexicons/configs/prompts), ensuring analysis logic is configuration-driven.  
5) **Ensure DB defaults + config seeding are updated**, so new analyses use the up-to-date defaults.

---

## 3) Non-Goals

- No changes to infra-only env vars (API keys, URLs, runner/admin keys).  
- No change to evidence extraction rules unless they are explicitly heuristic/hardcoded in code.  
- No changes to ‚ÄúContext vs evidenceScope‚Äù terminology.

---

## 4) Decisions (Contract)

### 4.1 LLM-only Text Analysis

- **All text-analysis points** (input classification, evidence quality, context similarity, verdict validation) are **LLM-only**.
- **Strict failure:** if any text-analysis LLM call fails, the job fails (no fallback, no best-effort bypass).

> **üèóÔ∏è ARCHITECT NOTE:**
> - **CRITICAL:** Define error taxonomy. Not all LLM failures should fail the job equally:
>   - **Transient errors** (network timeout, 429 rate limit): Retry with exponential backoff
>   - **Quota errors** (monthly limit exceeded): Fail with clear user guidance
>   - **Invalid response** (malformed JSON, hallucination): Retry up to N times, then fail
>   - **Provider outage** (500 errors): Circuit breaker after threshold, fail gracefully
> - **REQUIRED:** Add `maxRetries`, `retryBackoffMs`, `circuitBreakerThreshold` to config
> - **REQUIRED:** Define user-facing error messages for each failure class
> - **CONSIDER:** Even with strict policy, differentiate between "user can retry" vs "systemic failure"

### 4.2 Env Overrides

- **No analysis-affecting env overrides**: remove `FH_CONFIG_ENV_OVERRIDES`, `PIPELINE_ENV_MAP`, and all `FH_LLM_*` flags.
- Env vars remain only for infra/secrets; UCM (DB) is the sole source of analysis behavior.

### 4.3 ‚ÄúMove Heuristics to UCM‚Äù

- Any remaining **analysis-affecting text/phrase heuristics** must be moved into **UCM-managed lexicons/configs/prompts**.
- Avoid domain-specific or test-case strings in code. Keep code generic; store rules/wording in UCM.

---

## 5) Deliverables

### 5.1 Code Changes

- Remove `FH_LLM_*` reads and conditional logic across the pipeline.
- Remove hybrid/heuristic fallback services in text analysis.
- Remove `FH_CONFIG_ENV_OVERRIDES` and env override mapping in `config-loader`.

### 5.2 Config & DB Changes

- Introduce **`pipeline.v2`** (or equivalent) without LLM feature-flag booleans and fallback controls.
- Migration: **convert pipeline.v1 ‚Üí pipeline.v2** in DB and set it active.
- Update default configs in code and ensure **seed scripts** populate the new defaults.
- Ensure new analyses **use the updated defaults** immediately after migration/reseed.

### 5.3 Documentation Updates

Remove or update mentions of:

- `FH_LLM_*` flags and fallback behavior
- Hybrid/heuristic fallbacks
- Env-based analysis overrides

Add references to this plan and document the **LLM-only contract**.

---

## 6) Implementation Plan (Phased)

### Phase A ‚Äî New Plan Doc (this file)

- Provide a review-ready plan for LLM-only contract enforcement and env fallback removal.

### Phase B ‚Äî Code Cleanup

1) **Remove env override plumbing**
   - `config-loader.ts`: delete `FH_CONFIG_ENV_OVERRIDES` and env-to-config maps.
   - Ensure DB config + built-in defaults remain the only sources.

2) **Remove `FH_LLM_*` usage and fallback paths**
   - `text-analysis-service.ts`: always LLM; remove hybrid/heuristic logic.
   - Remove `text-analysis-hybrid.ts` usage; delete file if unused.
   - Remove `text-analysis-heuristic.ts` from runtime path (retain only if needed for tests, clearly marked).
   - Remove `FH_LLM_TIERING` and related env-based toggles from tiering logic.

### Phase C ‚Äî Move Remaining Heuristics to UCM

- Identify any remaining **hardcoded text/phrase** logic in analysis code.
- Move those lists into UCM lexicon configs or prompt templates.
- Ensure ‚Äúgeneric-by-design‚Äù compliance (no test-case terms in code or prompts).

### Phase D ‚Äî Config/DB Migration & Seeding

- Create `pipeline.v2` schema + migration path.
- Update default config object(s) in code for the new schema.
- Ensure seed scripts (e.g., default config seeding + prompt seeding) write the **new defaults** and activate them.
- Provide one-time migration script or admin action to upgrade existing DBs.

> **üèóÔ∏è ARCHITECT NOTE:**
> - **REQUIRED:** Create Phase D.1 - Pre-Migration Validation:
>   - Snapshot current DB state
>   - Run migration in dry-run mode
>   - Validate all v1 configs can be converted to v2
>   - Identify orphaned/invalid configs
> - **REQUIRED:** Create Phase D.2 - In-Flight Analysis Handling:
>   - **Option A:** Pause new analyses, drain queue, then migrate
>   - **Option B:** Allow in-flight to complete with v1, new use v2
>   - **Option C:** Force-migrate in-flight (risky, not recommended)
>   - **DECISION NEEDED:** Which approach? Document rationale.
> - **REQUIRED:** Create Phase D.3 - Rollback Procedure:
>   - DB backup before migration
>   - Rollback SQL script tested in staging
>   - Code can run both v1 and v2 during migration window
>   - Feature flag to switch active version
> - **REQUIRED:** Create Phase D.4 - Gradual Activation:
>   - Add `PIPELINE_V2_ENABLED` feature flag (boolean)
>   - Add `PIPELINE_V2_ROLLOUT_PCT` (0-100, for canary)
>   - Monitor error rates during rollout
>   - Automated rollback if error rate >5%

### Phase E ‚Äî Documentation Updates

Update the following docs to reflect **UCM-only** controls and remove legacy env flags:

- `Docs/STATUS/Current_Status.md`
- `Docs/USER_GUIDES/LLM_Configuration.md`
- `Docs/USER_GUIDES/Promptfoo_Testing.md`
- `Docs/ARCHITECTURE/Overview.md`
- `Docs/ARCHITECTURE/Pipeline_TriplePath_Architecture.md`
- `Docs/ARCHIVE/REVIEWS/LLM_Text_Analysis_Pipeline_Deep_Analysis.md`
- `Docs/ARCHIVE/REVIEWS/Unified_Config_Management_Proposal.md`
- `Docs/ARCHIVE/REVIEWS/Unified_Configuration_Management_Plan.md`
- Any other doc files containing `FH_LLM_*`

---

## 7) Migration Strategy

### 7.1 Config Schema Evolution

**Old:** `pipeline.v1` (contains LLM feature flags and fallback knobs)
**New:** `pipeline.v2` (LLM-only contract, no fallback or env flags)

> **üèóÔ∏è ARCHITECT NOTE:**
> - **MISSING:** Actual schema definitions. Add Section 14 (see review above) with:
>   - TypeScript interfaces for both v1 and v2
>   - JSON schema for validation
>   - Example configs showing migration
>   - Field mapping table (v1 ‚Üí v2)
>   - Which v1 fields are removed vs renamed vs merged

### 7.2 DB Upgrade

1) Add migration that converts existing `pipeline.v1` configs to `pipeline.v2`.
2) Update active config pointers to `pipeline.v2`.
3) Reseed defaults if missing or stale.

> **üèóÔ∏è ARCHITECT NOTE:**
> - **INSUFFICIENT:** This is too high-level for safe production migration.
> - **REQUIRED ADDITIONS:**
>   - **Migration SQL script** with:
>     - Transaction wrapping (all-or-nothing)
>     - Constraint validation
>     - Foreign key preservation
>     - Index creation for v2 queries
>   - **Data validation queries** to run before/after:
>     - Count of v1 configs before migration
>     - Count of v2 configs after migration (should match)
>     - Validation that no data loss occurred
>   - **Rollback script:**
>     - Tested in staging environment
>     - Can revert v2 ‚Üí v1 if needed within 24hr window
>   - **Migration checklist:**
>     - [ ] Backup database
>     - [ ] Run dry-run migration in staging
>     - [ ] Validate data integrity post-migration
>     - [ ] Run smoke tests with v2 configs
>     - [ ] Enable v2 for 5% of traffic
>     - [ ] Monitor for 24hrs, check error rates
>     - [ ] Gradual rollout to 100%
>     - [ ] Archive v1 configs (don't delete immediately)

---

## 8) Verification / Test Plan

- `rg "process\.env\.FH_LLM_" apps/web/src` returns **0**.
- `rg "FH_LLM_" Docs` returns **0** (or only in explicitly-marked historical docs).
- Run promptfoo text-analysis suite and verify configs map to new schema.
- Run one analysis and confirm:
  - job config snapshot uses `pipeline.v2`.
  - text analysis failures **fail the job** (strict policy).

> **üèóÔ∏è ARCHITECT NOTE:**
> - **INSUFFICIENT:** Testing strategy is too minimal for production system.
> - **REQUIRED ADDITIONS:**
>
> #### 8.1 Unit Testing
> - [ ] All config-loader tests pass with v2 schema
> - [ ] All text-analysis-service tests pass without fallback paths
> - [ ] Migration function tests (v1 ‚Üí v2 conversion)
> - [ ] Test coverage ‚â•90% for modified code paths
>
> #### 8.2 Integration Testing
> - [ ] Mock LLM provider returns valid responses ‚Üí analysis succeeds
> - [ ] Mock LLM provider returns 429 rate limit ‚Üí retry ‚Üí eventual success
> - [ ] Mock LLM provider returns 500 error ‚Üí circuit breaker ‚Üí fail gracefully
> - [ ] Mock LLM provider timeout ‚Üí retry with backoff ‚Üí eventual failure
> - [ ] Mock LLM provider returns invalid JSON ‚Üí retry ‚Üí fail with clear error
> - [ ] Test ALL analysis types: input classification, evidence quality, context similarity, verdict
>
> #### 8.3 Performance Testing
> - [ ] Baseline latency metrics with v1 (hybrid approach)
> - [ ] Compare v2 latency (LLM-only): p50, p95, p99
> - [ ] Load test: 100 concurrent analyses, measure throughput
> - [ ] Stress test: LLM provider rate limits, verify graceful degradation
> - [ ] Cost analysis: $/analysis for v1 vs v2
>
> #### 8.4 Regression Testing
> - [ ] Run analysis on 50+ historical test cases
> - [ ] Compare v1 vs v2 results (should be equivalent or better)
> - [ ] Verify no feature regressions
>
> #### 8.5 Chaos Engineering
> - [ ] Kill LLM provider connection mid-analysis ‚Üí verify failure handling
> - [ ] Inject random LLM latency (0-30s) ‚Üí verify timeout handling
> - [ ] Exhaust rate limits ‚Üí verify error messaging
> - [ ] Database connection loss during config load ‚Üí verify error handling
>
> #### 8.6 Acceptance Criteria
> - [ ] All tests pass in CI/CD pipeline
> - [ ] Manual QA sign-off on staging environment
> - [ ] Performance benchmarks within acceptable range (define "acceptable")
> - [ ] Security review completed (no exposed secrets, proper error handling)

---

## 9) Risks & Mitigations

| Risk | Impact | Mitigation | Owner | Status |
|------|--------|-----------|--------|--------|
| LLM outage causes failed jobs | **CRITICAL** | Add retry/backoff, circuit breaker, SLO monitoring, clear error messages | TBD | Planned |
| Migration leaves mixed configs | High | Feature flag for v2 activation, gradual rollout, automated validation | TBD | Planned |
| Database migration failure | **CRITICAL** | Transaction-wrapped migration, tested rollback script, full backup | TBD | Planned |
| In-flight analyses corrupted | High | Pause queue during migration OR dual-version support | TBD | **DECISION NEEDED** |
| Performance degradation (latency) | High | Load testing, p95 latency SLO, performance benchmarks | TBD | Planned |
| Cost increase from LLM-only | Medium | Cost modeling, usage monitoring, budget alerts | TBD | Planned |
| Incomplete heuristic migration | Medium | Code audit, grep for hardcoded strings, validation tool | TBD | Planned |
| Config validation errors | Medium | JSON schema validation, automated config tests | TBD | Planned |
| Docs drift | Medium | Use single reference doc (this plan) + automated link checker | TBD | Planned |
| Rollback not tested | **CRITICAL** | Test rollback in staging, maintain v1 code for 30d post-launch | TBD | **BLOCKER** |
| Unknown dependencies broken | High | Dependency mapping, integration tests, staged rollout | TBD | Planned |
| User-facing errors unclear | Medium | Error message UX review, user testing, help docs | TBD | Planned |

> **üèóÔ∏è ARCHITECT NOTE:**
> - **CRITICAL RISKS ADDED:** Database migration failure, rollback untested
> - **REQUIRED:** Assign owners to each risk before Phase B begins
> - **REQUIRED:** Address all CRITICAL risks before production deployment
> - **REQUIRED:** Create mitigation tracking dashboard/checklist

---

## 10) Open Questions

> **üèóÔ∏è ARCHITECT NOTE:** The following questions MUST be answered before implementation:

### 10.1 Migration Approach
- **Q1:** How do we handle in-flight analyses during DB migration?
  - **Options:** A) Pause queue, B) Dual-version support, C) Force-migrate
  - **Decision needed by:** Before Phase D planning
  - **Impact:** Affects migration script design and downtime requirements

### 10.2 Operational Thresholds
- **Q2:** What is the acceptable LLM call failure rate?
  - **Current answer needed:** Define SLO (e.g., 99.5% success rate)
  - **Impact:** Determines circuit breaker thresholds and alerting

- **Q3:** What is the acceptable latency for LLM-only analysis?
  - **Current answer needed:** Define p95 latency target (e.g., <5s)
  - **Impact:** Affects user experience and timeout configurations

- **Q4:** What is the cost budget per analysis?
  - **Current answer needed:** Define max cost (e.g., $0.10 per analysis)
  - **Impact:** May require prompt optimization or provider negotiation

### 10.3 Schema Design
- **Q5:** What specific fields are removed from v1 ‚Üí v2?
  - **Required:** Complete field mapping table
  - **Impact:** Affects migration script and validation logic

- **Q6:** Are there any v1 configs that cannot be migrated to v2?
  - **Required:** Identify edge cases and document manual migration steps
  - **Impact:** May require one-off migration support

### 10.4 Deployment Strategy
- **Q7:** What are the rollback triggers?
  - **Proposed:** Error rate >5%, latency p95 >10s, cost >2x baseline
  - **Decision needed:** Confirm thresholds with stakeholders

- **Q8:** How long should we maintain v1 code post-migration?
  - **Proposed:** 30 days post-100% rollout
  - **Decision needed:** Confirm with team

### 10.5 Testing Coverage
- **Q9:** What is the minimum required test coverage for modified code?
  - **Proposed:** ‚â•90% for critical paths, ‚â•80% overall
  - **Decision needed:** Confirm with QA team

### 10.6 Error Handling
- **Q10:** Should we implement a "fallback to manual review" mode?
  - **Context:** If LLM fails, flag for human review instead of blocking?
  - **Impact:** Could reduce strict failure impact but adds complexity
  - **Decision needed:** Define scope and implementation approach

---

## 12) Operational Readiness

> **üèóÔ∏è ARCHITECT NOTE:** This section is **DEFERRED FOR POC** - Required for production deployment only. Documented here as reference architecture for future production migration.

### 12.1 Service Level Objectives (SLOs)

**Proposed SLOs** (to be confirmed with stakeholders):

- **Availability:** 99.5% of analysis jobs complete successfully (excluding user errors)
- **Latency:**
  - p50 < 3 seconds per LLM call
  - p95 < 8 seconds per LLM call
  - p99 < 15 seconds per LLM call
- **Error Budget:** 0.5% monthly (‚âà216 minutes downtime or equivalent failed requests)

**Error Budget Policy:**
- If error budget exhausted: halt feature releases, focus on reliability
- If 50% consumed mid-month: conduct incident review

### 12.2 Circuit Breaker Implementation

```typescript
// Proposed configuration structure
{
  "circuitBreaker": {
    "failureThreshold": 0.5,        // 50% failure rate triggers open
    "failureWindow": "5m",            // Measure failures over 5 minutes
    "samplingWindow": 20,             // Minimum 20 requests before evaluation
    "openDuration": "30s",            // Stay open for 30s before half-open
    "halfOpenMaxCalls": 3,            // Allow 3 test calls in half-open
    "successThreshold": 0.8           // 80% success to close circuit
  }
}
```

**Behavior:**
- **CLOSED:** Normal operation, all LLM calls proceed
- **OPEN:** Fail fast without LLM calls, return clear error message
- **HALF-OPEN:** Test with limited calls, close if successful

### 12.3 Retry & Backoff Strategy

```typescript
{
  "retry": {
    "maxAttempts": 3,
    "initialDelayMs": 1000,
    "maxDelayMs": 10000,
    "backoffMultiplier": 2,
    "retryableErrors": ["TIMEOUT", "RATE_LIMIT", "SERVER_ERROR_5XX"],
    "nonRetryableErrors": ["INVALID_API_KEY", "MALFORMED_REQUEST", "QUOTA_EXCEEDED"]
  }
}
```

**Error Classification:**
- **Transient (retry):** Network timeout, 429 rate limit, 500/502/503 errors
- **Permanent (fail):** 401 auth, 400 bad request, 403 forbidden
- **Quota (fail with guidance):** 429 with quota message, monthly limit exceeded

### 12.4 Cost Management

**Cost Monitoring:**
- Track cost per analysis (LLM tokens √ó provider rate)
- Daily/weekly/monthly spending dashboards
- Budget alerts at 70%, 90%, 100% of monthly allocation

**Cost Optimization:**
- Prompt optimization to reduce token usage
- Caching for repeated analyses (if applicable)
- Rate limiting to prevent runaway costs

**Proposed Budget:**
- Define max cost per analysis: $0.XX (to be determined based on business model)
- Monthly budget cap with alerts

### 12.5 Rate Limiting & Quota Management

**Provider Rate Limits:**
- Document each LLM provider's rate limits (requests/min, tokens/min)
- Implement client-side rate limiting to stay within limits
- Queue system for burst traffic

**Quota Exhaustion:**
- Monitor quota usage (daily/monthly limits)
- Alert at 80% quota usage
- Fail gracefully with clear user message when quota exceeded

---

## 13) Deployment Strategy

> **üèóÔ∏è ARCHITECT NOTE:** This section is **DEFERRED FOR POC** - Gradual rollout required for production only. POC can use direct deployment.

### 13.1 Feature Flag

**Implementation:**
```typescript
// Environment-level deployment control (acceptable use case for env var)
PIPELINE_V2_ENABLED=false          // Master kill switch
PIPELINE_V2_ROLLOUT_PERCENT=0      // Gradual rollout 0-100
```

**Flag Logic:**
- If `PIPELINE_V2_ENABLED=false`: Use v1 for all analyses
- If `PIPELINE_V2_ENABLED=true`: Use `ROLLOUT_PERCENT` to determine v1 vs v2
- Rollout based on consistent hash of analysis ID (sticky sessions)

### 13.2 Deployment Phases

| Phase | Rollout % | Duration | Success Criteria | Rollback Trigger |
|-------|-----------|----------|------------------|------------------|
| **0. Staging** | 100% | 1 week | All tests pass, manual QA approved | N/A |
| **1. Dark Launch** | 0% (v2 runs but results discarded) | 3 days | Logs show v2 runs without errors | Error rate >1% |
| **2. Canary** | 5% | 2 days | Error rate <1%, latency p95 <8s | Error rate >2% |
| **3. Ramp Up** | 25% | 2 days | Error rate <0.5%, no customer complaints | Error rate >1% |
| **4. Majority** | 50% | 3 days | Cost within budget, SLOs met | SLO violation |
| **5. Full Rollout** | 100% | Ongoing | All metrics healthy | Critical incident |

### 13.3 Rollback Procedure

**Automated Rollback Triggers:**
- Error rate >5% over 10-minute window
- Latency p95 >15s over 10-minute window
- Cost >3x baseline

**Manual Rollback Steps:**
1. Set `PIPELINE_V2_ENABLED=false`
2. Restart application servers
3. Monitor for 30 minutes to ensure v1 recovery
4. Conduct incident retrospective

**Rollback Testing:**
- Must be tested in staging before production deployment
- Document rollback time (target: <5 minutes)

### 13.4 Go/No-Go Checklist

**Before Each Phase:**
- [ ] Previous phase success criteria met
- [ ] Monitoring dashboards show healthy metrics
- [ ] No open P0/P1 incidents
- [ ] Team available for monitoring (no on-call rotations)
- [ ] Rollback procedure tested and ready

---

## 14) Pipeline v2 Schema Definition

> **üèóÔ∏è ARCHITECT NOTE:** **REQUIRED FOR POC** - Simplified schema acceptable for POC; can be refined during implementation.

### 14.1 TypeScript Interface (To Be Implemented)

```typescript
// DRAFT - To be refined during Phase D planning

interface PipelineConfigV2 {
  version: "2.0";

  // LLM-only configuration (no fallback options)
  textAnalysis: {
    provider: "openai" | "anthropic" | "custom";
    model: string;
    temperature: number;
    maxTokens: number;

    // Retry and resilience (moved from env to config)
    retry: {
      maxAttempts: number;
      initialDelayMs: number;
      maxDelayMs: number;
      backoffMultiplier: number;
    };

    // Circuit breaker settings
    circuitBreaker: {
      enabled: boolean;
      failureThreshold: number;
      failureWindow: string;
      samplingWindow: number;
      openDuration: string;
    };

    // Timeout settings
    timeouts: {
      inputClassification: number;
      evidenceQuality: number;
      contextSimilarity: number;
      verdictValidation: number;
    };
  };

  // UCM-managed lexicons (no hardcoded heuristics)
  lexicons: {
    inputTypes: string[];           // Moved from code
    evidenceQualifiers: string[];   // Moved from code
    contextKeywords: string[];      // Moved from code
  };

  // Prompt configuration
  prompts: {
    inputClassificationPrompt: string;
    evidenceQualityPrompt: string;
    contextSimilarityPrompt: string;
    verdictValidationPrompt: string;
  };

  // Analysis pipeline settings
  pipeline: {
    strictMode: boolean;            // Always true for v2
    enableCaching: boolean;
    maxConcurrentLLMCalls: number;
  };
}

// V1 Schema (for reference during migration)
interface PipelineConfigV1 {
  version: "1.0";

  // REMOVED in v2: Feature flags
  features: {
    enableLLMClassification?: boolean;     // Always true in v2
    enableLLMEvidenceQuality?: boolean;    // Always true in v2
    enableHybridFallback?: boolean;        // Removed in v2
  };

  // REMOVED in v2: Env override support
  envOverrides?: Record<string, any>;      // Removed in v2

  // Migrated to v2.textAnalysis
  llmConfig: {
    provider: string;
    model: string;
    // ... other settings
  };
}
```

### 14.2 Migration Mapping

| V1 Field | V2 Field | Transformation |
|----------|----------|----------------|
| `features.enableLLMClassification` | **REMOVED** | Always true in v2 |
| `features.enableHybridFallback` | **REMOVED** | Not supported in v2 |
| `envOverrides` | **REMOVED** | Not supported in v2 |
| `llmConfig.provider` | `textAnalysis.provider` | Direct copy |
| `llmConfig.model` | `textAnalysis.model` | Direct copy |
| `llmConfig.temperature` | `textAnalysis.temperature` | Direct copy with validation |
| **NEW** | `textAnalysis.retry` | Default values from code config |
| **NEW** | `textAnalysis.circuitBreaker` | Default values from code config |
| **NEW** | `lexicons.*` | Extract from code heuristics |
| **NEW** | `prompts.*` | Extract from code or set defaults |

### 14.3 Example Configuration

**V1 Example:**
```json
{
  "version": "1.0",
  "features": {
    "enableLLMClassification": true,
    "enableHybridFallback": true
  },
  "llmConfig": {
    "provider": "openai",
    "model": "gpt-4",
    "temperature": 0.7
  },
  "envOverrides": {
    "FH_LLM_CLASSIFICATION": "false"
  }
}
```

**V2 Example (after migration):**
```json
{
  "version": "2.0",
  "textAnalysis": {
    "provider": "openai",
    "model": "gpt-4",
    "temperature": 0.7,
    "retry": {
      "maxAttempts": 3,
      "initialDelayMs": 1000,
      "maxDelayMs": 10000,
      "backoffMultiplier": 2
    },
    "circuitBreaker": {
      "enabled": true,
      "failureThreshold": 0.5,
      "failureWindow": "5m",
      "samplingWindow": 20,
      "openDuration": "30s"
    }
  },
  "lexicons": {
    "inputTypes": ["claim", "evidence", "context"],
    "evidenceQualifiers": ["strong", "moderate", "weak"],
    "contextKeywords": ["relevant", "related", "background"]
  },
  "prompts": {
    "inputClassificationPrompt": "Classify the following input...",
    "evidenceQualityPrompt": "Evaluate the quality of this evidence...",
    "contextSimilarityPrompt": "Determine similarity between...",
    "verdictValidationPrompt": "Validate the verdict..."
  },
  "pipeline": {
    "strictMode": true,
    "enableCaching": false,
    "maxConcurrentLLMCalls": 10
  }
}
```

### 14.4 Validation Rules

- `version` must equal "2.0"
- `textAnalysis.provider` must be one of allowed providers
- `textAnalysis.retry.maxAttempts` must be 1-10
- `textAnalysis.temperature` must be 0.0-1.0
- All prompt fields must be non-empty strings
- `pipeline.strictMode` must always be `true` in v2

---

## 15) Monitoring & Observability

> **üèóÔ∏è ARCHITECT NOTE:** This section is **DEFERRED FOR POC** - Basic logging acceptable for POC; comprehensive monitoring required for production only.

### 15.1 Metrics to Track

**LLM Performance Metrics:**
```
# Success rates
llm_analysis_success_rate{type="input_classification"}
llm_analysis_success_rate{type="evidence_quality"}
llm_analysis_success_rate{type="context_similarity"}
llm_analysis_success_rate{type="verdict_validation"}

# Latency (milliseconds)
llm_analysis_latency_ms{type="*", percentile="p50|p95|p99"}

# Cost (USD)
llm_analysis_cost_usd{provider="openai|anthropic"}
llm_total_cost_daily_usd
llm_total_cost_monthly_usd

# Errors
llm_analysis_errors_total{type="*", error_class="transient|permanent|quota"}
llm_circuit_breaker_state{state="open|closed|half_open"}
llm_retry_attempts_total{type="*"}

# Throughput
llm_analysis_requests_per_minute
llm_analysis_queue_depth
```

**System Metrics:**
```
# Config version usage
pipeline_config_version{version="1.0|2.0"}

# Job outcomes
analysis_job_status{status="success|failure|timeout"}
analysis_job_duration_ms{percentile="p50|p95|p99"}
```

### 15.2 Dashboards

**Dashboard 1: LLM Health**
- Success rate per analysis type (last 1h, 24h, 7d)
- Latency percentiles (p50, p95, p99)
- Circuit breaker state timeline
- Error rate by error class

**Dashboard 2: Cost Monitoring**
- Cost per analysis (current vs baseline)
- Daily/monthly cost trends
- Cost by LLM provider
- Budget utilization %

**Dashboard 3: Migration Progress**
- % of analyses using v1 vs v2
- Error rates compared (v1 vs v2)
- Latency compared (v1 vs v2)
- Rollout percentage over time

### 15.3 Alerts

| Alert | Condition | Severity | Action |
|-------|-----------|----------|--------|
| LLM Success Rate Low | <95% over 10min | **CRITICAL** | Page on-call, check circuit breaker |
| LLM Latency High | p95 >15s over 10min | **HIGH** | Investigate provider status |
| Circuit Breaker Open | State=open for >5min | **HIGH** | Check LLM provider, consider rollback |
| Cost Budget Alert | >90% monthly budget | **MEDIUM** | Review usage, optimize prompts |
| Migration Error Spike | v2 errors >2x v1 errors | **CRITICAL** | Halt rollout, investigate |
| Config Migration Failed | Migration job failed | **CRITICAL** | Rollback, investigate |

### 15.4 Runbooks

**Runbook 1: LLM Provider Outage**
1. Verify circuit breaker is open (preventing cascading failures)
2. Check provider status page
3. Communicate ETA to users
4. If outage >1hr, consider rollback to v1 (if within 30d window)

**Runbook 2: High Error Rate**
1. Check dashboard for error classification (transient vs permanent)
2. If transient (timeouts, rate limits): Verify retry/backoff working
3. If permanent (auth, malformed): Investigate code or config changes
4. If quota exceeded: Purchase additional quota or wait for reset

**Runbook 3: Migration Rollback**
1. Set `PIPELINE_V2_ENABLED=false`
2. Restart application servers
3. Verify v1 traffic recovery
4. Check database for migration state
5. If needed, run rollback SQL script
6. Conduct incident retrospective

### 15.5 Logging Strategy

**Log Levels:**
- **ERROR:** All LLM call failures, circuit breaker opens, config load errors
- **WARN:** Retries, approaching quota limits, degraded performance
- **INFO:** LLM calls, config loads, migration events
- **DEBUG:** Retry attempts, circuit breaker state changes, detailed LLM responses

**Structured Logging:**
```json
{
  "timestamp": "2026-02-01T12:34:56Z",
  "level": "ERROR",
  "service": "text-analysis",
  "analysisId": "abc123",
  "analysisType": "input_classification",
  "provider": "openai",
  "model": "gpt-4",
  "errorClass": "transient",
  "errorCode": "TIMEOUT",
  "retryAttempt": 2,
  "message": "LLM call timeout after 10s"
}
```

---

## 11) Definition of Done

### 11.1 Code Completion
- [ ] All `FH_LLM_*` env flags removed from code (verified: `rg "FH_LLM_" apps/web/src` returns 0)
- [ ] No hybrid/heuristic fallback in text analysis (verified: deleted files + grep checks)
- [ ] All hardcoded heuristics moved to UCM lexicon configs
- [ ] Code review approved by 2+ senior engineers
- [ ] Test coverage ‚â•90% for modified code paths

### 11.2 Configuration & Database
- [ ] `pipeline.v2` schema defined and documented
- [ ] UCM is the sole source of analysis behavior (no env overrides)
- [ ] DB migration script created and tested in staging
- [ ] DB rollback script created and tested in staging
- [ ] DB defaults and seed scripts updated to new config schema
- [ ] All v1 configs successfully migrated to v2 in staging

### 11.3 Testing
- [ ] All unit tests passing (‚â•90% coverage)
- [ ] All integration tests passing (LLM mocking + real calls)
- [ ] Performance tests meet SLOs (latency p95 < Xms, define X)
- [ ] Regression tests pass on 50+ historical analyses
- [ ] Chaos engineering tests pass (failure injection)
- [ ] Load tests pass (100 concurrent analyses)
- [ ] Security review completed (no exposed secrets, proper error handling)

### 11.4 Deployment
- [ ] Feature flag `PIPELINE_V2_ENABLED` implemented
- [ ] Canary deployment tested in staging (5% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
- [ ] Rollback procedure tested in staging
- [ ] Production deployment plan approved
- [ ] Monitoring dashboards created (success rate, latency, cost)
- [ ] Alerting configured (circuit breaker, error thresholds)

### 11.5 Documentation
- [ ] All `FH_LLM_*` references removed from docs (verified: `rg "FH_LLM_" Docs` returns 0 or only historical)
- [ ] Links to this plan added in updated docs
- [ ] API documentation updated (if applicable)
- [ ] Runbooks created for common failure scenarios
- [ ] User-facing error message documentation created
- [ ] Migration guide for teams/users (if applicable)

### 11.6 Operational Readiness
- [ ] SLOs defined and agreed (e.g., 99.5% success rate, p95 latency <5s)
- [ ] Circuit breaker implementation verified
- [ ] Cost monitoring enabled and budget alerts configured
- [ ] On-call runbooks updated
- [ ] Incident response plan documented
- [ ] Post-deployment monitoring plan defined (30-day observation period)

### 11.7 Sign-offs
- [ ] Product owner approval
- [ ] Engineering lead approval
- [ ] QA sign-off
- [ ] DevOps/SRE sign-off
- [ ] Security review sign-off
- [ ] Architecture review sign-off (Principal Architect)

> **üèóÔ∏è ARCHITECT NOTE:**
> - **REQUIRED:** All checkboxes must be completed before marking this initiative "done"
> - **REQUIRED:** Create tracking ticket/issue for each checkbox
> - **REQUIRED:** Regular status updates during implementation (weekly recommended)
> - **BLOCKER:** Architecture sign-off requires addressing all CRITICAL gaps in review above

---

## 16) Appendices

### Appendix A: Code Inventory (To Be Completed in Phase B)

**Files to Modify:**
```
apps/web/src/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ config-loader.ts              [MODIFY] Remove FH_CONFIG_ENV_OVERRIDES
‚îÇ   ‚îú‚îÄ‚îÄ text-analysis-service.ts      [MODIFY] Remove hybrid/fallback logic
‚îÇ   ‚îî‚îÄ‚îÄ tiering-service.ts            [MODIFY] Remove FH_LLM_TIERING
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline-config.ts            [CREATE] Add PipelineConfigV2 interface
‚îî‚îÄ‚îÄ migrations/
    ‚îî‚îÄ‚îÄ pipeline-v1-to-v2.ts          [CREATE] Migration script
```

**Files to Delete:**
```
apps/web/src/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ text-analysis-hybrid.ts       [DELETE] Hybrid service
‚îÇ   ‚îî‚îÄ‚îÄ text-analysis-heuristic.ts    [DELETE] Heuristic fallback
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ env-override-maps.ts          [DELETE] Env override mappings
```

**Dependencies to Audit:**
- Run: `rg "FH_LLM_" apps/web/src --count-matches` to count all occurrences
- Run: `rg "text-analysis-hybrid" apps/web/src` to find all imports
- Run: `rg "process\.env\.FH_CONFIG" apps/web/src` to find env reads

### Appendix B: Migration Checklist

**Pre-Migration:**
- [ ] Full database backup created
- [ ] Rollback script tested in staging
- [ ] All v1 configs inventoried (count: ___)
- [ ] Migration dry-run completed successfully
- [ ] Team notified of maintenance window

**During Migration:**
- [ ] Analysis queue paused OR dual-version support enabled
- [ ] Migration script executed
- [ ] Validation queries run (v1 count == v2 count)
- [ ] Smoke tests passed
- [ ] Rollback script verified accessible

**Post-Migration:**
- [ ] v2 configs activated for 5% traffic
- [ ] Monitoring for 24hrs, no errors
- [ ] Gradual rollout to 100%
- [ ] v1 configs archived (not deleted)
- [ ] Team retrospective scheduled

### Appendix C: Open Action Items

**Immediate (Before Phase B):**
1. [ ] **Answer Q1-Q10** in Section 10 (Open Questions)
2. [ ] **Assign owners** to all risks in Section 9
3. [ ] **Define SLO thresholds** in Section 12.1 (confirm with stakeholders)
4. [ ] **Finalize v2 schema** in Section 14.1 (technical design session)
5. [ ] **Create tracking dashboard** for DoD checkboxes (Section 11)

**Short-term (Before Phase D):**
6. [ ] **Write migration SQL script** with transaction wrapping
7. [ ] **Write rollback SQL script** and test in staging
8. [ ] **Implement feature flags** for gradual rollout
9. [ ] **Create monitoring dashboards** per Section 15.2
10. [ ] **Write runbooks** per Section 15.4

**Medium-term (Before Phase E):**
11. [ ] **Complete all testing** per Section 8 (enhanced)
12. [ ] **Update all documentation** per Phase E list
13. [ ] **Conduct load testing** with LLM-only approach
14. [ ] **Perform cost analysis** comparing v1 vs v2

---

## üèóÔ∏è FINAL ARCHITECT SUMMARY

### Review Outcome: **CONDITIONAL APPROVAL PENDING REVISIONS**

**What This Plan Does Well:**
‚úÖ Clear strategic vision for LLM-only contract
‚úÖ Phased implementation approach
‚úÖ Comprehensive documentation update list
‚úÖ Strong motivation and goals definition

**Critical Gaps Addressed in This Review:**
üìù Added Section 12: Operational Readiness (SLOs, circuit breakers, cost management)
üìù Added Section 13: Deployment Strategy (gradual rollout, rollback procedures)
üìù Added Section 14: Pipeline v2 Schema Definition (TypeScript interfaces, migration mapping)
üìù Added Section 15: Monitoring & Observability (metrics, dashboards, alerts, runbooks)
üìù Enhanced Section 8: Verification/Test Plan (integration, performance, chaos testing)
üìù Enhanced Section 9: Risks & Mitigations (12 risks identified vs original 3)
üìù Enhanced Section 10: Open Questions (10 critical questions to answer)
üìù Enhanced Section 11: Definition of Done (76 checkboxes vs original 5 items)

### Next Steps for Plan Owner:

**IMMEDIATE (This Week):**
1. Review all üèóÔ∏è ARCHITECT NOTES throughout this document
2. Address 5 BLOCKING ISSUES identified in the review summary (top of doc)
3. Answer Q1-Q10 in Section 10 (Open Questions)
4. Assign owners to all 12 risks in Section 9
5. Schedule architecture review meeting to discuss operational resilience

**SHORT-TERM (Next 2 Weeks):**
6. Finalize pipeline.v2 schema (Section 14)
7. Define SLOs and confirm with stakeholders (Section 12.1)
8. Create migration and rollback SQL scripts
9. Set up monitoring infrastructure (Section 15)
10. Complete code inventory (Appendix A)

**BEFORE IMPLEMENTATION:**
11. Get sign-off on all 76 DoD checkboxes (Section 11)
12. Complete all Phase B prerequisites
13. Conduct architecture review for final approval

### Architecture Approval Status:

**Current Status:** ‚úÖ **APPROVED FOR POC IMPLEMENTATION**

**POC Approval Criteria (All Met):**
- ‚úÖ Core technical approach is sound (LLM-only contract)
- ‚úÖ Phased implementation plan is clear
- ‚úÖ Reference architecture documented for future production use
- ‚úÖ Schema definition will be completed during implementation
- ‚úÖ Basic testing plan in place

**Future Production Approval Will Require:**
- [ ] Sections 12-15 implemented (operational readiness, deployment strategy, monitoring)
- [ ] Comprehensive test plan executed
- [ ] Migration strategy with rollback tested
- [ ] Performance benchmarks validated

**Estimated Timeline:**
- **POC Implementation:** 2-4 weeks (Phases B-E)
- **Production Hardening:** Additional 4-6 weeks when ready to promote

### Contact for Questions:

For clarification on any architectural recommendations in this review, schedule a 1:1 with the Principal Architect before proceeding with implementation.

**Final Note for POC:** This plan is **APPROVED FOR POC EXECUTION**. The team may proceed with Phases B-E immediately. Sections 12-15 are documented as best-practice reference architecture for when the POC is promoted to production, but they do not block POC implementation. This approach allows rapid POC validation while maintaining a clear path to production-grade deployment.

---

**Document Version History:**
- 2026-02-01: Initial draft (FactHarbor Team)
- 2026-02-01: Principal Architect review - Production scope
- 2026-02-01: Updated for POC context - **APPROVED FOR POC IMPLEMENTATION**

