= Orchestrated Pipeline =

{{warning}}
**Archived 2026-02-19** — The Orchestrated pipeline was **removed in v2.11.0 (2026-02-17)**. It has been replaced by the **[[ClaimAssessmentBoundary pipeline>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.Pipeline Variants.WebHome]]** as the default analysis pipeline. This page is preserved for historical reference only. The source file ##orchestrated.ts## (~18,400 lines) has been deleted from the codebase.
{{/warning}}

{{info}}
**Developer Reference (HISTORICAL)** — Detailed implementation of the former default pipeline with function names, LLM call points, budget controls, and adaptive fallback mechanisms.

**Key Files (removed)**: ##apps/web/src/lib/analyzer/orchestrated.ts##, ##apps/web/prompts/orchestrated.prompt.md##
{{/info}}

== Pipeline Flow ==

The Orchestrated Pipeline follows a fixed 5-step AKEL flow: Understand → Research → Verdict → Summary → Report. Each step is TypeScript-orchestrated with explicit LLM call points and deterministic control flow.

{{include reference="FactHarbor.Product Development.Diagrams.Orchestrated Pipeline Detail.WebHome"/}}

== LLM vs Web Search (At a Glance) ==

{{info}}
**Quick visibility guide**
* **LLM-heavy phases**: Understand, Verdict
* **Web-heavy phase**: Research
* **Hybrid phase**: Research combines web retrieval with LLM evidence extraction
{{/info}}

|= Phase |= Primary Driver |= LLM Activity |= Web/Search Activity
| Understand | LLM reasoning | Claim understanding, context shaping, decomposition | None
| Research | Web retrieval | Query planning + evidence extraction per source | Search provider calls + source fetch
| Verdict | LLM reasoning | Claim verdicts + article verdict + grounding checks | None
| Summary / Report | Deterministic formatting | None | None

== Step-by-Step Reference ==

=== Step 1: UNDERSTAND ===

|= Function |= Purpose |= LLM Calls |= Web/Search Calls
| ##runFactHarborAnalysis()## | Main entry point, initializes state | 0 | 0
| ##understandClaim()## | Extracts claims, detects input type, identifies thesis, builds/normalizes AnalysisContexts | 1 | 0
| ##detectContexts()## | Deterministic wrapper (currently disabled for semantic pre-detection) | 0 | 0
| Gate 1 | Structural claim gate before research | 0 | 0

**Output**: Array of validated claims with types, roles, dependencies, and context assignments.

=== Step 2: RESEARCH ===

|= Function |= Purpose |= LLM Calls |= Web/Search Calls
| ##decideNextResearch()## | Generates targeted search queries based on claims and gaps | 1 per iteration | 0
| ##searchWebWithProvider()## | Executes web search (Google CSE or SerpAPI) | 0 | 1+ per iteration
| ##assessSearchRelevanceBatch()## | LLM-classifies results as primary / secondary / unrelated | 1 per batch | 0
| ##fetchSourceContent()## | Parallel content fetching with timeout | 0 | 1 per selected source URL
| ##prefetchSourceReliability()## | Batch source reliability lookup/evaluation | 0 (in orchestrated flow) | 0 (SR cache/service boundary)
| ##buildAdaptiveFallbackQueries()## | Relaxes search constraints when candidates < threshold | 0 | 0
| ##extractEvidence()## | Extracts evidence items from each source document | 1 per source | 0

**Search Relevance Modes**: Before fetching, ##assessSearchRelevanceBatch()## classifies search results using one of three UCM-managed relevance modes loaded from ##orchestrated.prompt.md##:

|= Mode |= Prompt Section |= When Used
| **Strict** | ##SEARCH_RELEVANCE_MODE_STRICT## | ##requireContextMatch## + ##strictInstitutionMatch## — demands exact institution/entity AND context match
| **Moderate** | ##SEARCH_RELEVANCE_MODE_MODERATE## | ##requireContextMatch## only — entity match preferred, same subject matter accepted
| **Relaxed** | ##SEARCH_RELEVANCE_MODE_RELAXED## | Neither constraint — general topic/entity overlap suffices

The selected mode instructions are injected as ##${MODE_INSTRUCTIONS}## into the ##SEARCH_RELEVANCE_BATCH_SYSTEM## prompt section.

**Adaptive Fallback**: When fewer than 5 candidate sources are found, the system generates up to 2 additional fallback queries with relaxed constraints.

**Loop Termination**: The research loop exits when any budget limit is reached (iterations, tokens, or sources).

=== Step 3: VERDICT ===

|= Function |= Purpose |= LLM Calls |= Web/Search Calls
| ##generateClaimVerdicts()## | Per-claim verdict with truth percentage, confidence, reasoning | 1 | 0
| ##calculateWeightedVerdictAverage()## | Aggregates claim verdicts into weighted averages | 0 | 0
| ##detectClaimContestation()## | Identifies claims with significant counter-evidence | 0 | 0
| ##detectHarmPotential()## | Flags claims with potential harm implications | 0 | 0
| Gate 4 | Assesses verdict confidence (source count, fact count, reasoning quality) | 0 | 0
| ##generateArticleVerdict()## | Overall article verdict aggregated from claims | 1 | 0

**Post-Processing** — After LLM verdict generation, deterministic corrections are applied:
* ##detectAndCorrectVerdictInversion()## — Fixes direction mismatches between truth% and verdict label
* ##applyEvidenceWeighting()## — Adjusts truth% based on source reliability scores
* Confidence calibration — 4-layer system (density, band snapping, verdict coupling, context consistency)

=== Steps 4-5: SUMMARY and REPORT ===

|= Function |= Purpose |= LLM Calls |= Web/Search Calls
| ##generateTwoPanelSummary()## | Formats results for the UI two-panel display | 0 | 0
| ##generateReport()## | Generates human-readable Markdown report | 0 | 0

No LLM calls — these steps use deterministic formatting of the verdict results.

== Budget Controls ==

Budget limits prevent runaway costs and ensure predictable analysis times.

|= Parameter |= Default |= Config Property |= Purpose
| Max iterations per context | 5 | ##maxIterationsPerContext## | Limits research depth per AnalysisContext
| Max total iterations | 20 | ##maxTotalIterations## | Caps total research iterations across all contexts
| Max total tokens | 750,000 | ##maxTotalTokens## | Token budget across all LLM calls

== Adaptive Fallback Parameters ==

|= Parameter |= Default |= Config Property |= Purpose
| Min candidates before fallback | 5 | ##searchAdaptiveFallbackMinCandidates## | Triggers fallback when sources are sparse
| Max extra fallback queries | 2 | ##searchAdaptiveFallbackMaxQueries## | Limits additional search queries

== LLM Call Summary ==

|= Pipeline Phase |= LLM Call Count |= Web/Search Call Count |= Model Tier
| Understand (claim extraction) | 1 | 0 | Standard
| Research (query generation) | 1 per iteration | 0 | Budget
| Research (search + fetch) | 0 | 1+ search per iteration + 1 fetch per selected source | N/A
| Research (evidence extraction) | 1 per source | 0 | Budget
| Verdict (claim verdicts) | 1 | 0 | Premium
| Verdict (article verdict) | 1 | 0 | Premium

**Typical total**: 8-15 LLM calls for a standard article analysis (5-10 claims, 5-8 sources).

== Shared Modules ==

|= Module |= Key Functions Used |= Pipeline Phase
| ##analysis-contexts.ts## | ##detectContexts()##, ##canonicalizeContexts()## | Understand
| ##claim-decomposition.ts## | ##normalizeClaimText()##, ##deriveCandidateClaimTexts()## | Understand
| ##quality-gates.ts## | Gate 1 (claim validation), Gate 4 (confidence) | Understand, Verdict
| ##evidence-filter.ts## | ##filterByProbativeValue()##, ##countVaguePhrases()## | Research
| ##source-reliability.ts## | ##prefetchSourceReliability()##, ##applyEvidenceWeighting()## | Research, Verdict
| ##aggregation.ts## | ##calculateWeightedVerdictAverage()##, ##detectClaimContestation()## | Verdict
| ##verdict-corrections.ts## | ##detectAndCorrectVerdictInversion()## | Verdict
| ##provenance-validation.ts## | ##filterEvidenceByProvenance()## | Research
| ##confidence-calibration.ts## | 4-layer calibration pipeline | Verdict

== Output Schema ==

The pipeline produces the **canonical result schema** used by the Jobs UI:

|= Field |= Type |= Description
| ##article## | object | Input metadata, thesis, analysisContexts
| ##claims## | array | Extracted claims with types, roles, dependencies
| ##claimVerdicts## | array | Per-claim verdicts with truthPercentage, confidence, reasoning
| ##articleVerdict## | object | Overall verdict aggregated from claims
| ##evidenceItems## | array | Evidence extracted from sources
| ##sources## | array | Source metadata with reliability scores
| ##meta## | object | Providers, timing, gate stats, budget usage

== Prompt Loading ==

All LLM prompts are loaded from UCM-managed ##orchestrated.prompt.md## via ##loadAndRenderSection()##. The prompt file contains 40+ named sections covering every LLM call point in the pipeline. Key section groups:

|= Section Group |= Sections |= Pipeline Phase
| Understand | ##UNDERSTAND##, ##UNDERSTAND_USER##, ##UNDERSTAND_JSON_FALLBACK_SYSTEM##, ##UNDERSTAND_STRUCTURED_RETRY_SYSTEM## | Step 1
| Supplemental | ##SUPPLEMENTAL_CLAIMS##, ##SUPPLEMENTAL_CONTEXTS##, ##OUTCOME_CLAIMS##, ##OUTCOME_ENRICH_*## | Step 1 (post-Gate 1)
| Context Refinement | ##CONTEXT_REFINEMENT##, ##CONTEXT_REFINEMENT_CANDIDATES_BLOCK##, ##CONTEXT_REFINEMENT_USER## | Post-Research
| Evidence Extraction | ##EXTRACT_EVIDENCE##, ##EXTRACT_EVIDENCE_USER##, ##EXTRACT_EVIDENCE_HIGH_IMPACT_FILTER_USER## | Step 2
| Search Relevance | ##SEARCH_RELEVANCE_MODE_STRICT##, ##SEARCH_RELEVANCE_MODE_MODERATE##, ##SEARCH_RELEVANCE_MODE_RELAXED##, ##SEARCH_RELEVANCE_BATCH_SYSTEM##, ##SEARCH_RELEVANCE_BATCH_USER## | Step 2
| Grounding | ##GROUNDED_SEARCH_REQUEST##, ##GROUNDING_KEY_TERMS_BATCH_USER##, ##GROUNDING_ADJUDICATION_BATCH_USER## | Step 2-3
| Verdict | ##VERDICT##, ##VERDICT_USER##, ##VERDICT_BREVITY_RULES##, ##VERDICT_DIRECTION_VALIDATION_BATCH_USER## | Step 3
| Claim Verdicts | ##CLAIM_VERDICTS##, ##CLAIM_VERDICTS_USER##, ##CLAIM_VERDICTS_KEY_FACTORS_APPEND## | Step 3
| Knowledge Config | ##KNOWLEDGE_RECENCY_GUIDANCE##, ##KNOWLEDGE_INSTRUCTION_ALLOW_MODEL##, ##KNOWLEDGE_INSTRUCTION_EVIDENCE_ONLY## | Cross-cutting
| Provider Hints | ##PROVIDER_HINT_OPENAI##, ##PROVIDER_HINT_ANTHROPIC##, ##PROVIDER_HINT_GOOGLE##, ##PROVIDER_HINT_MISTRAL## | Cross-cutting

----

**Archived from:** [[Deep Dive Index>>FactHarbor.Product Development.Specification.Architecture.Deep Dive.WebHome]]
