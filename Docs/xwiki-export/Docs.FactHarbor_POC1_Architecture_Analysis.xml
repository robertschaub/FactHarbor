<?xml version="1.1" encoding="UTF-8"?>
<xwikidoc version="1.3" reference="Docs.FactHarbor POC1 Architecture Analysis" locale=""><web>Docs</web><name>FactHarbor POC1 Architecture Analysis</name><language /><defaultLanguage /><translation>0</translation><creator>xwiki:XWiki.Admin</creator><createdDate>1737936000000</createdDate><parent>Docs.WebHome</parent><author>xwiki:XWiki.Admin</author><contentAuthor>xwiki:XWiki.Admin</contentAuthor><date>1738108800000</date><contentUpdateDate>1738108800000</contentUpdateDate><version>2.1</version><title>FactHarbor POC1 Architecture Analysis</title><comment>Terminology corrections: EVIDENCE entity standardization</comment><minorEdit>false</minorEdit><syntaxId>xwiki/2.1</syntaxId><hidden>false</hidden><content>= FactHarbor POC1 Architecture Analysis =

**Version:** 2.6.17
**Analysis Date:** January 2026
**Document Purpose:** Technical diagrams, gap analysis, and optimization recommendations
**Last Updated:** 2026-01-28 (Terminology corrections applied)

{{info}}
**Terminology Note:** This document uses "Evidence" as the entity name for extracted information from sources. In the current POC1 codebase, this is implemented as `ExtractedFact` (TypeScript interface). The term "Evidence" more accurately reflects that these items are extracted material to be evaluated, not verified facts. See `Docs/REVIEWS/Terminology_Audit_Fact_Entity.md` for migration plans.
{{/info}}

----

== 1. AKEL Flow Diagram (with LLM and WebSearch Interactions) ==


{{mermaid}}
flowchart TB
    subgraph Input["üì• Input Layer"]
        URL[URL Input]
        TEXT[Text Input]
    end

    subgraph Retrieval["üîç Content Retrieval"]
        FETCH[extractTextFromUrl]
        PDF[PDF Parser&lt;br/&gt;pdf-parse v1]
        HTML[HTML Parser&lt;br/&gt;cheerio]
    end

    subgraph AKEL["üß† AKEL Pipeline"]
        direction TB

        subgraph Step1["Step 1: Understand"]
            UNDERSTAND[understandClaim&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Detect input type&lt;br/&gt;‚Ä¢ Extract claims&lt;br/&gt;‚Ä¢ Identify dependencies&lt;br/&gt;‚Ä¢ Assign risk tiers]
            LLM1[("ü§ñ LLM Call #1&lt;br/&gt;Claude/GPT/Gemini")]
        end

        subgraph Step2["Step 2: Research (Iterative)"]
            DECIDE[decideNextResearch&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Generate queries&lt;br/&gt;‚Ä¢ Focus areas]

            SEARCH[("üåê Web Search&lt;br/&gt;Google CSE / SerpAPI")]

            FETCHSRC[fetchSourceContent&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Parallel fetching&lt;br/&gt;‚Ä¢ Timeout handling]

            EXTRACT[extractFacts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Parse sources&lt;br/&gt;‚Ä¢ Extract facts]
            LLM2[("ü§ñ LLM Call #2-N&lt;br/&gt;Per source")]
        end

        subgraph Step3["Step 3: Verdict Generation"]
            VERDICT[generateVerdicts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Claim verdicts&lt;br/&gt;‚Ä¢ Article verdict&lt;br/&gt;‚Ä¢ Dependency propagation]
            LLM3[("ü§ñ LLM Call #N+1&lt;br/&gt;Final synthesis")]
        end

        subgraph Step4["Step 4: Report"]
            REPORT[buildTwoPanelSummary&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Format results&lt;br/&gt;‚Ä¢ Generate markdown]
        end
    end

    subgraph Output["üì§ Output"]
        RESULT[AnalysisResult JSON]
        MARKDOWN[Report Markdown]
    end

    %% Flow connections
    URL --&gt; FETCH
    TEXT --&gt; UNDERSTAND
    FETCH --&gt; PDF
    FETCH --&gt; HTML
    PDF --&gt; UNDERSTAND
    HTML --&gt; UNDERSTAND

    UNDERSTAND --&gt; LLM1
    LLM1 --&gt; DECIDE

    DECIDE --&gt; SEARCH
    SEARCH --&gt; FETCHSRC
    FETCHSRC --&gt; EXTRACT
    EXTRACT --&gt; LLM2
    LLM2 --&gt; DECIDE

    DECIDE --&gt;|"Research Complete"| VERDICT
    VERDICT --&gt; LLM3
    LLM3 --&gt; REPORT

    REPORT --&gt; RESULT
    REPORT --&gt; MARKDOWN

    %% Styling
    classDef llm fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef search fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef step fill:#f3e5f5,stroke:#4a148c,stroke-width:2px

    class LLM1,LLM2,LLM3 llm
    class SEARCH search
    class UNDERSTAND,DECIDE,FETCHSRC,EXTRACT,VERDICT,REPORT step
{{/mermaid}}

----

== 2. ERD Data Model (Current POC1 Implementation) ==

**Data Objects ERD**

{{mermaid}}
erDiagram
    ARTICLE ||--o{ CLAIM : "contains"
    ARTICLE ||--|| ARTICLE_VERDICT : "has"
    CLAIM ||--|| CLAIM_VERDICT : "has"
    CLAIM ||--o{ CLAIM : "depends on"
    CLAIM_VERDICT }o--o{ EVIDENCE : "supported by"
    SOURCE ||--o{ EVIDENCE : "provides"
    ARTICLE ||--o{ SOURCE : "references"

    ARTICLE {
        string id PK "Unique identifier (job ID)"
        string inputType "text | url"
        string inputValue "Original URL or text"
        string articleThesis "Main argument/thesis"
        string detectedInputType "question | claim | article"
        boolean isQuestion "True if input is a question"
        datetime createdAt "Analysis timestamp"
        datetime updatedAt "Last update"
        json distinctProceedings "Legal proceedings if any"
        boolean hasMultipleProceedings "Multi-proceeding flag"
        string proceedingContext "Context for proceedings"
        json logicalFallacies "Detected fallacies array"
        boolean isPseudoscience "Pseudoscience detection"
        string_array pseudoscienceCategories "Categories if detected"
        int llmCalls "Total LLM API calls"
        json searchQueries "All search queries performed"
        string schemaVersion "e.g. 2.6.17"
    }

    CLAIM {
        string id PK "SC1, SC2, C1, etc."
        string articleId FK "Parent article"
        string text "The claim statement"
        string type "legal | procedural | factual | evaluative"
        string claimRole "attribution | source | timing | core"
        string_array dependsOn "IDs of prerequisite claims"
        string_array keyEntities "Named entities in claim"
        boolean isCentral "Is this a central claim?"
        string relatedProceedingId "Linked proceeding if any"
        int startOffset "Position in original text"
        int endOffset "End position in original text"
        string approximatePosition "Descriptive position"
    }

    CLAIM_VERDICT {
        string id PK "Same as claim ID"
        string claimId FK "Reference to claim"
        string llmVerdict "WELL-SUPPORTED | PARTIALLY-SUPPORTED | UNCERTAIN | REFUTED"
        string verdict "True | Mostly True | Leaning True | Unverified | Leaning False | Mostly False | False"
        int confidence "0-100 LLM confidence"
        int truthPercentage "0-100 calibrated truth score"
        string riskTier "A (high) | B (medium) | C (low)"
        string reasoning "Explanation of verdict"
        string_array supportingEvidenceIds "Evidence IDs supporting this"
        boolean dependencyFailed "True if prerequisite failed"
        string_array failedDependencies "Which deps failed"
        string highlightColor "green | light-green | yellow | orange | dark-orange | red | dark-red"
        boolean isPseudoscience "Pseudoscience flag"
        string escalationReason "Why verdict was escalated"
    }

    ARTICLE_VERDICT {
        string id PK "Same as article ID"
        string articleId FK "Reference to article"
        string llmArticleVerdict "Original LLM verdict"
        int llmArticleConfidence "Original LLM confidence"
        string articleVerdict "True | Mostly True | Leaning True | Unverified | Leaning False | Mostly False | False"
        int articleTruthPercentage "0-100 calibrated score"
        string articleVerdictReason "Why verdict differs from claims avg"
        int claimsAverageTruthPercentage "Average of claim verdicts"
        string claimsAverageVerdict "7-point average verdict"
        int claimsTotal "Total claims analyzed"
        int claimsSupported "Claims with truth &gt;= 72%"
        int claimsUncertain "Claims with truth 43-71%"
        int claimsRefuted "Claims with truth &lt; 43%"
        int centralClaimsTotal "Number of central claims"
        int centralClaimsSupported "Central claims supported"
    }

    EVIDENCE {
        string id PK "S1-F1, S1-F2 format"
        string sourceId FK "Reference to source"
        string claimId FK "Optional: specific claim this supports"
        string statement "The extracted statement text"
        string category "legal_provision | direct_evidence | expert_quote | statistic | event | criticism"
        string specificity "high | medium"
        string sourceExcerpt "Original text excerpt"
        string relatedProceedingId "Linked proceeding if any"
        boolean isContestedClaim "Is this a contested assertion"
        string claimSource "Who made contested claim"
    }

    SOURCE {
        string id PK "S1, S2, etc."
        string articleId FK "Parent article"
        string url "Full URL"
        string title "Page/document title"
        string domain "Extracted domain"
        int trackRecordScore "0-100 reliability score or null"
        string fullText "Extracted content"
        datetime fetchedAt "When content was fetched"
        string category "news | academic | government | legal"
        boolean fetchSuccess "True if fetch succeeded"
        string searchQuery "Which query found this"
        string mimeType "text/html | application/pdf"
    }
{{/mermaid}}

**Data Usage ERD**

{{mermaid}}
erDiagram
    JOB ||--o{ JOB_EVENT : "has"
    JOB ||--|| ANALYSIS_RESULT : "produces"
    ANALYSIS_RESULT ||--o{ CLAIM_VERDICT : "contains"
    ANALYSIS_RESULT ||--o{ FETCHED_SOURCE : "references"
    ANALYSIS_RESULT ||--o{ EVIDENCE : "contains"
    CLAIM_VERDICT }o--o{ EVIDENCE : "supported by"
    FETCHED_SOURCE ||--o{ EVIDENCE : "provides"
    CLAIM_VERDICT ||--o{ CLAIM_VERDICT : "depends on"

    JOB {
        string JobId PK "GUID"
        string Status "QUEUED|RUNNING|COMPLETE|FAILED"
        int Progress "0-100"
        datetime CreatedUtc
        datetime UpdatedUtc
        string InputType "text|url"
        string InputValue "URL or text content"
        string InputPreview "First 100 chars"
        json ResultJson "Full analysis result"
        string ReportMarkdown "Formatted report"
    }

    JOB_EVENT {
        long Id PK
        string JobId FK
        datetime TsUtc
        string Level "info|warn|error"
        string Message
    }

    ANALYSIS_RESULT {
        string schemaVersion "2.6.17"
        string inputType "question|claim|article"
        boolean isQuestion
        string articleThesis
        int articleTruthPercentage "0-100"
        string articleVerdict "7-point scale"
        json claimPattern "total/supported/uncertain/refuted"
        boolean isPseudoscience
        int llmCalls "Total LLM invocations"
        json searchQueries "All search queries"
    }

    CLAIM_VERDICT {
        string claimId PK "SC1, SC2, etc."
        string claimText
        boolean isCentral
        string claimRole "attribution|source|timing|core"
        string_array dependsOn "Prerequisite claim IDs"
        boolean dependencyFailed
        string llmVerdict "WELL-SUPPORTED|PARTIALLY-SUPPORTED|UNCERTAIN|REFUTED"
        string verdict "7-point: True to False"
        int confidence "0-100"
        int truthPercentage "0-100"
        string riskTier "A|B|C"
        string reasoning
        string_array supportingEvidenceIds
        string highlightColor "green to dark-red"
    }

    FETCHED_SOURCE {
        string id PK "S1, S2, etc."
        string url
        string title
        int trackRecordScore "0-100 or null"
        string fullText "Extracted content"
        datetime fetchedAt
        string category "legal|news|academic"
        boolean fetchSuccess
        string searchQuery "Which query found this"
    }

    EVIDENCE {
        string id PK "S1-F1, S1-F2, etc."
        string statement "The extracted statement text"
        string category "legal_provision|direct_evidence|expert_quote|statistic|event|criticism"
        string specificity "high|medium"
        string sourceId FK
        string sourceUrl
        string sourceTitle
        string sourceExcerpt
        string relatedProceedingId
        boolean isContestedClaim
        string claimSource
    }
{{/mermaid}}

----

== 3. Overall Architecture with Interactions ==

{{mermaid}}
flowchart TB
    subgraph Client["üñ•Ô∏è Client Layer"]
        BROWSER[Web Browser]
        ANALYZE_PAGE["/analyze page&lt;br/&gt;React + TailwindCSS"]
        JOBS_PAGE["/jobs page&lt;br/&gt;Job history &amp; status"]
    end

    subgraph NextJS["‚ö° Next.js Web App (apps/web)"]
        direction TB

        subgraph API_Routes["API Routes"]
            ANALYZE_API["/api/fh/analyze&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;POST: Create job"]
            JOBS_API["/api/fh/jobs&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;GET: List jobs&lt;br/&gt;POST: Create job"]
            JOB_API["/api/fh/jobs/[id]&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;GET: Job status"]
            EVENTS_API["/api/fh/jobs/[id]/events&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;GET: Job events (SSE)"]
            RUN_JOB["/api/internal/run-job&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;POST: Execute analysis"]
        end

        subgraph Lib["Core Libraries"]
            ANALYZER["analyzer.ts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;AKEL Pipeline&lt;br/&gt;2918 lines"]
            RETRIEVAL["retrieval.ts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;URL content extraction"]
            WEBSEARCH["web-search.ts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;Search abstraction"]
            MBFC["mbfc-loader.ts&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;Source reliability"]
        end
    end

    subgraph DotNet["üîß .NET API (apps/api)"]
        DOTNET_API["FactHarbor.Api&lt;br/&gt;ASP.NET Core"]

        subgraph Controllers["Controllers"]
            ANALYZE_CTRL["AnalyzeController"]
            JOBS_CTRL["JobsController"]
            INTERNAL_CTRL["InternalJobsController"]
        end

        subgraph Services["Services"]
            JOB_SVC["JobService&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;Job CRUD operations"]
            RUNNER_CLIENT["RunnerClient&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;Calls Next.js runner"]
        end

        DB[(SQLite Database&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;JobEntity&lt;br/&gt;JobEventEntity)]
    end

    subgraph External["üåê External Services"]
        LLM_PROVIDERS["LLM Providers&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Anthropic Claude&lt;br/&gt;‚Ä¢ OpenAI GPT&lt;br/&gt;‚Ä¢ Google Gemini&lt;br/&gt;‚Ä¢ Mistral"]
        SEARCH_PROVIDERS["Search Providers&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Google CSE&lt;br/&gt;‚Ä¢ SerpAPI&lt;br/&gt;‚Ä¢ Brave&lt;br/&gt;‚Ä¢ Tavily"]
        WEB["Web Content&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ News sites&lt;br/&gt;‚Ä¢ PDFs&lt;br/&gt;‚Ä¢ Academic sources"]
    end

    %% Client interactions
    BROWSER --&gt; ANALYZE_PAGE
    BROWSER --&gt; JOBS_PAGE
    ANALYZE_PAGE --&gt; ANALYZE_API
    JOBS_PAGE --&gt; JOBS_API

    %% Next.js internal
    ANALYZE_API --&gt; JOBS_API
    JOBS_API --&gt;|"Proxy"| DOTNET_API
    JOB_API --&gt;|"Proxy"| DOTNET_API
    EVENTS_API --&gt;|"Proxy"| DOTNET_API

    %% .NET flow
    DOTNET_API --&gt; ANALYZE_CTRL
    DOTNET_API --&gt; JOBS_CTRL
    DOTNET_API --&gt; INTERNAL_CTRL
    ANALYZE_CTRL --&gt; JOB_SVC
    JOBS_CTRL --&gt; JOB_SVC
    JOB_SVC --&gt; DB
    JOB_SVC --&gt; RUNNER_CLIENT
    RUNNER_CLIENT --&gt;|"HTTP POST"| RUN_JOB

    %% Analysis execution
    RUN_JOB --&gt; ANALYZER
    ANALYZER --&gt; RETRIEVAL
    ANALYZER --&gt; WEBSEARCH
    ANALYZER --&gt; MBFC

    %% External calls
    ANALYZER --&gt;|"AI SDK"| LLM_PROVIDERS
    WEBSEARCH --&gt; SEARCH_PROVIDERS
    RETRIEVAL --&gt; WEB

    %% Styling
    classDef external fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef core fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    classDef api fill:#e3f2fd,stroke:#1565c0,stroke-width:2px

    class LLM_PROVIDERS,SEARCH_PROVIDERS,WEB external
    class ANALYZER,RETRIEVAL,WEBSEARCH,MBFC core
    class ANALYZE_API,JOBS_API,JOB_API,EVENTS_API,RUN_JOB api
{{/mermaid}}

----

== 4. Specification vs Implementation Gap Analysis ==

=== 4.1 Data Model Gaps ===

| Specification Entity | POC1 Status | Gap Description |
|-|-|-|
| **Claim** | ‚ö†Ô∏è Partial | No persistent storage; claims exist only in JSON result. Missing: `status`, `confidence_score`, `risk_score`, `completeness_score`, `version`, `views`, `edit_count` |
| **Evidence** | ‚ö†Ô∏è Partial | Implemented as `ExtractedFact` but lacks: `supports` enum, proper `relevance_score` |
| **Source** | ‚ö†Ô∏è Partial | `FetchedSource` exists but missing: `type` enum, `accuracy_history`, `correction_frequency`, weekly update scheduler |
| **Scenario** | ‚ùå Missing | Not implemented. Claims are evaluated directly without scenario contexts |
| **Verdict** | ‚ö†Ô∏è Partial | `ClaimVerdict` exists but missing: `likelihood_range`, `uncertainty_factors` array, proper `explanation_summary` |
| **User** | ‚ùå Missing | No user authentication or role system |
| **Edit** | ‚ùå Missing | No audit trail for changes |

=== 4.2 AKEL Component Gaps ===

| Spec Component | POC1 Status | Gap Description |
| |-|-|
| **AKEL Orchestrator** | ‚úÖ Implemented | `runAnalysis()` function serves this role |
| **Claim Extractor** | ‚úÖ Implemented | `understandClaim()` with claim role/dependency tracking |
| **Claim Classifier** | ‚ö†Ô∏è Partial | Risk tier (A/B/C) assigned, but no domain classification |
| **Scenario Generator** | ‚ùå Missing | Claims evaluated without scenario extraction |
| **Evidence Summarizer** | ‚úÖ Implemented | `extractFacts()` function |
| **Contradiction Detector** | ‚ö†Ô∏è Partial | `isContestedClaim` flag exists but no active contradiction search |
| **Quality Gate Validator** | ‚ùå Missing | No source quality gates, no mandatory checks |
| **Audit Sampling Scheduler** | ‚ùå Missing | No audit system |
| **Embedding Handler** | ‚ùå Missing | Not needed for POC |
| **Federation Sync** | ‚ùå Missing | Not needed for POC |

=== 4.3 Architecture Gaps ===

| Spec Requirement | POC1 Status | Gap Description |
| |-|-|
| **Three-Layer Architecture** | ‚úÖ Implemented | Interface (Next.js) ‚Üí Processing (AKEL) ‚Üí Data (SQLite) |
| **LLM Abstraction Layer** | ‚úÖ Implemented | AI SDK supports multiple providers with failover |
| **PostgreSQL Primary DB** | ‚ö†Ô∏è Different | Using SQLite for simplicity (acceptable for POC) |
| **Redis Caching** | ‚ùå Missing | No caching layer |
| **S3 Archival** | ‚ùå Missing | No long-term storage |
| **Background Jobs** | ‚ùå Missing | No scheduler for source updates, cache warming |
| **Quality Monitoring** | ‚ö†Ô∏è Partial | LLM call counting exists, but no anomaly detection |

=== 4.4 Publication &amp; Review Gaps ===

| Spec Feature | POC1 Status | Gap Description |
| |-|-|
| **Risk Tier Publication Rules** | ‚ùå Missing | All results published immediately regardless of tier |
| **Human Review Queue** | ‚ùå Missing | No review workflow |
| **AI-Generated Labeling** | ‚ö†Ô∏è Partial | Results show "AI analysis" but no formal labeling system |
| **Audit Rate Sampling** | ‚ùå Missing | No sampling audits |

----

== 5. Optimization Recommendations ==

=== 5.1 Cost Optimizations ===

{{mermaid}}
pie title Current LLM Cost Distribution (Estimated per Analysis)
    "Step 1: Understand" : 15
    "Step 2: Research (per source)" : 60
    "Step 3: Verdicts" : 25
{{/mermaid}}

| Optimization | Estimated Savings | Implementation Effort |
| |-| |
| **Cache claim understanding** | 30-50% on repeated claims | Medium |
| **Use Haiku for fact extraction** | 40% on Step 2 costs | Low (config change) |
| **Batch fact extraction** | 20% fewer API calls | Medium |
| **Skip search for known claims** | 50%+ for cached claims | High (needs claim DB) |
| **Reduce max iterations** | Linear reduction | Low (config change) |

=== 5.2 Timing Optimizations ===

{{mermaid}}
gantt
    title Current Analysis Timeline (Typical)
    dateFormat ss
    axisFormat %S sec

    section Current Flow
    URL Fetch           :a1, 00, 2s
    Step 1 Understand   :a2, after a1, 15s
    Search Iteration 1  :a3, after a2, 8s
    Fetch Sources 1     :a4, after a3, 10s
    Extract Facts 1     :a5, after a4, 12s
    Search Iteration 2  :a6, after a5, 8s
    Fetch Sources 2     :a7, after a6, 10s
    Extract Facts 2     :a8, after a7, 12s
    Generate Verdicts   :a9, after a8, 15s

    section Optimized Flow
    URL Fetch           :b1, 00, 2s
    Step 1 Understand   :b2, after b1, 10s
    Search + Fetch (parallel) :b3, after b2, 12s
    Extract Facts (batched)   :b4, after b3, 8s
    Generate Verdicts   :b5, after b4, 10s
{{/mermaid}}

| Optimization | Time Savings | Notes |
| | |-|
| **Parallel source fetching** | Already implemented | Currently fetches 3 sources in parallel |
| **Streaming LLM responses** | 20-30% perceived | User sees progress faster |
| **Search query batching** | 10-15% | Send multiple queries to search API |
| **Reduce prompt size** | 5-10% per call | Optimize system prompts |
| **Use faster models for extraction** | 30-40% on Step 2 | Claude Haiku vs Sonnet |

=== 5.3 Priority Recommendations ===

1. **HIGH PRIORITY - Implement Claim Caching**
   - Cache claim verdicts by content hash
   - Reduces costs for repeated/similar claims
   - Enables the separated verdict architecture (see Section 6)

2. **MEDIUM PRIORITY - Use Tiered Models**
   - Step 1 (Understand): Sonnet (needs reasoning)
   - Step 2 (Extract): Haiku (simple extraction)
   - Step 3 (Verdicts): Sonnet (needs synthesis)

3. **LOW PRIORITY - Add Redis Cache**
   - Cache source content (24h TTL)
   - Cache search results (1h TTL)
   - Reduces external API calls

----

== 6. Separated Verdict Architecture Proposal ==

=== 6.1 Current Architecture ===

{{mermaid}}
flowchart LR
    subgraph Current["Current: Monolithic Analysis"]
        INPUT[Article Input] --&gt; ANALYZE[Full Analysis Pipeline]
        ANALYZE --&gt; CLAIMS[Claim Verdicts]
        ANALYZE --&gt; ARTICLE[Article Verdict]
        CLAIMS -.-&gt;|"Aggregated"| ARTICLE
    end
{{/mermaid}}

**Issues:**
- Every analysis re-processes all claims
- No caching of individual claim verdicts
- Article verdict tightly coupled to claim extraction

=== 6.2 Proposed Separated Architecture ===

{{mermaid}}
flowchart TB
    subgraph Input["Input Processing"]
        ARTICLE[Article/Text Input]
        EXTRACT[Claim Extraction]
    end

    subgraph ClaimLayer["Claim Verdict Layer (Cacheable)"]
        CACHE[(Claim Cache&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;Key: claim_hash&lt;br/&gt;TTL: 7 days)]

        CLAIM1["Claim 1 Analysis"]
        CLAIM2["Claim 2 Analysis"]
        CLAIM3["Claim N Analysis"]

        VERDICT1[Claim 1 Verdict]
        VERDICT2[Claim 2 Verdict]
        VERDICT3[Claim N Verdict]
    end

    subgraph ArticleLayer["Article Verdict Layer (Dynamic)"]
        AGGREGATE[Aggregate Claim Verdicts]
        CONTEXT[Apply Article Context&lt;br/&gt;‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ&lt;br/&gt;‚Ä¢ Claim relationships&lt;br/&gt;‚Ä¢ Logical structure&lt;br/&gt;‚Ä¢ Author intent]
        ARTICLE_VERDICT[Article Verdict]
    end

    %% Flow
    ARTICLE --&gt; EXTRACT
    EXTRACT --&gt; CLAIM1
    EXTRACT --&gt; CLAIM2
    EXTRACT --&gt; CLAIM3

    CLAIM1 --&gt;|"Cache Miss"| VERDICT1
    CLAIM2 --&gt;|"Cache Hit"| VERDICT2
    CLAIM3 --&gt;|"Cache Miss"| VERDICT3

    CLAIM1 &lt;-.-&gt; CACHE
    CLAIM2 &lt;-.-&gt; CACHE
    CLAIM3 &lt;-.-&gt; CACHE

    VERDICT1 --&gt; AGGREGATE
    VERDICT2 --&gt; AGGREGATE
    VERDICT3 --&gt; AGGREGATE

    AGGREGATE --&gt; CONTEXT
    CONTEXT --&gt; ARTICLE_VERDICT

    classDef cache fill:#fff9c4,stroke:#f57f17,stroke-width:2px
    classDef dynamic fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    class CACHE cache
    class CONTEXT,ARTICLE_VERDICT dynamic
{{/mermaid}}

=== 6.3 Benefits Analysis ===

| Benefit | Impact | Rationale |
|-| |-|
| **Cost Reduction** | 40-70% for repeated claims | Many articles share common claims (e.g., "COVID vaccines are safe") |
| **Faster Analysis** | 50%+ for cached claims | Skip research + LLM calls for known claims |
| **Consistency** | High | Same claim always gets same verdict (until cache expires) |
| **Freshness Control** | Configurable TTL | Balance consistency vs. new evidence |
| **Scalability** | Linear improvement | More users = higher cache hit rate |

=== 6.4 Implementation Considerations ===

**Claim Hashing Strategy:**
{{code language="typescript"}}function getClaimHash(claim: string): string {
  // Normalize: lowercase, remove punctuation, stem words
  const normalized = normalize(claim);
  // Hash for cache key
  return crypto.createHash('sha256').update(normalized).digest('hex').slice(0, 16);
}{{/code}}

**Cache Invalidation Triggers:**
- TTL expiration (default 7 days)
- Major news event related to claim topic
- Source track record significant change
- Manual invalidation by moderator

**Article Verdict Considerations:**
- Article verdict should ALWAYS be dynamic (never cached)
- Same claims in different article contexts may yield different article verdicts
- Example: "Vaccines are safe" + "Vaccines cause autism" ‚Üí article may be misleading even if first claim is true

=== 6.5 Recommendation ===

**YES, separating is beneficial** with the following caveats:

1. **Claim verdicts should be cached** with semantic similarity matching (not just exact match)
2. **Article verdicts should always be dynamic** to account for:
   - Claim relationships and logical structure
   - Author's argumentative strategy
   - Context and framing
   - Selective use of true claims to support false conclusions

3. **Implementation phases:**
   - Phase 1: Exact-match claim caching (simple hash)
   - Phase 2: Semantic similarity caching (embedding-based)
   - Phase 3: Federated claim sharing across instances

----

== 7. Summary ==

=== Current State ===

- POC1 implements core AKEL pipeline successfully
- Claim dependency tracking is implemented
- Multiple LLM providers supported
- No persistent claim storage or caching

=== Key Gaps from Specification ===

- No scenario extraction
- No user/role system
- No audit trail
- No source track record updates
- No review queue

=== Recommended Next Steps ===

1. Implement claim caching layer
2. Separate claim vs article verdict generation
3. Add Redis for source/search caching
4. Implement tiered model selection
5. Add basic audit logging
</content></xwikidoc>