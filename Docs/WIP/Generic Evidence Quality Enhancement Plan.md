# Generic Evidence Quality Enhancement Plan

**Author:** Claude (Lead Architect)
**Status:** ‚ö†Ô∏è RE-VALIDATION EXECUTED ‚Äî CLOSURE GATES STILL NOT MET
**Created:** 2026-02-05
**Updated:** 2026-02-08 (Session 15: source-count alignment + context frame signal + anchor recovery)
**Priority:** üî¥ HIGH (confidence collapse fixed; context-target and variance gates still failing)
**Verification Report:** [Evidence_Quality_Verification_Report.md](Evidence_Quality_Verification_Report.md)

**Issues Addressed:**

1. ‚úÖ Opinion vs evidence confusion - **RESOLVED** via deterministic filtering (91% ‚Üí 0% opinion contamination)
2. ‚è≥ LLMs don't know the present - **Phase 3 PARTIAL** (verdict prompt refined; full validation pending)
3. ‚ö†Ô∏è Report stability/context recall for sensitive procedural claims - **ACTIVE** (verdict accuracy fixes applied, configurability added, validation pending)
4. ‚úÖ Verdict accuracy suppression (39% vs expected ~73%) - **FIXED** (3 root causes identified and resolved)

---

## Current Implementation State (2026-02-08)

### Completed So Far

1. **Phase 1 completed and verified**
   - Deterministic evidence filtering is enforced even when upstream LLM filtering succeeds.
   - Opinion evidence items are removed deterministically; low-probative evidence is filtered reliably.
2. **Phase 2 implementation delivered in code**
   - `buildContextAwareCriticismQueries()` added in `orchestrated.ts`.
   - `checkSearchResultRelevance()` heuristic pre-filter added before extraction.
   - Filter telemetry logging (`stats.filterReasons`) added for observability.
3. **Phase 3 foundations delivered**
   - LLM relevance mode supports `off | auto | on`; default behavior is `auto`.
   - Normalization heuristics moved to UCM-backed config and made editable.
4. **Report-quality hardening delivered**
   - Question-to-statement normalization logic improved and regression-tested.
   - Context drift recovery improvements were added in orchestrated research flow.
5. **Verdict accuracy fixes delivered (Session 5-8)**
   - Context-claims consistency anchoring prevents LLM framing bias from suppressing verdicts.
   - Contested factor weighting reduced (0.3‚Üí0.5, 0.5‚Üí0.7) to prevent double-penalization.
   - Verdict prompt refined: knowledge cutoff no longer forces MIXED/UNVERIFIED; expanded documented evidence definition for legal/procedural claims.
   - Article Verdict Problem Override softened from hard cap to proportional blending.
6. **LLM tiering activated**
   - Haiku 3.5 for understand/extract, Sonnet 4 for verdict/context refinement.
   - Stale model ID fixed, context_refinement routed to premium tier.
7. **UCM configurability expanded (PipelineConfig)**
   - 5 new tunables added: `contextClaimsAnchorDivergenceThreshold`, `contextClaimsAnchorClaimsWeight`, `probativeDeduplicationThreshold`, `searchAdaptiveFallbackMinCandidates`, `searchAdaptiveFallbackMaxQueries`.
   - Dead `searchRelevanceLlmEnabled` removed; `searchRelevanceLlmMode` is sole control.
   - `anchorVerdictTowardClaims()` extracted to shared helper with defensive validation.
8. **CalcConfig fully wired to analyzer code (Session 9)**
   - **The CalcConfig placebo is fixed.** Previously, CalcConfig existed as a full schema loaded per-job via `getAnalyzerConfig()`, but no analyzer code actually read it ‚Äî the Admin UI for CalcConfig had zero effect. Now every report-influencing constant is wired.
   - **13 CalcConfig sections, 68 total fields** ‚Äî all connected to runtime code with backward-compatible defaults.
   - **7 existing sections wired** (verdictBands, aggregation, sourceReliability, qualityGates, contestationPenalties, deduplication, mixedConfidenceThreshold) to: `orchestrated.ts`, `aggregation.ts`, `quality-gates.ts`, `truth-scale.ts`, `source-reliability.ts`, `verdict-corrections.ts`, `evidence-filter.ts`.
   - **6 new CalcConfig sections added** (evidenceFilter, articleVerdictOverride, claimDecomposition, contextSimilarity, tangentialPruning, claimClustering) to `config-schemas.ts` + wired into `orchestrated.ts`.
   - **Derived values use VERDICT_BANDS**: `truthFromBand()` coefficients, verdict correction caps, and counter-claim thresholds are now computed from CalcConfig band boundaries instead of hardcoded magic numbers.
   - TypeScript compiles clean. All 67 relevant tests pass (aggregation: 13, evidence-filter: 54).

### Root Cause Analysis (2026-02-07)

Deep codebase analysis identified 4 concrete root causes for the open issues:

| # | Root Cause | Symptom | Fix Applied |
|---|-----------|---------|-------------|
| 1 | Frame signal gate (line 1614-1621) only checked `methodology\|boundaries\|geographic\|temporal` ‚Äî missed `institution`/`court` | Multi-context collapse for legal claims with different courts | Added `institution`/`court` to frame key computation |
| 2 | Aggressive dedup override (line 2131) forced merge at 0.92 when `assessedSim >= 0.75`, even when contexts had different institutions | Distinct legal contexts merged because assessed questions were phrased similarly | Suppress override when contexts have distinct `court`/`institution`/`jurisdiction` |
| 3 | `buildContextAwareCriticismQueries` (line 641) used `.find()` ‚Äî only first context with metadata | Multi-context analyses missing criticism queries for secondary contexts | Now iterates ALL contexts, deduplicating by jurisdiction/institution pair |
| 4 | Auto LLM relevance mode gated on `relevantResults.length === 0` (line 11679) | Path-dependent: one lucky heuristic pass disabled LLM review for all subsequent ambiguous results | Removed empty-results gate; LLM budget (`maxCalls=3`) still caps total calls |

### Verdict Accuracy Root Cause Analysis (2026-02-07, Session 5)

Live validation (Job `bc9d9e9621214793954128b107dc0711`) showed verdict of 39% vs expected ~73%. Three compounding mechanisms identified:

| # | Root Cause | Impact | Fix |
|---|-----------|--------|-----|
| 5 | **No context-claims anchoring**: LLM context verdicts (35%/42%) used directly, ignoring higher evidence-based claims average (52%) | Verdict suppressed 13+ points below evidence | Added `anchorVerdictTowardClaims()` helper ‚Äî blends toward claims when divergence > threshold |
| 6 | **Contested factor over-weighting**: "established" counter-evidence ‚Üí 0.3x weight, double-penalizing since truthPercentage already reflects counter-evidence | Claims average suppressed ~10-15 points | Reduced weights: 0.3‚Üí0.5 (established), 0.5‚Üí0.7 (disputed) |
| 7 | **Verdict prompt bias against procedural claims**: Knowledge cutoff guidance pushed to UNVERIFIED/MIXED; evidence quality conflated "peer-reviewed" with "documented evidence" | Systematically low context verdicts for legal/procedural claims | Refined prompt: directional verdicts from documented evidence, expanded evidence types |

### Still Open / Pending Validation

1. **Verdict stability** ‚Äî Re-runs executed (Sessions 12 and 14); `confidence=0` outliers were fixed, but variance remains above threshold for key claim families.
2. **Context recall** ‚Äî Re-run executed; expected-context hit rates still unstable (Bolsonaro and technology families fail target).
3. **Verdict accuracy** ‚Äî Score variance improved for some claims, but closure requires confidence + context gates to pass together.
4. **Session 14 update** ‚Äî `confidence=0` outliers eliminated (`0/25`), but primary closure still fails due context-hit misses and variance failures (government trust, technology comparison).
4. **Dynamic pipeline convergence** ‚Äî Tracked separately (experimental). Monitor.
5. **Article-mode input test** ‚Äî Proportional blending (Fix in Article VP Override) needs "Coffee cures cancer" pattern verification.
6. ~~UCM config reseed~~ **DONE** (forced reseed executed; active pipeline hash changed)
7. **CalcConfig Admin UI verification** ‚Äî Confirm that all 6 new CalcConfig sections appear in Admin UI and changes take effect at runtime.

### Remaining Work Before Marking Plan Complete

1. ~~Improve multi-context recall without domain-specific rules~~ **DONE** (Fixes 1+2: generic institutional identity protection)
2. ~~Tune pre-filter/relevance gating to reduce false negatives~~ **DONE** (Fixes 3+4: multi-context queries + deterministic LLM budget)
3. ~~Fix verdict accuracy suppression~~ **DONE** (Fixes 5-7: anchoring + contested weights + prompt refinement)
4. ~~Make tunables UCM-configurable (PipelineConfig)~~ **DONE** (5 new config fields + shared helper)
5. ~~Wire ALL report-influencing constants to CalcConfig~~ **DONE** (Session 9: 13 sections, 68 fields, 10 files touched)
6. ~~Reseed UCM configs (both PipelineConfig and CalcConfig)~~ **DONE** (forced reseed run; config hash verified in DB)
7. ~~Complete repeated-run validation closure suite and compare against variance/context gates~~ **DONE** (Session 12: 25-run orchestrated matrix completed; gates still failing).
8. ~~Fix confidence-collapse path (`confidence=0`) and enforce stable confidence calculation under sparse-source runs~~ **DONE** (Session 13, validated in Session 14).
9. Improve context-target stability (prevent Bolsonaro under-detection and scientific/technology over-splitting).
10. Reduce high variance for government-trust and technology-comparison families.
11. Align low-source warning semantics with displayed source metrics (currently inconsistent on some runs).
12. Verify CalcConfig sections in Admin UI and confirm runtime pickup.
13. Publish final verification evidence and only then mark Phase 2/3 complete.

---

## Executive Summary

This plan addresses systematic evidence quality issues where third-party commentary (opinions, reactions, characterizations) contaminates analyses that should be driven by probative evidence. While this failure mode often appears in procedural/process questions (e.g., fairness, compliance, integrity), the root causes are GENERIC and apply across domains (legal, scientific, corporate, historical).

**Two Core Problems:**

1. **Opinion vs Evidence Confusion**: The system lacks mechanisms to distinguish opinion from evidence and filter irrelevant third-party commentary BEFORE extraction, leading to contamination across ALL analysis types (legal, scientific, corporate, historical).
2. **LLMs Don't Know The Present**: LLMs are trained on past data with a knowledge cutoff date, and have NO knowledge of current reality after that cutoff - current government trustworthiness, recent verdicts, contemporary reputations, ongoing events. Yet the system doesn't explicitly acknowledge this limitation or enforce evidence recency requirements for time-sensitive claims.

**Solution Approach** : Five generic principles that strengthen evidence quality universally:

1. Contextual relevance pre-filtering (before extraction) - **Addresses Problem 1**
2. Enhanced opinion vs evidence distinction - **Addresses Problem 1**
3. Probative value validation (deterministic correction) - **Addresses Problem 1**
4. **LLM knowledge gap handling (time-sensitive claims) - Addresses Problem 2**
5. Context-aware criticism search queries - **Addresses Problem 1**

**Problem-Solution Mapping:**


| Core Problem                           | Solutions            | Phase     |
| ---------------------------------------- | ---------------------- | ----------- |
| **Problem 1: Opinion ‚â† Evidence**     | Solutions 2, 3, 5, 1 | Phase 1-2 |
| **Problem 2: LLMs Don't Know Present** | Solution 4           | Phase 3   |

---

## Observed Patterns (Sampled, Generic)

In sampled recent runs, we observed generic failure modes that can happen for **any topic**:

1. ~~**Opinion evidence items can be overweighted**~~ ‚úÖ **RESOLVED** (Phase 1: deterministic filtering)
   - Evidence items labeled `sourceAuthority="opinion"` can still be assigned `probativeValue="high"|"medium"` by the LLM.
   - Without deterministic enforcement, these items can influence verdicts despite being non-probative.
2. ~~**Criticism search can import irrelevant third-party reactions**~~ ‚úÖ **RESOLVED** (Phase 2: context-aware queries)
   - Broad criticism queries can pull reactions that are not directly tied to the AnalysisContext being analyzed.
3. **Context reference drift** ‚Äî ‚è≥ improved but under validation
   - Sub-claims can be assigned to context IDs that are not present in `analysisContexts`, indicating a pipeline coordination issue.
4. **Evidence clustering across contexts** ‚Äî ‚è≥ improved (frame signal + dedup fixes)
   - Evidence can cluster into a single context, leaving other contexts under-evidenced and lowering confidence.
5. **Verdict-stage resilience gaps** ‚Äî ‚è≥ improved
   - Intermittent provider/SDK failures can cause a job to fail even though fallback logic exists in other parts of the pipeline.

**Sampled metric (illustrative):** In a small sample (n=11) of extracted evidence items labeled `sourceAuthority="opinion"`, 10 were assigned `probativeValue="high"|"medium"` by the LLM (91% mismatch). This indicates deterministic correction is necessary; prompt tuning alone is insufficient.

**Example debug warning (generic):**

```
[YYYY-MM-DDTHH:MM:SSZ] ‚ö†Ô∏è Claim SC<N> assigned to non-existent context CTX_<id>
```

---

## Alignment With Repo Rules (Non‚ÄëNegotiable)

- **Generic-by-design**: No domain-specific heuristics or keyword lists; use structural signals (sourceAuthority, evidenceBasis, evidenceScope, jurisdictional standing).
- **Terminology**: Use **AnalysisContext** for top-level frames and **EvidenceScope** for per-evidence metadata.
- **EvidenceItems are not facts**: All extracted statements are unverified evidence until assessed.
- **Pipeline integrity**: Understand ‚Üí Research ‚Üí Verdict; do not skip gates.

---

## Deep Analysis of User's Core Principles

### Principle A: Government Opinions ‚â† Trustworthy Evidence

**User's insight** : "Opinions from Governments should never just be trusted without strong evidence (they could even cheat and manufacture 'evidence'), many governments are biased, quite some are autocratic or leaning autocratic."

**Generic abstraction** : ANY entity's OPINION about another entity is not evidence about that entity. This applies universally:

* Government A's opinion about Government B
* Company A's opinion about Company B
* Expert A's opinion about Study B
* Historian A's characterization of Event B

**Current system gap** : ~~The system has `sourceAuthority="opinion"` classification but doesn't ENFORCE that opinions cannot have high probativeValue.~~ ‚úÖ **RESOLVED** ‚Äî Deterministic `filterByProbativeValue()` now always runs; opinion sources filtered regardless of LLM classification.

**Solution** : Deterministic validation that DOWNGRADES opinion sources to low probativeValue, regardless of source prestige.

---

### Principle B: LLM Knowledge Has Cutoff Date

**User's insight** : "We should be aware and take measures of the situation that LLM's base only on past data maybe even with latest data from a year ago or so... they likely don't know that a current government cannot be trusted. And also in other situations they might just don't know - the LLM may not have information about recent verdicts or decisions."

**Generic abstraction** : LLMs don't know CURRENT REALITY (any events after their training data cutoff):

* Current government trustworthiness
* Recent verdicts/decisions
* Contemporary reputations
* Active/ongoing processes
* Latest organizational changes

**Current system gap** : ~~Verdict prompts don't acknowledge knowledge cutoff.~~ ‚úÖ **RESOLVED** ‚Äî Verdict prompt now includes knowledge cutoff awareness; `validateEvidenceRecency()` applies confidence penalty for time-sensitive claims without recent evidence.

**Solution** : Explicit knowledge cutoff awareness in prompts + confidence penalties for time-sensitive claims lacking recent evidence.

---

### Principle C: Evidence Must Come From Trusted Sources

**User's insight** : "Evidence source must always come from trusted sources and evidence with probativeValue=low should simply be discarded. Maybe we need to better define EvidenceItem, and better prompt the LLM to make sure EvidenceItem gets the appropriate values."

**Generic abstraction** : Evidence quality depends on DOCUMENTATION + SPECIFICITY + AUTHORITY, evaluated independently of whether it supports or contradicts the claim.

**Current system strengths** :

* Already has `sourceAuthority` (primary/secondary/opinion/contested)
* Already has `evidenceBasis` (scientific/documented/anecdotal/theoretical/pseudoscientific)
* Already has `probativeValue` (high/medium/low)
* Already filters low probativeValue items

**Current system gaps** : ‚úÖ **ALL RESOLVED**

1. ~~Prompt guidance doesn't emphasize opinion detection strongly enough~~ ‚Üí Opinion detection decision tree added
2. ~~No deterministic validation catches LLM classification errors~~ ‚Üí `filterByProbativeValue()` always runs
3. ~~Official/government sources can be opinion even if authoritative~~ ‚Üí Foreign-government political statements ‚Üí opinion rule added

**Solution** : Enhanced prompts with UNIVERSAL opinion detection rules + deterministic validation layer.

---

### Principle D: Web Search Provides Current Info BUT Results Need Evaluation

**User's insight** : "Web search must be used to enhance sight into the present."

**Generic abstraction** : Web search solves knowledge gap BUT search results are just TEXT that needs the SAME quality evaluation as any other source. Recency ‚â† reliability.

**Current system gap** : ~~Quality evaluation happens AFTER extraction, not during search result selection.~~ ‚úÖ **RESOLVED** ‚Äî Heuristic pre-filter (`checkSearchResultRelevance()`) + LLM relevance mode + context-aware criticism queries now filter BEFORE extraction. Adaptive fallback prevents over-filtering.

**Solution** : Relevance pre-filter BEFORE extraction + context-aware criticism queries.

---

## Implementation Notes (Aligned to Existing Pipeline Fields)

The plan should **reuse existing fields** and **avoid schema changes** unless absolutely necessary:

- `EvidenceItem.sourceAuthority` (primary/secondary/opinion/contested)
- `EvidenceItem.evidenceBasis` (scientific/documented/anecdotal/theoretical/pseudoscientific)
- `EvidenceItem.probativeValue` (high/medium/low)
- `EvidenceItem.claimDirection` (supports/contradicts/neutral)
- `EvidenceItem.evidenceScope` (per-evidence methodology/boundary metadata)
- `ClaimUnderstanding.thesisRelevance` (direct/tangential/irrelevant)

These are already used in:
- `apps/web/src/lib/analyzer/orchestrated.ts`
- `apps/web/src/lib/analyzer/evidence-filter.ts`
- `apps/web/src/lib/analyzer/aggregation.ts`

The enhancements below should **extend/strengthen** these, not replace them.

---

## Root Cause Analysis: The Generic Pattern

### What Happened

* **Query** : `[Entity] criticism concerns` (too broad)
* **Result** : External reactions/characterizations retrieved that are not about the process itself
* **Error** : Third-party opinion treated as evidence about the subject's procedural integrity/fairness
* **Impact** : Low-quality evidence contaminated analysis, reducing verdict accuracy

### Generic Pattern (Applies to ALL domains)

```
Subject being analyzed: Entity X in Context C
Irrelevant source retrieved: Entity Y's OPINION about Entity X
Error: Opinion treated as EVIDENCE

Examples across domains:
- Legal: Foreign government opinion on domestic trial ‚Üí NOT evidence of trial fairness
- Scientific: Industry association opinion on study ‚Üí NOT evidence of study validity
- Corporate: Competitor statement about rival ‚Üí NOT evidence of rival's conduct
- Historical: Modern historian's characterization ‚Üí NOT evidence of historical event
```

### Root Causes (Generic)

**Root Cause Group 1 - Opinion/Relevance Issues:**

1. **Search too broad** : No relevance filtering before extraction
2. **Opinion vs evidence confusion** : Characterizations treated as documented evidence
3. **Jurisdiction mismatch** : External actors' views on internal matters
4. **No standing check** : Third parties commenting without authority/relevance

**Root Cause Group 2 - Knowledge Gap Issues:**
5. **LLM knowledge cutoff not acknowledged** : System doesn't tell LLM "you don't know events after your training cutoff"
6. **No recency validation** : Time-sensitive claims not checked for recent evidence
7. **Training data treated as current** : LLM may use outdated "knowledge" about trustworthiness, status, etc.

---

## Web Search Architecture & Optimization Strategy

### Current Architecture

**CRITICAL**: FactHarbor uses **APPLICATION-controlled** web search, NOT LLM-invoked web search.

**Current flow:**
```
1. Application calls searchWebWithProvider() ‚Üí SerpAPI/Google CSE
2. Application fetches URL content from search results
3. Application passes fetched content to LLM for evidence extraction
4. LLM processes content without knowing it came from web search
```

**Key file:** [web-search.ts](apps/web/src/lib/web-search.ts) - Application directly controls search APIs

**Why this matters:** The LLM doesn't know it's getting web search results to fill its knowledge gaps. It treats all provided text equally, whether from web search or other sources.

---

### How Solutions Optimize Web Search to Extend LLM Knowledge

The 5 generic solutions work together to ensure web search effectively extends LLM knowledge:

| Solution | Optimization | Benefit |
|----------|--------------|---------|
| **Solution 4: Knowledge cutoff awareness** | Tell LLM about its knowledge gap in verdict prompt | LLM trusts web results over outdated training data for current claims |
| **Solution 5: Context-aware queries** | Build search queries with jurisdiction/context metadata | Returns relevant sources, filters out foreign/unrelated commentary |
| **Solution 1: Relevance pre-filter** | Filter search results BEFORE fetching URLs | Saves tokens, improves quality, prevents irrelevant source contamination |
| **Solution 4: Recency detection** | Apply date filters for time-sensitive claims | Gets current info (e.g., 2025-2026 sources) instead of outdated articles |
| **Solution 2: Opinion vs evidence** | Enhanced extraction prompt distinguishes opinion from evidence | LLM doesn't treat third-party commentary as documented facts |

**Optimization principle:** Control the entire pipeline (query ‚Üí filter ‚Üí extract) rather than letting LLM invoke web search autonomously.

---

### Why Application-Controlled Search is Better

**Advantages vs LLM-invoked web search:**
1. ‚úÖ Full control over query construction (context-aware, jurisdiction-scoped)
2. ‚úÖ Pre-filter results before extraction (relevance, jurisdiction match)
3. ‚úÖ URL deduplication across iterations (avoid re-fetching)
4. ‚úÖ Deterministic search behavior (reproducible results)
5. ‚úÖ Lower cost (no LLM deciding when to search)

**Disadvantages of LLM-invoked search:**
- ‚ùå Less control over query construction
- ‚ùå Cannot pre-filter results before LLM sees them
- ‚ùå No URL deduplication
- ‚ùå Higher cost (LLM autonomously decides when/what to search)
- ‚ùå Non-deterministic (different searches on different runs)

---

### Best Practices for Web Search Extending LLM Knowledge

**1. Knowledge Cutoff Awareness (Solution 4)**
- **Location:** Verdict prompt
- **Implementation:** Add `## KNOWLEDGE CUTOFF AWARENESS` section to verdict prompt
- **Benefit:** LLM knows to trust web evidence over training data for time-sensitive claims

**2. Context-Aware Query Construction (Solution 5)**
- **Location:** Search query generation ([orchestrated.ts:5975-5993](apps/web/src/lib/analyzer/orchestrated.ts#L5975))
- **Implementation:** Use AnalysisContext metadata (jurisdiction, institution) in queries
- **Benefit:** Returns relevant sources instead of broad/irrelevant results

**3. Relevance Pre-Filtering (Solution 1)**
- **Location:** Before URL fetch in research loop
- **Implementation:** Classify search results as "primary_source" | "secondary_commentary" | "unrelated"
- **Benefit:** LLM only processes high-quality, relevant sources

**4. Recency Detection (Solution 4)**
- **Location:** ClaimUnderstanding phase (temporal context detection)
- **Implementation:** Apply `dateRestrict` parameter to search API for time-sensitive claims
- **Benefit:** For "Is X currently trustworthy?", get 2025-2026 sources, not 2022-2023

**5. Opinion vs Evidence Distinction (Solution 2)**
- **Location:** Evidence extraction prompt
- **Implementation:** Add universal opinion detection decision tree
- **Benefit:** LLM doesn't conflate third-party characterizations with documented evidence

---

## Proposed Generic Solutions

### Solution 1: Contextual Relevance Pre-Filter ‚úÖ IMPLEMENTED

**Principle** : Verify source is DIRECTLY RELEVANT to the AnalysisContext BEFORE extracting evidence.

**Status:** Heuristic pre-filter (`checkSearchResultRelevance()`) + LLM classification (`searchRelevanceLlmMode: auto`) + adaptive fallback implemented in `orchestrated.ts`.

**Current flow** (wasteful):

```
Search ‚Üí Fetch ALL ‚Üí Extract evidence ‚Üí Filter low quality
```

**New flow** (efficient):

```
Search ‚Üí Relevance pre-filter ‚Üí Fetch relevant only ‚Üí Extract ‚Üí Quality filter
```

**Implementation** :

* **File** : `apps/web/src/lib/analyzer/orchestrated.ts` around lines 10698-10906
* **Add** : `filterSearchResultsByRelevance()` function
* **Logic** : Classify each result as "primary_source" | "secondary_commentary" | "unrelated"
* **Keep** : Only "primary_source" results

**Classification criteria** (universal):

1. **Subject match** : Is this about the SAME subject as AnalysisContext?
2. **Direct vs indirect** : PRIMARY information or COMMENTARY about information?
3. **Jurisdiction match** : Appropriate authority/standing for this context?

**Examples** :


| Domain     | Context           | PRIMARY (keep)      | COMMENTARY (reject)                  |
| ------------ | ------------------- | --------------------- | -------------------------------------- |
| Legal      | Domestic trial   | Court docs, filings | Foreign State Dept opinion                |
| Scientific | Tech A efficiency | Studies measuring A | Industry statements about studies    |
| Corporate  | Company X fraud   | Regulator filings, audits | Competitor statements                |
| Historical | Event X           | Contemporary docs   | Modern historians' characterizations |

---

### Solution 2: Enhanced Opinion vs Evidence Distinction ‚úÖ IMPLEMENTED

**Principle** : Strengthen prompts to ALWAYS distinguish opinion from documented evidence, regardless of source credibility.

**Status:** Opinion detection decision tree added to `extract-evidence-base.ts`. Foreign-government political statements ‚Üí opinion classification rule added.

**Problem** : Government/official sources can be opinion even if authoritative. "Government official states X" is OPINION unless citing specific documentation.

**Implementation** :

* **File** : `apps/web/src/lib/analyzer/prompts/base/extract-evidence-base.ts` lines 120-141
* **Change** : Replace SOURCE AUTHORITY section with enhanced version
* **Add** : Universal opinion detection decision tree

**Universal opinion detection rules** :

An item is OPINION (not documented evidence) if:

1. Characterizes/evaluates without providing measurements or records
2. States a position/stance without citing specific documentation
3. Makes claims without verifiable supporting data
4. Provides interpretation rather than observation

**Decision tree** :

```
1. Does source CITE specific records/measurements/data?
   YES ‚Üí Check if primary or secondary
   NO ‚Üí Likely OPINION

2. Is this CHARACTERIZATION (good/bad/fair) or MEASUREMENT (X units, Y count)?
   Characterization ‚Üí OPINION unless backed by documented evidence
   Measurement ‚Üí PRIMARY if original, SECONDARY if reported

3. For government/official sources:
   Policy statement/position = OPINION
   Statistical report with methodology = PRIMARY
   Press release claim = OPINION unless cites specific data
```

**Examples** (pattern recognition):

PRIMARY (documented):

* "Audit found 12 violations in records dated 2020-03-15"
* "Study measured 45% efficiency using Standard Protocol Y"
* "Court ruling Case-2023-456 states [legal text]"

OPINION (not documented):

* "Government official states process was appropriate"
* "Agency announces new policy position"
* "Department claims standards were met"
* "Report concludes X is justified" (check if based on documented findings)

---

### Solution 3: Probative Value Validation Layer ‚úÖ IMPLEMENTED

**Principle** : Add deterministic enforcement that prevents non-evidentiary material from influencing verdicts, even when upstream LLM steps mis-classify quality fields.

**Status:** Deterministic `filterByProbativeValue()` always runs. Opinion sources filtered. Dedup threshold configurable via UCM (`probativeDeduplicationThreshold`).

**Validated by data (sampled):** In a small sample (n=11) of evidence items labeled `sourceAuthority="opinion"`, 10 were incorrectly assigned `probativeValue="high"|"medium"` by the LLM (91% mismatch).

**Critical implementation alignment (P0):**
Today, when `llmEvidenceQuality` is enabled, the pipeline can accept the LLM quality filter result and skip the deterministic `filterByProbativeValue()` gate. This defeats the intended two-layer enforcement.

**Implementation (deterministic, generic):**

- **File** : `apps/web/src/lib/analyzer/orchestrated.ts`
  - Always run deterministic `filterByProbativeValue()` on the final kept evidence items (whether or not an LLM pre-filter ran).
- **File** : `apps/web/src/lib/analyzer/evidence-filter.ts`
  - Add a rule that **filters any evidence item with `sourceAuthority="opinion"`**, regardless of `probativeValue`.

**Why this is generic and unbiased:** It does not special-case any government/organization/person. It enforces the semantic contract already present in our fields: items labeled as opinion are not treated as probative evidence for claim verification.

**Deterministic enforcement rule (minimum viable):**

```text
IF sourceAuthority = "opinion" THEN discard evidence item (reason: opinion_source)
```

Optional follow-ups (still generic, but lower priority than the P0 rule above):
- Cap `"high" ‚Üí "medium"` when `sourceAuthority="contested"` or `evidenceBasis` is non-empirical.
- Add correction telemetry (counts by rule) for monitoring without relying on lexical keyword lists.

---

### Solution 4: LLM Knowledge Gap Handling (CRITICAL - Problem 2) ‚úÖ IMPLEMENTED

**Principle** : When LLM lacks current knowledge, REQUIRE web search evidence and FLAG uncertainty.

**Status:** Verdict prompt refined with knowledge cutoff awareness. `validateEvidenceRecency()` wired with UCM-configurable window. Prompt now allows directional verdicts from documented evidence (no longer forces MIXED/UNVERIFIED). Integration validation pending.

**Problem - LLMs Don't Know The Present**:

LLMs are trained on historical data with a specific knowledge cutoff date and have ZERO knowledge of:

- **Current events** (anything after training cutoff)
- **Current government/organizational trustworthiness** (may have changed since training)
- **Recent verdicts, decisions, policy changes** (LLM doesn't know they happened)
- **Contemporary reputations** (organizations/people's standing may have changed)
- **Ongoing proceedings/processes** (LLM can't know current status)

**Why this is dangerous**: The LLM may confidently make claims based on outdated training data (e.g., "Organization X is trustworthy" based on old data, when X's situation changed recently). Without explicit knowledge cutoff awareness, the system treats LLM-generated reasoning as if it knows current reality.

**Critical insight**: Web search SOLVES the knowledge gap by providing current information, BUT search results themselves still need quality evaluation (Solution 1-3). Recency ‚â† reliability.

**Implementation** :

* **File 1** : `apps/web/src/lib/analyzer/prompts/base/verdict-base.ts` - Add knowledge cutoff section
* **File 2** : `apps/web/src/lib/analyzer/orchestrated.ts` - Add `validateEvidenceRecency()` function

**Additions to verdict prompt** :

**Implementation Note:** The `${llmKnowledgeCutoff}` variable should be obtained dynamically:
- For Anthropic models: Check the model's system prompt or metadata for "knowledge cutoff" information
- If unavailable: Use model release date minus 3-6 months as approximation
- Store in configuration or retrieve at runtime from model metadata

```
## KNOWLEDGE CUTOFF AWARENESS

Today is ${currentDate}.
Your training data cutoff is: ${llmKnowledgeCutoff} (obtain from your system context/prompt).

For claims requiring knowledge of current reality (after ${llmKnowledgeCutoff}):
- You CANNOT know: Current government policies, recent verdicts, contemporary reputations
- You MUST rely ONLY on provided evidence from web search
- If evidence is dated before ${llmKnowledgeCutoff}, it may be outdated for time-sensitive claims

Time-sensitive claim types:
- Current status/state: "X is currently Y"
- Recent events: "X happened in [recent date]"
- Contemporary reputation: "X is known for Y"
- Active processes: "X is ongoing"

Confidence impact:
- Time-sensitive claim WITHOUT recent evidence ‚Üí Reduce confidence by 20%
- Claim about current trustworthiness ‚Üí Require web evidence from recent months/year
- Historical claim (before ${llmKnowledgeCutoff}) ‚Üí Training data may be relevant

Flag: "[KNOWLEDGE GAP] This claim requires current information (after ${llmKnowledgeCutoff}). Evidence may be incomplete."
```

**Recency validation function** :

* Detect time-sensitive patterns: "currently", "now", "recent", "ongoing", "is [state]"
* Check if evidence dates fall within relevant timeframe for the claim
* Apply confidence penalty if no recent evidence for time-sensitive claims

**Universal application** :

* Legal: "Trial was unfair" (recent) ‚Üí Requires evidence from relevant time period
* Scientific: "Technology A is more efficient" (current) ‚Üí Requires recent studies
* Political: "Government X is trustworthy" (current) ‚Üí CANNOT use LLM knowledge
* Corporate: "Company X has good safety record" (current) ‚Üí Requires recent audits

---

### Solution 5: Context-Aware Criticism Search ‚úÖ IMPLEMENTED

**Principle** : Make criticism queries CONTEXT-AWARE to prevent importing irrelevant third-party opinions.

**Status:** `buildContextAwareCriticismQueries()` iterates ALL contexts (not just first). Deduplicates by jurisdiction/institution pair.

**Current query** (too broad):

```typescript
`${entityStr} criticism concerns`
```

Returns ANY criticism, including foreign/unrelated actors.

**Implementation** :

* **File** : `apps/web/src/lib/analyzer/orchestrated.ts` lines 5975-5993
* **Replace** : `baseQueries` generation with `buildContextAwareCriticismQueries()`
* **Add** : Function that uses AnalysisContext metadata (jurisdiction, institution)

**New query logic** :

```typescript
function buildContextAwareCriticismQueries(
  entityStr: string,
  contexts: AnalysisContext[],
  impliedClaim: string
): string[] {
  // Extract jurisdiction/institution from contexts
  const jurisdiction = ctx.metadata.jurisdiction || ctx.metadata.geographic || "";
  const institution = ctx.metadata.institution || "";

    if (jurisdiction || institution) {
    // CONTEXT-BOUND criticism (only relevant actors)
    return [
      `${entityStr} ${jurisdiction} ${institution} criticism internal review`,
      `${entityStr} ${jurisdiction} appeals challenges objections`
    ];
  } else {
    // Generic but focused on DIRECT criticism
    return [
      `${entityStr} criticism documented evidence`,
      `${entityStr} challenges objections filed`
    ];
  }
}
```

**Examples** :


| Domain                       | Context                                          | Query                                                    |
| ------------------------------ | -------------------------------------------------- | ---------------------------------------------------------- |
| Legal (Domestic trial)      | `{ jurisdiction: "Country A", institution: "Court X" }` | "[Entity] Country A Court X criticism internal review"         |
| Scientific (Tech comparison) | `{ methodology: "Method Y", geographic: "Region Z" }`       | "technology A Method Y Region Z criticism documented evidence" |
| Corporate (Company fraud)    | `{ jurisdiction: "Regulator B" }`                     | "Company X Regulator B criticism internal review"             |

**Result** : Only relevant actors' criticisms, not foreign/third-party opinions.

---

## Implementation Plan

### Phase 0: Ground Truth + Instrumentation (NEW)

**Goal:** Ensure report issues are reproducible with clear artifacts.

1. **Capture artifacts per failing job**
   - Save `resultJson` + `reportMarkdown` and record Job ID.
   - Capture `JobEvents` (including stack traces for failures) for deterministic debugging.
2. **Add a minimal ‚Äúevidence quality snapshot‚Äù block** in reports (optional but recommended)
   - Count of opinion/secondary sources used
   - Count of `probativeValue=high` items from `sourceAuthority=opinion`
3. **Add failure observability + safe retries (P0 resilience)**
   - Persist stack traces for runner failures (so `"reading 'value'"`-type errors are actionable).
   - Add a one-time retry around verdict generation on internal errors (prevents rare transient failures from aborting the job).

This phase is light and does **not require schema changes**.

### Phase 1: Immediate Impact (Prevent Contamination) ‚úÖ COMPLETE

**Priority** : HIGH
**Duration** : 2 days
**Status** : ‚úÖ **VERIFIED COMPLETE** (2026-02-06)
**Verification** : See [Evidence_Quality_Verification_Report.md](Evidence_Quality_Verification_Report.md)

**Results:**
| Metric | Before | After |
|--------|--------|-------|
| Opinion sources in evidence | 11 (91% elevated) | 0 |
| Test analyses verified | - | 4 (procedural fairness, public health safety, technology efficiency, multilingual) |

1. **Solution 2: Enhanced opinion detection** ‚úÖ
   * [x] Update `apps/web/src/lib/analyzer/prompts/base/extract-evidence-base.ts` to enforce: opinion ‚Üí `probativeValue="low"` ‚Üí omit
   * [x] Add generic guidance to omit third-party reactions/characterizations without documentary support
   * [x] Add universal opinion detection decision tree (in extract-evidence-base.ts)
   * [x] Add generic examples for government/official sources (in extract-evidence-base.ts)

2. **Solution 3: Probative value validation** ‚úÖ
   * [x] Ensure deterministic `filterByProbativeValue()` runs even when the LLM evidence-quality filter succeeds (`apps/web/src/lib/analyzer/orchestrated.ts`)
   * [x] Filter out `sourceAuthority="opinion"` deterministically (`apps/web/src/lib/analyzer/evidence-filter.ts` lines 199-203)
   * [x] Add additional deterministic rules (vague-phrase cap, attribution/citation requirements) to prevent low-probative items slipping through
   * [x] Filter stats returned in `FilterStats.filterReasons` (available for logging)

**Achieved impact** : Opinion contamination eliminated (verified via database checks on 4 test analyses).

---

### Phase 2: Search Quality (Reduce Noise) ‚ö†Ô∏è IMPLEMENTED, VERIFICATION RE-OPENED

**Priority** : HIGH
**Duration** : 3 days
**Status** : ‚ö†Ô∏è **IMPLEMENTED; STABILIZATION/RE-VALIDATION IN PROGRESS**
**Depends On** : Phase 1 complete ‚úÖ

---

#### Task 2.1: Context-Aware Criticism Queries (Solution 5)

**Problem:** Generic criticism queries like `"${entityStr} criticism"` return irrelevant third-party reactions from unrelated jurisdictions/domains.

**Example:** Procedural fairness analysis returned foreign executive orders as "criticism evidence".

**Implementation:**

**File:** `apps/web/src/lib/analyzer/orchestrated.ts`
**Location:** Lines 5975-5993 (search for `"Criticism and opposing views"`)

**Step 1:** Add helper function (insert before `decideNextResearch`):

```typescript
/**
 * Build context-aware criticism queries that focus on relevant actors/jurisdictions.
 * Prevents foreign/unrelated third-party reactions from contaminating evidence.
 */
function buildContextAwareCriticismQueries(
  entityStr: string,
  contexts: AnalysisContext[],
  currentYear: number
): string[] {
  // Extract jurisdiction/institution from first context with metadata
  const ctx = contexts.find(c => c.metadata?.jurisdiction || c.metadata?.institution);
  const jurisdiction = ctx?.metadata?.jurisdiction || ctx?.metadata?.geographic || "";
  const institution = ctx?.metadata?.institution || "";

  if (jurisdiction || institution) {
    // CONTEXT-BOUND criticism (only relevant actors)
    return [
      `${entityStr} ${jurisdiction} ${institution} criticism official review`,
      `${entityStr} ${jurisdiction} appeals challenges objections ${currentYear}`,
      `${entityStr} ${institution} internal review findings`,
    ];
  } else {
    // Generic but focused on DIRECT criticism (not third-party reactions)
    return [
      `${entityStr} criticism documented evidence ${currentYear}`,
      `${entityStr} official response challenges`,
    ];
  }
}
```

**Step 2:** Update criticism query generation (modify lines ~5980-5984):

```typescript
// BEFORE:
const queries = recencyMatters ? [
  ...baseQueries,
  `${entityStr} criticism ${currentYear}`,
] : baseQueries;

// AFTER:
const contextAwareQueries = buildContextAwareCriticismQueries(
  entityStr,
  analysisContexts,  // pass from outer scope
  currentYear
);
const queries = recencyMatters
  ? [...baseQueries, ...contextAwareQueries]
  : [...baseQueries, ...contextAwareQueries.slice(0, 2)];
```

**Verification:**
- [ ] Run procedural fairness analysis for a domestic proceeding ‚Üí should NOT return foreign government documents
- [ ] Run public health safety analysis ‚Üí should return scientific criticism, not political statements
- [ ] Check `debug-analyzer.log` for generated queries

**Effort:** 2 hours

---

#### Task 2.2: Relevance Pre-Filter (Solution 1 - Heuristic)

**Problem:** Search results include obviously irrelevant sources that waste extraction tokens.

**Implementation:**

**File:** `apps/web/src/lib/analyzer/orchestrated.ts`
**Location:** After search results are fetched, before `extractEvidence()` call

**Step 1:** Add relevance heuristic function (token‚Äëbased, conservative):

- Tokenize with stopword filtering and plural‚Äëtolerant matching
- Use **subject-first** context tokens (fallback to assessedStatement/name only if subject missing)
- Require stronger matches when entity tokens include specific (long) identifiers

```typescript
interface RelevanceCheck {
  isRelevant: boolean;
  reason?: string;
}

/**
 * Quick heuristic check for obvious irrelevance.
 * Does NOT replace LLM extraction - just filters obvious noise.
 */
function checkSearchResultRelevance(
  result: SearchResult,
  entityStr: string,
  contexts: AnalysisContext[]
): RelevanceCheck {
  const title = (result.title || "").toLowerCase();
  const snippet = (result.snippet || "").toLowerCase();
  const url = (result.url || "").toLowerCase();

  // Tokenize ONLY core context fields (subject/name/assessedStatement)
  // Exclude broad geography/jurisdiction to avoid false positives.
  const entityTokens = tokenizeForMatch(entityStr, 3);
  const contextTokens = extractContextTokens(contexts); // subject-first; fallback only if subject missing
  const institutionTokens = extractInstitutionTokens(contexts); // institution/court/regulatoryBody

  const entityMatches = countTokenMatches(`${title} ${snippet}`, url, entityTokens);
  const contextMatches = countTokenMatches(`${title} ${snippet}`, url, contextTokens);
  const contextMin = contextTokens.length >= 4 ? 2 : 1;

  if (institutionTokens.length > 0) {
    const institutionMatches = countMatches(title, snippet, url, institutionTokens);
    if (institutionMatches === 0 && !(entityMatches > 0 && contextMatches >= contextMin)) {
      return { isRelevant: false, reason: "insufficient_context_match" };
    }
  }

  if (entityMatches > 0 || contextMatches >= contextMin) {
    return { isRelevant: true };
  }

  if (entityTokens.length === 0 && contextTokens.length === 0) {
    return { isRelevant: true };
  }

  return { isRelevant: false, reason: "entity_or_context_not_mentioned" };
}
```

**Step 2:** Apply filter before extraction (in research loop):

```typescript
// After fetching search results, before extraction:
const relevantResults = searchResults.filter(result => {
  const check = checkSearchResultRelevance(result, entityStr, analysisContexts);
  if (!check.isRelevant) {
    debugLog("Pre-filter rejected", { url: result.url, reason: check.reason });
  }
  return check.isRelevant;
});

// Use relevantResults for extraction instead of searchResults
```

**Verification:**
- [ ] Check `debug-analyzer.log` for "Pre-filter rejected" entries
- [ ] Verify relevant sources are NOT filtered (no false positives)
- [ ] Monitor extraction token usage (should decrease)

**Effort:** 3 hours

---

#### Task 2.3: Add Filter Telemetry (Minor)

**Problem:** No visibility into how often each filter rule triggers.

**File:** `apps/web/src/lib/analyzer/orchestrated.ts`
**Location:** After `filterByProbativeValue()` call

```typescript
// After filtering
const { kept, filtered, stats } = filterByProbativeValue(evidenceItems);

// Log filter stats for monitoring
debugLog("Evidence filter stats", {
  total: stats.total,
  kept: stats.kept,
  filtered: stats.filtered,
  reasons: stats.filterReasons,
});

// Include in result metadata (optional)
if (result.meta) {
  result.meta.filterStats = stats.filterReasons;
}
```

**Effort:** 30 minutes

---

**Phase 2 Checklist:**
- [x] Task 2.1: Context-aware criticism queries
- [x] Task 2.2: Relevance pre-filter (heuristic)
- [x] Task 2.3: Filter telemetry logging
- [x] UCM support for relevance mode (`off|auto|on`) with default `auto`
- [ ] Repeated-run stability validation on sensitive claims (orchestrated + dynamic)
- [ ] False-positive audit (<5% valid evidence filtered)
- [ ] Context recall audit (multi-context legal/procedural claims)

**Expected impact** : Reduces irrelevant search results and improves evidence quality, while preserving context coverage.

---

### Phase 3: Advanced Filtering (Complete Solution) ‚è≥ IN PROGRESS

**Priority** : MEDIUM
**Duration** : 4 days
**Status** : ‚è≥ **IN PROGRESS** (partial implementation complete; integration validation pending)
**Depends On** : Phase 2 stabilization

---

#### Task 3.1: LLM Knowledge Gap Handling (Solution 4)

**Problem:** LLMs have a knowledge cutoff date and cannot know current reality (recent verdicts, current government status, ongoing events).

**Implementation:**

**File:** `apps/web/src/lib/analyzer/prompts/base/verdict-base.ts`

Add knowledge cutoff awareness section:
```markdown
## KNOWLEDGE CUTOFF AWARENESS

Your training data has a cutoff date. For time-sensitive claims:
- If claim requires CURRENT knowledge (e.g., "is X currently..."):
  - You MUST have recent web evidence (within 6 months)
  - If no recent evidence: FLAG uncertainty, REDUCE confidence by 20%
- If claim is historical (e.g., "did X happen in 2020"):
  - Historical evidence is acceptable
```

**File:** `apps/web/src/lib/analyzer/orchestrated.ts`

Add recency validation:
```typescript
function validateEvidenceRecency(
  evidence: EvidenceItem[],
  claimIsTimeSensitive: boolean,
  currentDate: Date
): { hasRecentEvidence: boolean; oldestDate?: Date; penalty: number } {
  if (!claimIsTimeSensitive) return { hasRecentEvidence: true, penalty: 0 };

  const sixMonthsAgo = new Date(currentDate);
  sixMonthsAgo.setMonth(sixMonthsAgo.getMonth() - 6);

  const recentEvidence = evidence.filter(e =>
    e.sourceDate && new Date(e.sourceDate) >= sixMonthsAgo
  );

  return {
    hasRecentEvidence: recentEvidence.length > 0,
    penalty: recentEvidence.length === 0 ? 0.20 : 0,
  };
}
```

**Effort:** 4 hours

---

#### Task 3.2: LLM-Based Relevance Classification (Solution 1 - Complete)

**Problem:** Heuristic pre-filter may miss subtle irrelevance patterns.

**Implementation:** Add optional LLM classification step for edge cases where heuristics are uncertain, with off/auto/on modes (default auto via pipeline config).

```typescript
type RelevanceClass = "primary_source" | "secondary_commentary" | "unrelated";

async function classifySearchResultRelevance(
  result: SearchResult,
  claimContext: string,
  llmClient: LLMClient
): Promise<RelevanceClass> {
  // Only call LLM for ambiguous cases (heuristic uncertain)
  // ...
}
```

**Effort:** 4 hours

---

**Phase 3 Checklist:**
- [x] Task 3.1: Knowledge gap handling in verdict prompt
- [x] Task 3.1: Evidence recency validation function
- [x] Task 3.1: Confidence penalty for time-sensitive claims without recent evidence
- [x] Task 3.2: LLM-based relevance classification (optional enhancement, off/auto/on)
- [ ] Integration testing with time-sensitive claims

**Expected impact** : Handles time-sensitive claims correctly, completes relevance filtering.

---

## Verification Strategy

### Generic Test Cases (Cross-Domain)

**Test 1: Legal Domain (Foreign opinion contamination)**

* Input: "Was [domestic legal proceeding in Country A] fair?"
* Expected: REJECT foreign government opinions about Country A's proceedings
* Expected: ACCEPT Country A court documents, appeals, legal analysis
* Verify: No foreign political opinions in evidence

**Test 2: Scientific Domain**

* Input: "Is electric vehicle technology A more efficient than B?"
* Expected: REJECT industry association position statements
* Expected: ACCEPT peer-reviewed studies with measurements
* Verify: No advocacy materials treated as evidence

**Test 3: Corporate Domain**

* Input: "Did Company X commit fraud?"
* Expected: REJECT competitor statements about Company X
* Expected: ACCEPT regulatory filings, audit reports, whistleblower docs
* Verify: No third-party characterizations as high probativeValue

**Test 4: Historical Domain**

* Input: "Did Event X occur in Year Y?"
* Expected: ACCEPT contemporary documents from Year Y
* Expected: REJECT modern historians' characterizations without citing primary sources
* Verify: Primary sources prioritized

**Test 5: Time-Sensitive Knowledge Gap**

* Input: "Is Government X currently trustworthy?"
* Expected: FLAG knowledge gap (requires current information after training cutoff)
* Expected: REQUIRE recent web evidence (current year)
* Expected: REDUCE confidence if no recent evidence
* Verify: Warning shown to user

---

## Minimal Repro Protocol (for reviewers)

1. **Run an analysis** using a time-sensitive, procedural fairness input.
2. **Collect artifacts**:
   - `resultJson` and `reportMarkdown` from `Jobs` table.
   - `JobEvents` stream/table (includes error stack traces on failure).
   - `apps/web/debug-analyzer.log` tail.
3. **Check three red flags**:
   - Opinion/response sources labeled `probativeValue=high`.
   - Criticism sources from unrelated jurisdictions or actors.
   - Context duplication (multiple contexts with same institution/subject).

This protocol is designed to be domain‚Äëagnostic and repeatable.

---

## Success Metrics

**Baseline measurements from database analysis (2026-02-05):**

| Metric                                          | Baseline (Measured) | Target | Current (2026-02-07) | Status |
| ------------------------------------------------- | ------------------- | -------- | -------------------- | ------ |
| Opinion evidence items extracted with high/medium probativeValue | **91%** (10/11) | 0% | **0%** | ‚úÖ ACHIEVED |
| Opinion evidence items present after deterministic filtering     | **Present**     | 0% | **0** | ‚úÖ ACHIEVED |
| Irrelevant search results fetched               | ~40%                | <10%   | Improving (adaptive fallback + context-aware queries); requires 50-run measurement | ‚è≥ RE-MEASURE |
| Time-sensitive claims with old evidence flagged | 0%                  | 100%   | Verdict prompt refined; full metric pending | ‚è≥ PENDING |
| Evidence contamination rate (opinion/third-party commentary influencing verdicts) | **Present** | 0% | **0%** | ‚úÖ ACHIEVED |
| Sensitive-claim verdict variance across repeated runs            | High | ‚â§15 pts (legal), ‚â§10 pts (factual) | Improved (75% in some runs); 50-run suite pending | ‚è≥ VALIDATE |
| Verdict accuracy (Bolsonaro case: expected ~73%)                | **39%** | ~73% | Fixes applied (anchoring + weights + prompt); awaiting live validation | ‚è≥ VALIDATE |
| Multi-context recall for legal/procedural claims                | Inconsistent | ‚â•80% (4/5 runs) | Improved (2-3 contexts in some runs); 50-run suite pending | ‚è≥ VALIDATE |
| Verdict confidence stability (5 runs, same claim)               | Not measured | ‚â§15 pp | Not yet measured | ‚è≥ VALIDATE |
| Job failures due to intermittent provider/SDK errors            | **Present** (rare) | <1% | Improved, final verification pending | ‚è≥ VERIFY |

**Phase 1 Verification (2026-02-06):**
- Public health safety analysis: 19 primary, 3 secondary, **0 opinion** ‚úÖ
- Procedural fairness analysis (EN): 11 primary, 5 secondary, **0 opinion** ‚úÖ
- Procedural fairness analysis (non‚ÄëEN): 1 primary, **0 opinion** ‚úÖ (correctly low confidence)
- Technology efficiency analysis: 33 primary, 8 secondary, **0 opinion** ‚úÖ

**Key insight from baseline:** The 91% error rate for opinion sources (10/11 incorrectly elevated) was a systematic issue requiring deterministic correction. **Phase 1 resolved this completely.**

---

## Risk Assessment


| Risk                          | Probability | Impact | Mitigation                                                  |
| ------------------------------- | ------------- | -------- | ------------------------------------------------------------- |
| Over-filtering valid evidence | MEDIUM      | HIGH   | Extensive cross-domain testing, log all filtering decisions |
| LLM classification errors     | MEDIUM      | MEDIUM | Deterministic validation catches errors                     |
| Performance degradation       | LOW         | MEDIUM | Pre-filter reduces fetch/extract, net improvement expected  |
| Breaking existing analyses    | LOW         | HIGH   | Feature flags for gradual rollout, A/B testing              |

---

## Rollout Plan

**Current state:** All solutions deployed to main branch. UCM tunables allow per-environment adjustment without code changes.

1. **UCM config reseed** ‚Äî Verify running app picks up new config fields from `pipeline.default.json`
2. **50-run validation suite** ‚Äî 5 claims √ó 5 runs √ó 2 pipelines against closure criteria
3. **Article-mode input test** ‚Äî Verify "Coffee cures cancer" pattern still triggers proportional blending
4. **If closure criteria pass** ‚Üí Mark Phases 2+3 complete, plan CLOSED
5. **If variance > targets** ‚Üí Escalate to WEEK 2 remediation (test Opus for verdict, tune UCM values)
6. **UCM controls for rollback** ‚Äî All 5 new tunables can disable/adjust behavior without code changes:
   - `searchRelevanceLlmMode: off` disables LLM relevance filtering
   - `searchAdaptiveFallbackMinCandidates: 0` disables adaptive fallback
   - `contextClaimsAnchorDivergenceThreshold: 50` effectively disables anchoring
   - `probativeDeduplicationThreshold: 0.95` restores conservative dedup

---

## Files Modified

| File | Changes | Status |
|------|---------|--------|
| `apps/web/src/lib/analyzer/orchestrated.ts` | Frame signal gate, dedup protection, multi-context queries, auto LLM relevance, context-claims anchoring (`anchorVerdictTowardClaims()` helper), Article VP Override, source-dedup direction validation, adaptive fallback, **CalcConfig wiring** (contestation penalties, truthFromBand derived from bands, correction caps, claim decomposition, context similarity, tangential pruning, claim clustering, evidence filter, dedup threshold, aggregation weights, gate config pass-through) | ‚úÖ |
| `apps/web/src/lib/analyzer/aggregation.ts` | Contested factor weights: 0.3‚Üí0.5 (established), 0.5‚Üí0.7 (disputed); **CalcConfig wiring** (AggregationWeights interface, optional weights param on `getClaimWeight` + `calculateWeightedVerdictAverage`) | ‚úÖ |
| `apps/web/src/lib/analyzer/quality-gates.ts` | **CalcConfig wiring** (QualityGateConfig interface, optional gateConfig param on all gate functions, configurable thresholds for Gate 1 + Gate 4) | ‚úÖ |
| `apps/web/src/lib/analyzer/truth-scale.ts` | **CalcConfig wiring** (VerdictBandConfig interface, truthFromBand derived from bands, optional bands param on verdict/color functions, configurable mixedConfidenceThreshold) | ‚úÖ |
| `apps/web/src/lib/analyzer/source-reliability.ts` | **CalcConfig wiring** (optional bands param on `scoreToCredibilityLevel`) | ‚úÖ |
| `apps/web/src/lib/analyzer/verdict-corrections.ts` | **CalcConfig wiring** (optional verdictBands param on `detectCounterClaim`, configurable LEANING_TRUE/MIXED thresholds) | ‚úÖ |
| `apps/web/src/lib/analyzer/evidence-filter.ts` | Deterministic opinion filtering, dedup threshold 0.85‚Üí0.75, **CalcConfig wiring** (ProbativeFilterConfig pass-through) | ‚úÖ |
| `apps/web/src/lib/analyzer/prompts/base/verdict-base.ts` | Knowledge cutoff awareness, evidence quality expansion, authority/probative-first weighting, institutional majority/dissent | ‚úÖ |
| `apps/web/src/lib/analyzer/prompts/base/extract-evidence-base.ts` | Opinion detection decision tree, foreign-government political statements ‚Üí opinion | ‚úÖ |
| `apps/web/src/lib/analyzer/llm.ts` | context_refinement ‚Üí modelVerdict, defaultModelNameForTask premium fallback | ‚úÖ |
| `apps/web/src/lib/analyzer/model-tiering.ts` | Haiku 3.0‚Üí3.5, cost update, context_refinement ‚Üí premium strengths | ‚úÖ |
| `apps/web/src/lib/config-schemas.ts` | +5 PipelineConfig tunables, ‚àí1 dead field; **+6 new CalcConfig sections** (evidenceFilter, articleVerdictOverride, claimDecomposition, contextSimilarity, tangentialPruning, claimClustering), CalcConfig defaults updated to match runtime (contestationWeights 0.5/0.7) | ‚úÖ |
| `apps/web/configs/pipeline.default.json` | llmTiering=true, +5 UCM defaults, ‚àí1 dead field | ‚úÖ |
| `apps/web/test/unit/lib/analyzer/aggregation.test.ts` | Updated expectations for new contested weights | ‚úÖ |
| `apps/web/test/unit/lib/analyzer/v2.8-verification.test.ts` | Updated stale assertion (0.3‚Üí0.5 for established contested weight) | ‚úÖ |

---

## Dependencies

* No external dependencies
* No database migrations needed
* PipelineConfig extended with 5 new optional fields (backward compatible; defaults match original hardcoded values)
* CalcConfig extended with 6 new optional sections (68 total fields across 13 sections; all backward compatible)
* `searchRelevanceLlmEnabled` removed from schema (replaced by `searchRelevanceLlmMode` in earlier work)
* Both PipelineConfig and CalcConfig need reseed in running app for new fields to take effect

---

## Open Questions ‚Äî RESOLVED

1. **Relevance pre-filter approach?** ‚Üí **DECIDED: Heuristics first** (Phase 2), LLM fallback in auto mode (Phase 3). Both implemented.
2. **Confidence penalty for knowledge gap?** ‚Üí **DECIDED: 20%**, UCM-configurable via `recencyConfidencePenalty`. Implemented.
3. **Add third-party commentary flag?** ‚Üí **DECIDED: DEFERRED.** Solution 3's deterministic rules address the immediate problem.
4. **Handle no relevant criticism?** ‚Üí **DECIDED: Log and proceed.** "No relevant criticism found" logged; no fabricated counter-evidence.
5. **Context deduplication strengthening?** ‚Üí **DECIDED: OUT OF SCOPE.** Addressed separately in Pipeline Phase 2.

---

## Review Checklist

### Design Review

- [x] Solutions are **truly generic** (not case-specific to any single incident or report)
- [x] Solutions apply universally across domains (legal, scientific, corporate, historical)
- [x] No bias toward or against any specific government, organization, or entity
- [x] Root cause analysis is accurate and complete (7 root causes identified and fixed)
- [x] Proposed solutions address root causes (not symptoms)

### Technical Review

- [x] Implementation plan is feasible and well-sequenced
- [x] All 5 solutions implemented in code
- [x] No conflicts with existing Pipeline Improvement Plan
- [x] No schema changes required (uses existing fields + UCM config extension)
- [x] Backward compatibility maintained (UCM defaults match original hardcoded values)

### Testing & Validation

- [x] Cross-domain test cases are comprehensive (5 domains)
- [x] Success metrics are measurable and appropriate (10 metrics with baselines)
- [x] Risk assessment covers major concerns
- [ ] **50-run validation suite** ‚Äî PENDING (blocking plan closure)

### Open Questions Resolution

- [x] Q1: Heuristics first, LLM fallback auto mode ‚Äî IMPLEMENTED
- [x] Q2: 20% confidence penalty ‚Äî IMPLEMENTED, UCM-configurable
- [x] Q3: Third-party commentary flag ‚Äî DEFERRED (not blocking)
- [x] Q4: Log and proceed when no criticism ‚Äî IMPLEMENTED
- [x] Q5: Context dedup ‚Äî OUT OF SCOPE

---

## Approval Decision

**Status:** ‚ö†Ô∏è **APPROVED WITH CHANGES**

**Options:**

- ‚úÖ **APPROVED** - Proceed with implementation as specified
- ‚ö†Ô∏è **APPROVED WITH CHANGES** - Proceed after addressing specific concerns (list below)
- ‚ùå **REJECTED** - Major redesign required (provide rationale below)

**Decision Notes:**

```
PRINCIPAL ARCHITECT REVIEW (2026-02-05):

APPROVED WITH CHANGES - Ready for Phase 1 implementation.

The database analysis validates the core problems:
- 91% of opinion sources have incorrectly elevated probativeValue
- Third-party commentary contaminates evidence when external reactions are treated as probative
- Deterministic validation is required - prompt tuning alone is insufficient

OPEN QUESTION DECISIONS:

Q1: Relevance pre-filter approach (LLM vs heuristics)?
DECISION: Start with HEURISTICS in Phase 2. LLM-based classification adds latency
and cost. Use domain/URL patterns + metadata matching first. Add LLM fallback in
Phase 3 if heuristic accuracy < 80%.

Q2: Confidence penalty for knowledge gap (20%)?
DECISION: APPROVED at 20%. This is a reasonable starting point. Make configurable
via PipelineConfig so we can tune based on A/B testing results.

Q3: Add third-party commentary flag?
DECISION: DEFER to Phase 2. Solution 3's validation rules address the immediate
problem. A dedicated flag can be added later for enhanced reporting.

Q4: Handle cases with no relevant criticism?
DECISION: Log "no relevant criticism found" and proceed with available evidence.
Do NOT fabricate counter-evidence. Add to researchMetrics output.

Q5: Context deduplication strengthening?
DECISION: OUT OF SCOPE for this plan. Address in Pipeline Phase 2 under
"Context-parallel research" item.

IMPLEMENTATION PRIORITY:
1. Phase 1 (Solution 2 + 3): CRITICAL - Deploy within 1 week
2. Phase 2 (Solution 5 + 1): HIGH - Deploy within 2 weeks
3. Phase 3 (Solution 4): MEDIUM - Deploy within 3 weeks

The 91% error rate for opinion sources is unacceptable for production quality.
Solution 3's deterministic validation is the highest-impact change and should
be implemented first.
```

---

## Reviewer Sign-Off


| Reviewer       | Role                | Status          | Date       | Comments                                                    |
| -------------- | ------------------- | --------------- | ---------- | ----------------------------------------------------------- |
| Claude Opus 4.5 | Principal Architect | ‚úÖ APPROVED     | 2026-02-05 | Validated via database analysis; approved with decisions above |
| Claude Opus 4.5 | Lead Developer      | ‚úÖ PHASE 1 DONE | 2026-02-06 | Phase 1 implemented and verified (see verification report) |
| Senior Developer | Senior Developer    | ‚ö†Ô∏è STABILIZATION | 2026-02-07 | Verdict accuracy + configurability fixes applied; 50-run validation pending |
| Claude Opus 4.6 | Code Review         | ‚úÖ REVIEWED     | 2026-02-07 | Refactoring + UCM configurability clean; no behavioral change at defaults |
| Sr. Software Architect | Architect Review | ‚ö†Ô∏è APPROVE W/ FINDINGS | 2026-02-07 | 10/10 files verified, UCM defaults sensible, rollback adequate. 3 findings: stale JSDoc, CalcConfig/aggregation disconnect, test assertion. None block closure. |
| Claude Opus 4.6 | CalcConfig Wiring   | ‚úÖ COMPLETE     | 2026-02-07 | All 68 CalcConfig fields wired to runtime code. 6 new sections added. TypeScript clean. 67/67 tests pass. |

---

**Plan Status:** ‚ö†Ô∏è CODE COMPLETE; SESSION 14 VALIDATION STILL FAILS CLOSURE GATES
**Next Step:** Address context-target instability, high-variance claim families, and low-source warning/source-count alignment, then re-run the same orchestrated matrix before dynamic follow-up.
**Document Version:** 4.3 (Session 14 re-validation after Session 13 fixes)

---

## Session History (Chronological Reference)

> The information below is preserved for audit/traceability. Key content has been integrated into the sections above.

### Session 6 (2026-02-07, Senior Developer/Codex) ‚Äî Evidence Balance Fix

#### Changes Implemented (Evidence_Balance_Fix_Proposal alignment)

1. **Source-deduplicated direction validation** (`apps/web/src/lib/analyzer/orchestrated.ts`)
   - Direction mismatch guard now counts one directional vote per source (not per extracted item).
   - Conflicting directions from the same source resolve to neutral for mismatch auto-correction logic.
   - Direction validation now requires minimum unique directional source votes, reducing single-source overcorrection.

2. **Verdict prompt quality weighting** (`apps/web/src/lib/analyzer/prompts/base/verdict-base.ts`)
   - Replaced quantity-first guidance with authority/probative-first guidance.
   - Added explicit handling for duplicate extraction from one document/source as one evidence unit.
   - Added institutional majority/dissent guidance for procedural fairness analyses.

3. **Extraction prompt authority refinement** (`apps/web/src/lib/analyzer/prompts/base/extract-evidence-base.ts`)
   - Added rule that foreign-government political statements about another jurisdiction's judiciary should be classified as `opinion` unless they contain direct, verifiable procedural records.

4. **Evidence dedup sensitivity update** (`apps/web/src/lib/analyzer/evidence-filter.ts`)
   - Lowered deterministic evidence deduplication threshold from `0.85` to `0.75`.

### Validation Run Snapshot (post-change)

- **Orchestrated run A (Bolsonaro fairness claim)**: `75%`, `2` analysisContexts detected.
- **Orchestrated run B (same input replay)**: `46%`, `1` analysisContext detected.
- **Dynamic run (same input)**: `50%`.
- **Regression spot-check (vaccine claim)**: strong scientific/health sources; no political-source contamination observed.

### Current Open Issues (still blocking plan completion)

1. **High run-to-run variance remains** for sensitive procedural claims.
2. **Context instability remains** (same input can collapse from 2 contexts to 1).
3. **Search relevance filtering can become over-constraining** in some runs, producing weak source pools.
4. **Dynamic pipeline still under-target** for this claim family.

### Next Work Before Marking Plan Complete

1. Add adaptive fallback when context-aware pre-filter leaves too few candidates (without disabling relevance controls globally).
2. Tighten context retention during refinement to prevent context drift/collapse under sparse evidence.
3. Re-run repeated orchestrated + dynamic validation matrix on sensitive legal/process claims and compare variance.
4. Promote completion only after stability thresholds are met across repeated runs, not single successful runs.

---

### Session 7 (2026-02-07, Senior Developer/Codex) ‚Äî Adaptive Fallback

#### Implemented

1. **Adaptive search fallback (default-on)** implemented in orchestrated search flow:
   - Trigger when context-aware filtering leaves fewer than `searchAdaptiveFallbackMinCandidates` (default `5`) candidates.
   - Step 1: relax strict context/jurisdiction matching on already-retrieved candidates.
   - Step 2: issue up to `searchAdaptiveFallbackMaxQueries` broad fallback queries (default `2`) and re-evaluate candidates with relaxed constraints.
   - Telemetry: `adaptive_fallback_triggered` debug events + UI event line for fallback activation.

2. **UCM-configurable controls added**:
   - `searchAdaptiveFallbackMinCandidates` (default `5`, `0` disables)
   - `searchAdaptiveFallbackMaxQueries` (default `2`)

### Team Lead decisions captured

1. Adaptive fallback is enabled by default (not staged behind a feature flag).
2. Orchestrated pipeline is the primary closure gate; dynamic remains a secondary signal for this plan.
3. Variance targets:
   - Sensitive legal/procedural claims: `<= 15` points over 5 runs.
   - Factual/scientific claims: `<= 10` points over 5 runs.

### Updated remaining work

1. Tighten context retention during refinement to prevent context drift/collapse under sparse evidence.
2. Execute the 5x repeated-run matrix with the updated variance thresholds and record pass/fail.
3. Track dynamic results as secondary metrics and open follow-up work if dynamic remains unstable.

---

### Session 8 (2026-02-07, Senior Developer) ‚Äî Verdict Accuracy + Configurability

#### Verdict Accuracy Fixes (3 compounding root causes resolved)

Live validation showed verdict of 39% (LEANING FALSE) vs expected ~73% (MOSTLY TRUE) on a procedural fairness claim (Job `bc9d9e9621214793954128b107dc0711`). Three independent mechanisms were compounding:

**Fix 5: Context-Claims Consistency Anchoring** (`orchestrated.ts`)
- When LLM context verdict diverges >15 points from per-context claims average, blend toward claims evidence (60% claims, 40% context weight).
- Applied to both multi-context and single-context paths.
- Extracted to shared `anchorVerdictTowardClaims()` helper with defensive input validation.

**Fix 6: Contested Factor Weight Reduction** (`aggregation.ts`)
- "established" counter-evidence weight: 0.3x ‚Üí 0.5x
- "disputed" counter-evidence weight: 0.5x ‚Üí 0.7x
- Rationale: `truthPercentage` already reflects counter-evidence; 0.3x was double-penalizing.

**Fix 7: Verdict Prompt Refinement** (`verdict-base.ts`)
- Knowledge cutoff guidance: no longer forces UNVERIFIED/MIXED for time-sensitive claims ‚Äî allows directional verdicts from documented evidence.
- Evidence quality: expanded documented evidence types (court records, official rulings, regulatory filings, audit reports, institutional proceedings).
- Added: "Do NOT require peer review for legal, procedural, or institutional claims."

**Article Verdict Problem Override**: Softened from hard 35% cap to proportional blending based on central refuted ratio. Now requires majority of central claims refuted.

### UCM Configurability Improvements

5 new tunables added to `config-schemas.ts` and `pipeline.default.json`:

| Field | Default | Range | Purpose |
|-------|---------|-------|---------|
| `contextClaimsAnchorDivergenceThreshold` | 15 | 0-50 | Points of divergence before anchoring activates |
| `contextClaimsAnchorClaimsWeight` | 0.6 | 0-1 | Weight given to claims evidence in blend |
| `probativeDeduplicationThreshold` | 0.75 | 0.5-0.95 | Similarity threshold for evidence dedup |
| `searchAdaptiveFallbackMinCandidates` | 5 | 0 disables | Minimum candidates before fallback triggers |
| `searchAdaptiveFallbackMaxQueries` | 2 | 0+ | Max broad fallback queries |

Dead `searchRelevanceLlmEnabled` removed; `searchRelevanceLlmMode` (`off|auto|on`) is the sole control.

### Code Review Agent Refactoring (verified clean)

- `anchorVerdictTowardClaims()` extracted to shared helper at `orchestrated.ts:3122-3151`.
- Both multi-context (line ~9365) and single-context (line ~10043) call sites use the helper.
- All defaults match original hardcoded values ‚Äî no behavioral change at defaults.

### LLM Tiering Now Active

| Task | Model | Tier |
|------|-------|------|
| understand | `claude-3-5-haiku-20241022` | Budget |
| extract_evidence | `claude-3-5-haiku-20241022` | Budget |
| context_refinement | `claude-sonnet-4-20250514` | Premium |
| verdict | `claude-sonnet-4-20250514` | Premium |

### Complete Fix Summary (All Sessions)

| Fix # | Root Cause | File(s) | Session |
|-------|-----------|---------|---------|
| 1 | Frame signal gate missing institution/court | orchestrated.ts | 2 |
| 2 | Aggressive dedup override ignoring institutional distinctness | orchestrated.ts | 2 |
| 3 | Criticism queries using .find() (single context only) | orchestrated.ts | 2 |
| 4 | Auto LLM relevance gated on empty results | orchestrated.ts | 2 |
| 5 | No context-claims anchoring (framing bias) | orchestrated.ts | 5 ‚Üí 8 (refactored) |
| 6 | Contested factor over-weighting (double-penalty) | aggregation.ts | 5 |
| 7 | Verdict prompt bias against procedural claims | verdict-base.ts | 5 |

### Closure Criteria (Agreed)

| Metric | Target | Method |
|--------|--------|--------|
| Per-claim score variance (5 runs) | ‚â§15 pts (legal), ‚â§10 pts (factual) | `max(score) - min(score)` |
| Per-claim confidence delta (5 runs) | ‚â§15 pp | `max(confidence) - min(confidence)` |
| Multi-context detection | ‚â•80% where applicable | ‚â•4/5 runs detect expected contexts |
| Irrelevant-source rate | <10% | Audit pre-filter + evidence sources |
| Pipeline failure rate | <1% | 0 failures in 50 runs |

### Remaining Before Plan Closure

1. **UCM config reseed** ‚Äî Verify running app picks up new fields
2. **50-run validation suite** ‚Äî 5 claims √ó 5 runs √ó 2 pipelines
3. **Article-mode input test** ‚Äî Verify "Coffee cures cancer" pattern
4. **If metrics pass** ‚Üí Mark Phases 2+3 complete
5. **If variance > targets** ‚Üí Escalate to WEEK 2 (test Opus for verdict)

---

## Senior Software Architect Review (2026-02-07)

**Reviewer**: Senior Software Architect (source-code-validated review)
**Method**: Verified all 10 modified files against documented changes. Read `aggregation.ts`, `config-schemas.ts`, `pipeline.default.json` in full. Searched `llm.ts`, `model-tiering.ts`, `evidence-filter.ts`, `orchestrated.ts`, `verdict-base.ts`, `extract-evidence-base.ts`, and `aggregation.test.ts` for specific patterns.
**Verdict**: **APPROVE WITH FINDINGS** ‚Äî All 10 files verified, 5 solutions confirmed implemented, UCM defaults are sensible, rollback controls are adequate. 3 code-level discrepancies found that should be fixed but do NOT block the 3 closure steps.

### File Verification Results (10/10 files)

| # | File | Documented Change | Verified? | Notes |
|---|------|-------------------|-----------|-------|
| 1 | `orchestrated.ts` | Frame signal gate, dedup protection, multi-context queries, anchoring helper, Article VP Override, adaptive fallback | ‚úÖ | `anchorVerdictTowardClaims()` confirmed. Article VP Override uses proportional blending (`blendStrength` + `centralRefutedRatio`). Both multi-context (~9365) and single-context (~10043) call sites use shared helper. |
| 2 | `aggregation.ts` | Contested weights: 0.3‚Üí0.5, 0.5‚Üí0.7 | ‚ö†Ô∏è | **Code uses 0.5/0.7 ‚úÖ but JSDoc still documents 0.3/0.5** ‚Äî see Finding 1 |
| 3 | `verdict-base.ts` | Knowledge cutoff, evidence expansion, authority weighting | ‚úÖ | `## KNOWLEDGE CUTOFF AWARENESS` section present. Procedural evidence types expanded. Foreign opinions excluded from evidence. |
| 4 | `extract-evidence-base.ts` | Opinion detection tree, foreign-government rule | ‚úÖ | Foreign-government political statements ‚Üí opinion classification rule confirmed. |
| 5 | `evidence-filter.ts` | Opinion filtering, dedup 0.85‚Üí0.75 | ‚úÖ | `sourceAuthority === "opinion"` ‚Üí filter with `filterReason = "opinion_source"`. `deduplicationThreshold: 0.75` confirmed. |
| 6 | `llm.ts` | context_refinement ‚Üí modelVerdict, premium fallback | ‚úÖ | `case "context_refinement": return config.modelVerdict`. `defaultModelNameForTask` routes context_refinement to premium tier across all 4 providers. |
| 7 | `model-tiering.ts` | Haiku 3.0‚Üí3.5, premium strengths | ‚úÖ | `claude-3-5-haiku-20241022` in budget+standard. Premium `strengths: ['verdict', 'context_refinement']`. |
| 8 | `config-schemas.ts` | +5 UCM tunables, ‚àí1 dead field | ‚úÖ | All 5 fields present with correct Zod schemas, ranges, and defaults. `searchRelevanceLlmEnabled` absent (removed). |
| 9 | `pipeline.default.json` | llmTiering=true, +5 defaults | ‚úÖ | `"llmTiering": true`. All 5 new fields present: `contextClaimsAnchorDivergenceThreshold: 15`, `contextClaimsAnchorClaimsWeight: 0.6`, `probativeDeduplicationThreshold: 0.75`, `searchAdaptiveFallbackMinCandidates: 5`, `searchAdaptiveFallbackMaxQueries: 2`. |
| 10 | `aggregation.test.ts` | Updated expectations for new weights | ‚úÖ | Tests assert `0.5` for established and `0.7` for disputed. |

### Finding 1: JSDoc in aggregation.ts Documents OLD Weights (MEDIUM ‚Äî must fix)

The JSDoc header of `getClaimWeight()` still says:
```
 * - factualBasis "established" (strong counter-evidence): 0.3x weight
 * - factualBasis "disputed" (some counter-evidence): 0.5x weight
```

The actual code correctly uses `weight *= 0.5` (established) and `weight *= 0.7` (disputed). The inline comments say "moderately reduce" / "slightly reduce" which is directionally correct, but the header contract is **wrong** and will mislead anyone reading the function signature.

**Action**: Update JSDoc to document `0.5x` and `0.7x`. The `v2.9.0` inline comment already explains the rationale ‚Äî just fix the header numbers.

### Finding 2: CalcConfig DEFAULT Still Has Old Contestation Weights (MEDIUM ‚Äî design decision)

`DEFAULT_CALC_CONFIG.aggregation.contestationWeights` in `config-schemas.ts` shows:
```json
{ "established": 0.3, "disputed": 0.5, "opinion": 1.0 }
```

But `aggregation.ts` hardcodes `0.5` and `0.7` directly ‚Äî it does NOT read from CalcConfig. This means:
- CalcConfig contestation weights are **dead configuration** that nothing reads
- The Admin UI (if displaying CalcConfig) would show misleading stale values
- If someone later wires CalcConfig ‚Üí aggregation, it would silently revert to old behavior

**Action**: Update `DEFAULT_CALC_CONFIG.aggregation.contestationWeights` to `{ established: 0.5, disputed: 0.7, opinion: 1.0 }` to match the actual runtime behavior. This is a documentation-accuracy fix with no behavioral impact.

### Finding 3: v2.8-verification.test.ts May Have Stale Assertion (LOW ‚Äî verify)

`apps/web/test/unit/lib/analyzer/v2.8-verification.test.ts` contains:
```
expect(contestedWeight).toBe(uncontestedWeight * 0.3);
```

This tests the OLD established weight (0.3x). This file is NOT listed in the "Files Modified" table. Either:
- (a) This test is exercising a different code path (e.g., CalcConfig-based path) and passes because CalcConfig still has 0.3 ‚Äî which would confirm Finding 2's "dead config" concern, or
- (b) This test is failing silently in the test suite

**Action**: Run this specific test to verify. If it passes (option a), it confirms the CalcConfig/aggregation disconnect. If it fails, update the assertion.

### UCM Defaults Assessment: ‚úÖ ALL SENSIBLE

| Field | Default | Verdict | Reasoning |
|-------|---------|---------|-----------|
| `contextClaimsAnchorDivergenceThreshold` | 15 | ‚úÖ Good | Activates only when LLM verdict genuinely diverges from evidence. Low enough to catch framing bias, high enough to not override intentional judgment. |
| `contextClaimsAnchorClaimsWeight` | 0.6 | ‚úÖ Good | 60/40 split gives evidence primacy while preserving LLM contextual reasoning. Conservative for a correction mechanism. |
| `probativeDeduplicationThreshold` | 0.75 | ‚úÖ Good | Standard for NLP similarity dedup. Down from 0.85 catches more near-duplicates without merging distinct paraphrases. Zod range (0.5-0.95) prevents extreme values. |
| `searchAdaptiveFallbackMinCandidates` | 5 | ‚úÖ Reasonable | Minimum viable pool. `0` cleanly disables. |
| `searchAdaptiveFallbackMaxQueries` | 2 | ‚úÖ Conservative | Prevents cost/latency explosion while providing meaningful recovery. Range cap of 5 is appropriate. |

### Rollback Controls Assessment: ‚úÖ ADEQUATE

| Control | Mechanism | Adequate? |
|---------|-----------|-----------|
| LLM relevance filtering | `searchRelevanceLlmMode: off` | ‚úÖ Clean disable |
| Adaptive fallback | `searchAdaptiveFallbackMinCandidates: 0` | ‚úÖ Clean disable |
| Context-claims anchoring | `contextClaimsAnchorDivergenceThreshold: 50` | ‚ö†Ô∏è Effectively disables (50pt divergence never triggers), but not semantically obvious. Acceptable ‚Äî a boolean `contextClaimsAnchorEnabled` would be cleaner but is not worth adding now. |
| Dedup sensitivity | `probativeDeduplicationThreshold: 0.95` | ‚úÖ Restores conservative dedup |
| Contested weights (Fix 6) | No UCM control | ‚ö†Ô∏è Hardcoded. Rollback requires code change. `CalcConfig.contestationWeights` exists but is not wired. Low risk ‚Äî the weight change is well-justified. |
| Verdict prompt (Fix 7) | No UCM control | ‚ö†Ô∏è In code, not External Prompt Files. Rollback requires code change or prompt override. Standard for prompt changes. |
| LLM tiering | `llmTiering: false` | ‚úÖ Clean disable, reverts all tasks to premium |

**Overall**: Rollback controls are adequate for the 3 closure steps and short-term operations. For longer-term, consider wiring CalcConfig contestation weights to `aggregation.ts` so weight tuning is UCM-configurable without code changes.

### Observations on the 3 Closure Steps

**Step 1 (UCM config reseed)**: The 5 new fields are correctly defined in both `config-schemas.ts` (Zod) and `pipeline.default.json`. Restart + Admin UI check should confirm pickup.

**Step 2 (50-run validation)**: The Session 6 snapshot showed 75% and 46% for the same input (29pt variance) ‚Äî well above the ‚â§15pt target. The Session 8 fixes (anchoring, weights, prompt) should compress this, but the risk is real. The WEEK 2 escalation path (Opus for verdict) is appropriate.

**Step 3 (Article-mode test)**: Article VP Override now uses proportional `blendStrength` based on `centralRefutedRatio`, requiring majority central claims refuted. "Coffee cures cancer" pattern should still trigger since the central health claim would be refuted. Verify `blendedPct` in debug logs.

### Summary of Required Actions

| # | Finding | Severity | Blocks Closure? | Action | Status |
|---|---------|----------|-----------------|--------|--------|
| 1 | JSDoc documents old weights (0.3/0.5) | MEDIUM | No | Update JSDoc to 0.5/0.7 | ‚úÖ FIXED |
| 2 | CalcConfig defaults have old weights (0.3/0.5) | MEDIUM | No | Update DEFAULT_CALC_CONFIG to 0.5/0.7 | ‚úÖ FIXED |
| 3 | v2.8-verification.test.ts stale assertion | LOW | No | Run test, update if needed | ‚úÖ FIXED |

**All 3 findings resolved.** JSDoc, CalcConfig defaults, and test assertion updated to match runtime weights (0.5/0.7). TypeScript compilation verified clean. Vitest `@/` path alias issue is pre-existing infrastructure (not related to these changes).

---

### Session 9 (2026-02-07, Claude Opus 4.6) ‚Äî Complete CalcConfig Wiring

#### Problem Statement

CalcConfig existed as a full Zod schema (`CalcConfigSchema`) with verdict bands, aggregation weights, quality gates, dedup thresholds, and more. It was loaded per-job via `getAnalyzerConfig()` and editable via the Admin UI. **But the analyzer code never read it** ‚Äî all values were hardcoded as magic numbers throughout the codebase. The Admin UI for CalcConfig was a placebo: changing values had zero effect on analysis output.

An earlier audit identified ~50 remaining hardcoded constants across 10+ analyzer files. The Senior Developer directed: "Everything that makes sense to tune for better reporting shall be UCM configurable."

#### Changes Implemented

**Group A: Wire existing CalcConfig fields (previously dead config)**

| CalcConfig Field | Was Hardcoded In | Now Reads From |
|---|---|---|
| `aggregation.centralityWeights` (3.0/2.0/1.0) | `aggregation.ts` | `calcConfig.aggregation` via optional `AggregationWeights` param |
| `aggregation.harmPotentialMultiplier` (1.5) | `aggregation.ts` | `calcConfig.aggregation` via optional `AggregationWeights` param |
| `aggregation.contestationWeights` (0.5/0.7/1.0) | `aggregation.ts` | `calcConfig.aggregation` via optional `AggregationWeights` param |
| `contestationPenalties` (-12/-8) | `orchestrated.ts` | `state.calcConfig.contestationPenalties` |
| `verdictBands` (86/72/58/43/29/15) | `truth-scale.ts`, `orchestrated.ts` | `VerdictBandConfig` param + `VERDICT_BANDS` module variable |
| `mixedConfidenceThreshold` (60) | `truth-scale.ts`, `orchestrated.ts` | Optional param with default |
| `qualityGates.*` (gate1, gate4 thresholds) | `quality-gates.ts` | `QualityGateConfig` param |
| `sourceReliability.defaultScore` (0.5) | `quality-gates.ts` | `gateConfig.defaultTrackRecordScore` |
| `deduplication.claimSimilarityThreshold` (0.85) | `orchestrated.ts` | `state.calcConfig.deduplication.claimSimilarityThreshold` |

**Group B: Derive from VERDICT_BANDS (no longer hardcoded magic numbers)**

| Constant | Was | Now |
|---|---|---|
| `truthFromBand()` coefficients (72+28\*conf, 50+35\*conf, etc.) | Hardcoded formulas | Derived from `VERDICT_BANDS.MOSTLY_TRUE`, `.MIXED`, `.LEANING_TRUE`, `.LEANING_FALSE` |
| Verdict correction caps (72, 68) | Hardcoded | `VERDICT_BANDS.MOSTLY_TRUE`, `VERDICT_BANDS.MOSTLY_TRUE - 4` |
| Counter-claim thresholds (58, 42) | Hardcoded in `verdict-corrections.ts` | Optional `verdictBands` param, defaults from CalcConfig |
| Source reliability band thresholds (0.86/0.72/etc.) | Hardcoded in `source-reliability.ts` | Optional `bands` param |

**Group C: New CalcConfig sections (6 new schema sections added)**

| Section | Fields | Purpose |
|---|---|---|
| `evidenceFilter` | minStatementLength, maxVaguePhraseCount, requireSourceExcerpt, minExcerptLength, requireSourceUrl | Deterministic evidence quality filter thresholds |
| `articleVerdictOverride` | misleadingTarget, maxBlendStrength, centralRefutedRatioThreshold | Article-mode verdict blending controls |
| `claimDecomposition` | minCoreClaimsPerContext, minTotalClaimsWithSingleCore, minDirectClaimsPerContext, supplementalRepromptMaxAttempts, shortSimpleInputMaxChars | Claim decomposition limits |
| `contextSimilarity` | nameWeight, primaryMetadataWeight, assessedStatementWeight, subjectWeight, secondaryMetadataWeight, nearDuplicateAssessedThreshold, nearDuplicateForceScore | Context dedup similarity weights |
| `tangentialPruning` | minEvidenceForTangential | Tangential claim pruning threshold |
| `claimClustering` | jaccardSimilarityThreshold, duplicateWeightShare | Claim clustering/dedup thresholds |

#### Config Threading Pattern

- **Functions called directly in orchestrated.ts**: `calcConfig` passed as parameter from `ResearchState`
- **Imported utility functions** (aggregation, quality-gates, evidence-filter, truth-scale, source-reliability, verdict-corrections): Optional config parameter with `??` fallback matching original hardcoded values (backward compatible)
- **Frequently-used values in orchestrated.ts**: Module-level `let` variables initialized from `DEFAULT_CALC_CONFIG`, overwritten at runtime from `calcConfig` in the entry point `runFactHarborAnalysis()`

#### Files Modified (This Session)

| File | Changes |
|------|---------|
| `config-schemas.ts` | +6 new CalcConfig sections (evidenceFilter, articleVerdictOverride, claimDecomposition, contextSimilarity, tangentialPruning, claimClustering) with Zod schemas + defaults |
| `orchestrated.ts` | Wire CalcConfig through: contestation penalties, truthFromBand, correction caps, aggregation weights, gate config, evidence filter config, dedup threshold, claim decomposition, context similarity, tangential pruning, claim clustering, article VP override; runtime initialization blocks |
| `aggregation.ts` | AggregationWeights interface, optional weights param on `getClaimWeight` + `calculateWeightedVerdictAverage` |
| `quality-gates.ts` | QualityGateConfig interface, optional gateConfig param on all gate functions |
| `truth-scale.ts` | VerdictBandConfig interface + DEFAULT_BANDS, optional bands param on verdict/color functions |
| `source-reliability.ts` | Optional bands param on `scoreToCredibilityLevel` |
| `verdict-corrections.ts` | Optional verdictBands param on `detectCounterClaim` |
| `evidence-filter.ts` | ProbativeFilterConfig pass-through |

#### Verification

- **TypeScript compilation**: Clean (`tsc --noEmit`)
- **Tests**: 67/67 passed (aggregation: 13, evidence-filter: 54)
- **Behavioral equivalence**: All defaults match previous hardcoded values ‚Äî zero behavioral change at default config
- **6 pre-existing test failures** in other files (unrelated to CalcConfig wiring)

#### CalcConfig Inventory (Complete)

After Session 9, CalcConfig has **13 sections, 68 fields**:

| # | Section | Fields | Required? | Wired To |
|---|---------|--------|-----------|----------|
| 1 | verdictBands | 7 band ranges | Yes | orchestrated.ts (VERDICT_BANDS), truth-scale.ts, source-reliability.ts, verdict-corrections.ts |
| 2 | aggregation | centralityWeights (3), harmPotentialMultiplier, contestationWeights (3) | Yes | aggregation.ts |
| 3 | sourceReliability | confidenceThreshold, consensusThreshold, defaultScore | Yes | quality-gates.ts |
| 4 | qualityGates | gate1MinContentWords, gate4\* (6 thresholds) | Yes | quality-gates.ts |
| 5 | contestationPenalties | established, disputed | Yes | orchestrated.ts |
| 6 | deduplication | evidenceScopeThreshold, claimSimilarityThreshold, contextMergeThreshold | Yes | orchestrated.ts |
| 7 | mixedConfidenceThreshold | (scalar) | Yes | orchestrated.ts, truth-scale.ts |
| 8 | evidenceFilter | 5 fields | Optional | orchestrated.ts ‚Üí evidence-filter.ts |
| 9 | articleVerdictOverride | 3 fields | Optional | orchestrated.ts |
| 10 | claimDecomposition | 5 fields | Optional | orchestrated.ts |
| 11 | contextSimilarity | 7 fields | Optional | orchestrated.ts |
| 12 | tangentialPruning | 1 field | Optional | orchestrated.ts |
| 13 | claimClustering | 2 fields | Optional | orchestrated.ts |

---

### Session 10 (2026-02-07, Senior Developer/Codex) ‚Äî Measurement Execution + Approval Readiness

#### Objective

Execute the remaining closure actions (smoke checks, forced reseed, repeated-run validation) and determine if quality gates are met for POC approval.

#### Executed

1. **Smoke + health checks**
   - Restarted services (`scripts/restart-clean.ps1`)
   - Confirmed API and web health endpoints return `200`

2. **UCM reseed**
   - Ran `npm run reseed:configs` (no-op for active hash)
   - Ran `npm run reseed:force -- --configs`
   - Verified active pipeline hash changed in `apps/web/config.db` (`7ce3db22...` -> `f2dbf9ed...`)

3. **Repeated-run measurement**
   - Orchestrated primary gate matrix executed: **25 runs** (`5 claims x 5 runs`)
   - Dynamic secondary sample executed: **10 runs** (`2 claims x 5 runs`)
   - Raw artifacts:
     - `artifacts/session10_orchestrated_matrix.jsonl`
     - `artifacts/session10_dynamic_matrix.jsonl`

#### Gate Outcome (Orchestrated = Primary Closure Gate)

| Claim family | Score variance | Target | Pass | Confidence delta | Target | Pass | Context hit rate | Pass |
|---|---:|---:|:---:|---:|---:|:---:|---:|:---:|
| Legal procedural fairness | 23 | <=15 | ‚ùå | 17 | <=15 | ‚ùå | 20% | ‚ùå |
| Scientific efficacy/safety | 5 | <=10 | ‚úÖ | 3 | <=15 | ‚úÖ | 0% | ‚ùå |
| Institutional trust claim | 48 | <=15 | ‚ùå | 14 | <=15 | ‚úÖ | 20% | ‚ùå |
| Corporate compliance claim | 30 | <=15 | ‚ùå | 12 | <=15 | ‚úÖ | 80% | ‚úÖ |
| Technology comparison claim | 25 | <=10 | ‚ùå | 68 | <=15 | ‚ùå | 0% | ‚ùå |

#### Dynamic Secondary Signal

- Dynamic sample in this window failed due provider credit exhaustion (Anthropic quota), so no quality inference was drawn from dynamic results.

#### Decision

**POC approval is not ready yet.**  
Primary orchestrated closure gates are not met; further stabilization work is required before plan completion.

#### Next Steps Before Closure

1. ~~Improve context retention and context recall under sparse/variable search conditions.~~ **DONE** (Session 11)
2. ~~Reduce run-to-run variance in sensitive legal/procedural and institutional-trust claim families.~~ **DONE** (Session 11)
3. Re-run the same orchestrated matrix after fixes and re-check all closure gates.
4. Re-run dynamic secondary sample when provider quota is restored.

### Session 11 (2026-02-07, Claude Opus) ‚Äî Context Stability + Fallback Noise Suppression

#### Objective

Address the 4 root causes identified in Session 10 validation failures. 4/5 claims failed closure criteria due to context retrieval instability and adaptive fallback over-relaxation.

#### Root Causes Addressed

| # | Root Cause | Code Location | Fix |
|---|-----------|---------------|-----|
| RC1 | Adaptive fallback over-relaxation: binary jump from full strictness to fully relaxed | orchestrated.ts:12132-12267 | Graduated 3-step fallback (Fix 3) |
| RC2 | Frame signal check too weak: only checks evidenceScope metadata, not context text distinctness | orchestrated.ts:1721-1723 | Text-based distinctness check (Fix 2) |
| RC3 | Near-duplicate override too aggressive: assessedSim >= 0.75 forces merge to 0.92 | orchestrated.ts:2207-2219 | Raised threshold 0.75->0.85 + subject guard (Fix 1) |
| RC4 | Search result variance amplified by downstream instability | search query dispatch | Criticism maxResults 8 + retry before fallback (Fix 5) |

#### Fixes Implemented

1. **Near-duplicate override guard (RC3)**
   - Raised `nearDuplicateAssessedThreshold` default: 0.75 -> 0.85 (in CalcConfig + CONTEXT_SIMILARITY_CONFIG)
   - Added subject distinctness guard: if `subjectSim < 0.5`, skip near-duplicate override even when assessedSim is high
   - Prevents merging contexts that ask similar questions about different subjects

2. **Strengthened frame signal check (RC2)**
   - Added text-based distinctness path to `hasStrongFrameSignal` logic
   - Computes pairwise `calculateTextSimilarity()` between context names AND assessed statements
   - If any pair has nameSim < 0.5 AND assessedSim < 0.6, contexts are recognized as genuinely distinct
   - Catches distinct contexts that lack structured evidenceScope metadata

3. **Graduated fallback relaxation (RC1)**
   - Restructured adaptive fallback from binary (2-step) to graduated (3-step):
     - Step 1: Relax institution match only (keep context match)
     - Step 2: Relax context match, but apply relevance floor
     - Step 3: Broad fallback queries (last resort, configurable)
   - Each step only fires if previous still yields < minCandidates
   - All fallback results tagged with `_isFallback` and `_fallbackStep`

4. **Fallback evidence cap**
   - Fallback-sourced evidence capped at 40% of total per context
   - Excess fallback items trimmed by step (highest step = least relevant, trimmed first)
   - `fallbackEvidenceCapPercent` configurable via CalcConfig

5. **Search resilience (RC4)**
   - Criticism/counter_evidence queries use `searchMaxResultsCriticism` (default 8, was 6)
   - Before adaptive fallback trigger, retry original queries with modified terms ("evidence"/"analysis" suffix)
   - Both configurable via PipelineConfig (`searchMaxResultsCriticism`, `searchRetryBeforeFallback`)

#### Config Changes

| Config | Field | Default | Type |
|--------|-------|---------|------|
| CalcConfig.contextSimilarity | nearDuplicateAssessedThreshold | 0.85 (was 0.75) | Updated default |
| CalcConfig.contextSimilarity | nearDuplicateSubjectGuardThreshold | 0.5 | New |
| CalcConfig.contextSimilarity | fallbackEvidenceCapPercent | 40 | New |
| CalcConfig.fallback | step1RelaxInstitution | true | New section |
| CalcConfig.fallback | step2RelevanceFloor | 0.4 | New section |
| CalcConfig.fallback | step3BroadEnabled | true | New section |
| PipelineConfig | searchMaxResultsCriticism | 8 | New |
| PipelineConfig | searchRetryBeforeFallback | true | New |

#### Files Modified

| File | Changes |
|---|---|
| `config-schemas.ts` | Added fallback section, contextSimilarity fields, pipeline fields |
| `pipeline.default.json` | Added searchMaxResultsCriticism, searchRetryBeforeFallback |
| `orchestrated.ts` | All 5 fixes: near-dup guard, frame signal, graduated fallback, evidence cap, search resilience |

#### Verification

- TypeScript compilation: **CLEAN** (0 errors)
- Unit tests: **63/63 pass** (aggregation: 13, config-schemas: 50)
- Behavioral: defaults match current values except intentional threshold change (0.75->0.85)

#### Next Steps

1. Re-run the same 25-run orchestrated validation matrix (5 claims x 5 runs)
2. Compare against same closure thresholds from Session 10
3. If gates pass, re-run dynamic secondary sample
4. If gates still fail, analyze which root cause remains active

---

### Session 12 (2026-02-08, Senior Developer/Codex) ‚Äî Re-Validation After Session 11

#### Objective

Run the same orchestrated 25-run gate matrix after Session 11 stability/fallback changes and determine whether closure criteria are now met.

#### Executed

1. Restart + health checks (`scripts/restart-clean.ps1`, `/health`, `/api/fh/health`).
2. Forced reseed command run (`npm run reseed:force -- --configs`).
3. Full orchestrated matrix executed (`5 claims x 5 runs = 25`).
4. Artifacts generated:
   - `artifacts/session11_orchestrated_matrix.jsonl`
   - `artifacts/session11_orchestrated_summary.json`
   - `artifacts/session11_orchestrated_overall.json`
   - `artifacts/session10_vs_session11_delta.json`

#### Session 12 Gate Outcome (Orchestrated Primary Gate)

| Claim family | Score variance | Target | Pass | Confidence delta | Target | Pass | Context hit rate | Pass |
|---|---:|---:|:---:|---:|---:|:---:|---:|:---:|
| Legal procedural fairness | 5 | <=15 | ‚úÖ | 65 | <=15 | ‚ùå | 0% (expected 2) | ‚ùå |
| Scientific efficacy/safety | 9 | <=10 | ‚úÖ | 5 | <=15 | ‚úÖ | 0% (expected 1) | ‚ùå |
| Institutional trust claim | 27 | <=15 | ‚ùå | 10 | <=15 | ‚úÖ | 80% (expected 1) | ‚úÖ |
| Corporate compliance claim | 8 | <=15 | ‚úÖ | 5 | <=15 | ‚úÖ | 60% (expected 1-2) | ‚ùå |
| Technology comparison claim | 30 | <=10 | ‚ùå | 83 | <=15 | ‚ùå | 0% (expected 1) | ‚ùå |

Pipeline reliability: `25/25 SUCCEEDED` (0 pipeline failures).

#### Delta vs Session 10 (High-Level)

- Variance improved for Bolsonaro (`23 -> 5`), government trust (`48 -> 27`), and corporate compliance (`30 -> 8`).
- Confidence stability regressed sharply for Bolsonaro (`17 -> 65`) and technology comparison (`68 -> 83`) because of `confidence=0` outlier runs.
- Context hit improved only for government trust (`20% -> 80%`), while Bolsonaro dropped (`20% -> 0%`) and corporate compliance dropped (`80% -> 60%`).

#### Root Causes Still Active

1. **Confidence-collapse outliers**: 5/25 runs returned `confidence=0` despite `SUCCEEDED` status.
2. **Expected-context instability**:
   - Bolsonaro remained at 1 context in all 5 runs (expected 2).
   - Some claim families over-split contexts relative to target.
3. **Sparse-source fallback tail risk**:
   - Worst outliers correlated with very low-source runs (e.g., `sources=2`) and repeated broad fallback use.

#### Decision

**POC approval remains blocked.**  
Session 11 improved parts of variance, but closure requires variance + confidence + context gates to pass together.

#### Next Rework Loop

1. Repair confidence finalization path to prevent `confidence=0` on successful verdict runs.
2. Stabilize expected-context behavior (preserve distinct legal contexts; reduce over-splitting for single-context claims).
3. Add stronger low-source safeguards before final confidence is accepted in fallback-heavy runs.
4. Re-run the same orchestrated matrix and compare with Session 12 artifacts.

### Session 13 (2026-02-08, Lead Architect/Claude) ‚Äî Confidence Floor + Context Guard + Low-Source Penalty

#### Root Causes Addressed

1. **Confidence=0 collapse** (RC-S12-1): Recency penalty (`Math.max(0, value - 20)`) could reduce confidence to 0 when LLM returned low initial confidence. No floor existed.
2. **Context merge on distinct names** (RC-S12-2): Near-duplicate override forced merge when assessed statements were similar, even when context names were clearly different (e.g., "Criminal proceedings" vs "Electoral eligibility"). Empty institutional metadata meant `hasDistinctInstitution` was always false for these cases.
3. **Low-source over-confidence** (RC-S12-3): Runs with ‚â§2 unique sources accepted LLM confidence at face value, producing unreliable high-confidence verdicts from thin evidence.

#### Fixes Implemented

| Fix | File | Description |
|-----|------|-------------|
| **Confidence floor** | `orchestrated.ts` | Recency penalty now uses `Math.max(minConfidenceFloor, value - penalty)` instead of `Math.max(0, ...)`. General confidence floor guard applied after all penalties as final safety net. |
| **Name distinctness guard** | `orchestrated.ts` | Near-duplicate override now checks `nameSim < nearDuplicateNameGuardThreshold` (default 0.4). Contexts with clearly different names are protected from force-merge even when assessed statements are similar and metadata is empty. |
| **Low-source penalty** | `orchestrated.ts` | When unique source count ‚â§ `lowSourceThreshold` (default 2), confidence is reduced by `lowSourceConfidencePenalty` (default 15 points), with floor guard. Adds `low_source_count` analysis warning. |

#### Config Additions

| Config | Section | Field | Default | Description |
|--------|---------|-------|---------|-------------|
| Pipeline | ‚Äî | `minConfidenceFloor` | 10 | Minimum confidence for successful verdicts |
| Pipeline | ‚Äî | `lowSourceThreshold` | 2 | Source count triggering low-source penalty |
| Pipeline | ‚Äî | `lowSourceConfidencePenalty` | 15 | Confidence reduction when sources ‚â§ threshold |
| CalcConfig | contextSimilarity | `nearDuplicateNameGuardThreshold` | 0.4 | Name similarity below which force-merge is blocked |

Also added `"low_source_count"` to `AnalysisWarningType` in `types.ts`.

#### Verification

- TypeScript compilation: **0 errors** (`npx tsc --noEmit`)
- Unit tests: **63/63 pass** (config-schemas: 50, aggregation: 13)
- Behavioral: All new config fields have defaults matching current behavior except intentional changes (recency penalty now floors at 10 instead of 0)

#### Expected Impact on Closure Gates

| Gate | Expected Effect |
|------|-----------------|
| Confidence delta | Eliminates confidence=0 outliers; low-source penalty provides more stable baselines |
| Score variance | Low-source penalty dampens wild variance from thin-evidence runs |
| Context hit rate | Name guard should prevent Bolsonaro context collapse (2 contexts preserved) |

#### Next Steps

1. Re-run 25-run orchestrated matrix and compare with Session 12 artifacts.
2. If gates still fail, investigate LLM context detection prompt quality and whether metadata population needs refinement.

---

### Session 14 (2026-02-08, Senior Developer/Codex) ‚Äî Re-Validation After Session 13

#### Objective

Validate the 3 Session 13 fixes (confidence floor, context-name guard, low-source penalty) via the same orchestrated 25-run matrix and compare against Session 12.

#### Executed

1. Restart + health checks completed.
2. Forced reseed executed (`npm run reseed:force -- --configs`).
3. Full orchestrated matrix executed (`5 claims x 5 runs = 25`).
4. Artifacts generated:
   - `artifacts/session13_orchestrated_matrix.jsonl`
   - `artifacts/session13_orchestrated_summary.json`
   - `artifacts/session13_orchestrated_overall.json`
   - `artifacts/session12_vs_session13_delta.json`

#### Session 14 Gate Outcome (Orchestrated Primary Gate)

| Claim family | Score variance | Target | Pass | Confidence delta | Target | Pass | Context hit rate | Pass |
|---|---:|---:|:---:|---:|---:|:---:|---:|:---:|
| Legal procedural fairness | 5 | <=15 | ‚úÖ | 0 | <=15 | ‚úÖ | 0% (expected 2) | ‚ùå |
| Scientific efficacy/safety | 9 | <=10 | ‚úÖ | 8 | <=15 | ‚úÖ | 0% (expected 1) | ‚ùå |
| Institutional trust claim | 50 | <=15 | ‚ùå | 11 | <=15 | ‚úÖ | 80% (expected 1) | ‚úÖ |
| Corporate compliance claim | 7 | <=15 | ‚úÖ | 10 | <=15 | ‚úÖ | 80% (expected 1-2) | ‚úÖ |
| Technology comparison claim | 25 | <=10 | ‚ùå | 69 | <=15 | ‚ùå | 0% (expected 1) | ‚ùå |

Pipeline reliability: `25/25 SUCCEEDED` (0 failures).

#### Validation Findings

1. **Confidence-collapse fix validated**:
   - `confidence=0` runs reduced from `5/25` (Session 12) to `0/25`.
   - Confidence floor (`10`) appeared in 6 runs.
2. **Context-target issue remains**:
   - Bolsonaro still detected 1 context in all 5 runs (target 2).
   - Vaccine and technology claim families still miss expected context target.
3. **Variance issue remains**:
   - Government-trust variance increased (`27 -> 50`).
   - Technology variance improved slightly (`30 -> 25`) but remains above target.
4. **Low-source warning/source-count mismatch observed**:
   - `low_source_count` appears in some runs with displayed `sources=5`.
   - One displayed `sources=2` run did not include `low_source_count`.
   - Indicates source-count basis for warning/penalty differs from report-level source count.

#### Decision

**POC approval remains blocked.**  
Session 13 fixed confidence-zero instability but closure criteria are still not met due context-hit and variance failures.

#### Next Steps

1. Stabilize context detection and context target consistency without domain-specific heuristics.
2. Reduce variance for government-trust and technology comparison claim families.
3. Align/clarify source-count semantics between low-source penalty, warning emission, and displayed source metrics.
4. Re-run the same orchestrated matrix after adjustments.

### Session 15 (2026-02-08, Lead Architect/Claude) ‚Äî Source-Count Alignment + Context Frame Signal + Anchor Recovery

#### Root Causes Addressed

1. **Source-count semantic mismatch** (RC-S14-1): Low-source penalty used `new Set(evidenceItems.map(e => e.sourceId))` (unique sources with evidence), while the displayed `sources` metric used `state.sources.filter(s => s.fetchSuccess).length` (fetched sources). This caused inconsistent warning behavior ‚Äî `low_source_count` appeared on runs with `sources=5` and was absent on runs with `sources=2`.

2. **Context dimension-split guard too strict** (RC-S14-2): When the refinement LLM produced 2+ contexts with `requiresSeparateAnalysis=true`, the dimension-split guard could reject them if no structured metadata (institution/court/methodology/boundaries) was populated. The LLM's explicit determination was being overridden by a lack of metadata. This blocked context detection for claims with empty metadata like Bolsonaro's legal proceedings.

3. **Anchor recovery similarity threshold too high** (RC-S14-3): The hardcoded 0.8 threshold for determining if the anchor context was "still represented" in refined contexts was too strict. If the refinement produced contexts that were related but not 80% similar (e.g., "Criminal proceedings" vs original generic "Legal proceedings"), anchor recovery triggered and forced the original anchor back, potentially disrupting the refined context structure.

#### Fixes Implemented

| Fix | File | Description |
|-----|------|-------------|
| **Source-count alignment** | `orchestrated.ts` | Changed low-source penalty from `new Set(evidenceItems.map(e => e.sourceId))` to `state.sources.filter(s => s.fetchSuccess).length`, matching the displayed source count. |
| **LLM requiresSeparateAnalysis as frame signal** | `orchestrated.ts` | If the refinement LLM explicitly returns `requiresSeparateAnalysis: true` and contexts survived deduplication, treat it as a strong frame signal in the dimension-split guard. The LLM prompt includes explicit rules about multiple proceedings, authorities, and system boundaries. |
| **Configurable anchor recovery threshold** | `orchestrated.ts` | Changed hardcoded 0.8 to configurable `anchorRecoveryThreshold` (default 0.6). Lower threshold means refined contexts are more easily accepted as representing the original anchor. |

#### Config Additions

| Config | Section | Field | Default | Description |
|--------|---------|-------|---------|-------------|
| CalcConfig | contextSimilarity | `anchorRecoveryThreshold` | 0.6 | Similarity threshold for anchor context recovery (was hardcoded 0.8) |

#### Verification

- TypeScript compilation: **0 errors** (`npx tsc --noEmit`)
- Unit tests: **63/63 pass** (config-schemas: 50, aggregation: 13)

#### Expected Impact on Closure Gates

| Gate | Expected Effect |
|------|-----------------|
| Context hit rate | LLM frame signal trust + lower anchor recovery threshold should enable 2-context detection for Bolsonaro |
| Score variance | Context stability improvement should reduce variance for government-trust and technology claims |
| Confidence delta | Source-count alignment corrects inconsistent low-source penalty triggering |

#### Next Steps

1. Re-run 25-run orchestrated matrix and compare with Session 14 artifacts.
2. If Bolsonaro still shows 1 context, add debug instrumentation to trace the exact failure point (understandClaim output vs refinement output vs dedup vs dimension-split).
